<STRONG><FONT style="BACKGROUND-COLOR: #7be1e1" color=blue>Operating Systems: Principles and Practice (Second Edition) Volume II : 4. Concurrency and Threads : </FONT></STRONG>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=headers>Title:</SPAN></B><SPAN class=RefText> 4.8 Implementing Multi-Threaded Processes</SPAN></FONT></FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">So far, we have described how to implement multiple threads that run inside the operating system kernel. Of course, we also want to be able to run user programs as well. Since many user programs are single-threaded, we start with the simple case of how to integrate kernel threads and single-threaded processes. We then turn to various ways of implementing <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:multi-threaded process"}'>multi-threaded processes</A></EM>, processes with multiple threads. All widely used modern operating systems support both kernel threads and multi-threaded processes. Both programming languages, such as Java, and standard library interfaces such as POSIX and simple threads, use this operating system support to provide the thread abstraction to the programmer. </FONT><A id=x1-28001r49 name=x1-28001r49></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.1 </FONT><A id=x1-290001 name=x1-290001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Multi-Threaded Processes Using Kernel Threads</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The simplest way to support multiple threads per process is to use the kernel thread implementation we have already described. When a kernel thread creates, deletes, suspends, or resumes a thread, it can use a simple procedure call. When a user-level thread accesses the thread library to do the same things, it uses a system call to ask the kernel to do the operation on its behalf. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As shown earlier in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2300212"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.12</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, a thread in a process has: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A user-level stack for executing user code. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A kernel interrupt stack for when this thread makes system calls, causes a processor exception, or is interrupted. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A kernel TCB for saving and restoring the per-thread state.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To create a thread, the user library allocates a user-level stack for the thread and then does a system call into the kernel. The kernel allocates a TCB and interrupt stack, and arranges the state of the thread to start execution on the user-level stack at the beginning of the requested procedure. The kernel needs to store a pointer to the TCB in the process control block; if the process exits, the kernel must terminate any other threads running in the process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">After creating the thread, the kernel puts the new thread on the ready list, to be scheduled like any other thread, and returns unique identifier for the user program to use when referring to the newly created thread (e.g., for join). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thread join, yield, and exit work the same way: by calling into the kernel to perform the requested function. </FONT><A id=x1-29001r54 name=x1-29001r54></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.2 </FONT><A id=x1-300002 name=x1-300002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing User-Level Threads Without Kernel Support</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">It is also possible to implement threads as a library completely at user level, without any operating system support. Early thread libraries took this pure user-level approach for the simple reason that few operating systems supported multi-threaded processes. Even once operating system support for threads became widespread, pure user-level threads were sometimes used to minimize dependencies on specific operating systems and to maximize portability; for example, the earliest implementations of Sun&#8217;s Java Virtual Machine (JVM) implemented what were called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:green threads"}'>green threads</A></EM>, a pure user-level implementation of threads. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The basic idea is simple. The thread library instantiates all of its data structures within the process: TCBs, the ready list, the finished list, and the waiting lists all are just data structures in the process&#8217;s address space. Then, calls to the thread library are just procedure calls, akin to how the same functions are implemented within a multi-threaded kernel. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To the operating system kernel, a multi-threaded application using green threads appears to be a normal, single-threaded process. The process as a whole can make system calls, be time-sliced, etc. Unlike with kernel threads, when a process using green threads is time-sliced, the entire process, including all of its threads, is suspended. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A limitation of green threads is that the operating system kernel is unaware of the state of the user-level ready list. If the application performs a system call that blocks waiting for I/O, the kernel is unable to run a different user-level thread. Likewise, on a multiprocessor, the kernel is unable to run the different threads running within a single process on different processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Preemptive User-level Threads.</B> However, it is possible on most operating systems to implement preemption among user-level threads executing within a process. As we discussed in Chapter&nbsp;2, most operating systems provide an upcall mechanism to deliver asynchronous event notification to a process; on UNIX these are called signal handlers. Typical events or signals include the user hitting &#8220;Escape&#8221; or on UNIX &#8220;Control-C&#8221;; this informs the application to attempt to cleanly exit. Another common event is a timer interrupt to signal elapsed real time. To deliver an event, the kernel suspends the process execution and then resumes it running at a handler specified by the user code, typically on a separate upcall or signal stack. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To implement preemptive multi-threading for some process P : </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-30002x1 name=x1-30002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The user-level thread library makes a system call to register a timer signal handler and signal stack with the kernel. </FONT></P>
<LI class=enumerate><A id=x1-30004x2 name=x1-30004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When a hardware timer interrupt occurs, the hardware saves P &#8217;s register state and runs the kernel&#8217;s handler. </FONT></P>
<LI class=enumerate><A id=x1-30006x3 name=x1-30006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Instead of restoring P &#8217;s register state and resuming P where it was interrupted, the kernel&#8217;s handler copies P &#8217;s saved registers onto P &#8217;s signal stack. </FONT></P>
<LI class=enumerate><A id=x1-30008x4 name=x1-30008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The kernel resumes execution in P at the registered signal handler on the signal stack. </FONT></P>
<LI class=enumerate><A id=x1-30010x5 name=x1-30010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The signal handler copies the processor state of the preempted user-level thread from the signal stack to that thread&#8217;s TCB. </FONT></P>
<LI class=enumerate><A id=x1-30012x6 name=x1-30012x6></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The signal handler chooses the next thread to run, re-enables the signal handler (the equivalent of re-enabling interrupts), and restores the new thread&#8217;s state from its TCB into the processor. execution with the state (newly) stored on the signal stack.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This approach virtualizes interrupts and processor exceptions, providing a user-level process with a very similar picture to the one the kernel gets when these events occur. </FONT><A id=x1-30013r55 name=x1-30013r55></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.3 </FONT><A id=x1-310003 name=x1-310003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing User-Level Threads With Kernel Support</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Today, most programs use kernel-supported threads rather than pure user-level threads. Major operating systems support threads using standard abstractions, so the issue of portability is less of an issue than it once was. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, various systems take more of a hybrid model, attempting to combine the lightweight performance and application control over scheduling found in user-level threads, while keeping many of the advantages of kernel threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Hybrid Thread Join.</B> Thread libraries can avoid transitioning to the kernel in certain cases. For example, rather than always making a system call for thread_join&nbsp;to wait for the target thread to finish, thread_exit&nbsp;can store its exit value in a data structure in the process&#8217;s address space. Then, if the call to thread_join&nbsp;happens after the targeted thread has exited, it can immediately return the value without having to make a system call. However, if the call to thread_join&nbsp;precedes the call to thread_exit, then a system call is needed to transition to the WAITING&nbsp;state and let some other thread run. As a further optimization, on a multiprocessor it can sometimes make sense for thread_join&nbsp;to spin for a few microseconds before entering the kernel, in the hope that the other thread will finish in the meantime. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Per-Processor Kernel Threads.</B> It is possible to adapt the green threads approach to work on a multiprocessor. For many parallel scientific applications, the cost of creating and synchronizing threads is paramount, and so an approach that requires a kernel call for most thread operations would be prohibitive. Instead, the library multiplexes user-level threads on top of kernel threads, in exactly the same way that the kernel multiplexes kernel threads on top of physical processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When the application starts up, the user-level thread library creates one kernel thread for each processor on the host machine. As long as there is no other activity on the system, the kernel will assign each of these threads a processor. Each kernel thread executes the user-level scheduler in parallel: pull the next thread off the user-level ready list, and run it. Because thread scheduling decisions occur at user level, they can be flexible and application-specific; for example, in a parallel graph algorithm, the programmer might adjust the priority of various threads based on the results of the computation on other parts of the graph. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Of course, most of the downsides of green threads are still present in these systems: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Any time a user-level thread calls into the kernel, its host kernel thread blocks. This prevents the thread library from running a different user-level thread on that processor in the meantime. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Any time the kernel time-slices a kernel thread, the user-level thread it was running is also suspended. The library cannot resume that thread until the kernel thread resumes.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Scheduler Activations.</B> To address these issues, some operating systems have added explicit support for user-level threads. One such model, implemented most recently in Windows, is called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:scheduler activations"}'>scheduler activations</A></EM>. In this approach, the user-level thread scheduler is notified (or activated) for every kernel event that might affect the user-level thread system. For example, if one thread blocks in a system call, the activation informs the user-level scheduler that it should choose another thread to run on that processor. Scheduler activations are like upcalls or signals, except that they do not return to the kernel; instead, they directly perform user-level thread suspend and resume. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Various operations trigger a scheduler activation upcall: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-31002x1 name=x1-31002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Increasing the number of virtual processors.</B> When a program starts, it receives an activation to inform the program that it has been assigned a virtual processor: that activation runs the main thread and any other threads that might be created. To assign another virtual processor to the program, the kernel makes another activation upcall on the new processor; the user-level scheduler can pull a waiting thread off the ready list and run it. </FONT></P>
<LI class=enumerate><A id=x1-31004x2 name=x1-31004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Decreasing the number of virtual processors.</B> When the kernel preempts a virtual processor (e.g., to give the processor to a different process), the kernel makes an upcall on one of the other processors assigned to the parallel program. The thread system can then move the preempted user-level thread onto the ready list, so that a different processor can run it. </FONT></P>
<LI class=enumerate><A id=x1-31006x3 name=x1-31006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition to WAITING.</B> When a user-level thread blocks in the kernel waiting for I/O, the kernel similarly makes an upcall to notify the user-level scheduler that it needs to take action, e.g., to choose another thread to run while waiting for the I/O to complete. </FONT></P>
<LI class=enumerate><A id=x1-31008x4 name=x1-31008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition from WAITING&nbsp;to READY.</B> When the I/O completes, the kernel makes an upcall to notify the scheduler that the suspended thread can be resumed. </FONT></P>
<LI class=enumerate><A id=x1-31010x5 name=x1-31010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition from RUNNING&nbsp;to idle.</B> When a user-level activation finds an empty ready list (i.e., it has no more work to do), it can make a system call into the kernel to return the virtual processor for use by some other process.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As a result, most thread management functions &#8212; thread_create, thread_yield, thread_exit, and thread_join, as well as the synchronization functions described in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> &#8212; are implemented as procedure calls within the process. Yet the user-level thread system always knows exactly how many virtual processors it has been assigned and is in complete control of what runs on those processors. </FONT><A id=x1-31011r53 name=x1-31011r53></A></P><A id=x1-320009 name=x1-320009><BR><BR><FONT style="BACKGROUND-COLOR: #7be1e1">