<STRONG>Operating Systems: Principles and Practice (Second Edition) Volume II : 4. Concurrency and Threads : </STRONG>
<P></P>
<H4 class=subsectionHead>4.8.3 <A id=x1-310003 name=x1-310003></A>Implementing User-Level Threads With Kernel Support</H4>
<P>Today, most programs use kernel-supported threads rather than pure user-level threads. Major operating systems support threads using standard abstractions, so the issue of portability is less of an issue than it once was. </P>
<P>However, various systems take more of a hybrid model, attempting to combine the lightweight performance and application control over scheduling found in user-level threads, while keeping many of the advantages of kernel threads. </P>
<P><SPAN class=extract><STRONG>Hybrid Thread Join. </STRONG><SPAN class=extract><SPAN class=extract>Thread libraries can avoid transitioning to the kernel in certain cases. For example, rather than always making a system call for thread_join&nbsp;to wait for the target thread to finish, thread_exit&nbsp;can store its exit value in a data structure in the process&#8217;s address space. Then, if the call to thread_join&nbsp;happens after the targeted thread has exited, it can immediately return the value without having to make a system call. However, if the call to thread_join&nbsp;precedes the call to thread_exit, then a system call is needed to transition to the WAITING&nbsp;state and let some other thread run. As a further optimization, on a multiprocessor it can sometimes make sense for thread_join&nbsp;to spin for a few microseconds before entering the kernel, in the hope that the other thread will finish in the meantime.</SPAN> </SPAN></SPAN></P><SPAN>
<P><STRONG>Per-Processor Kernel Threads. </STRONG>It is possible to adapt the green threads approach to work on a multiprocessor. For many parallel scientific applications, the cost of creating and synchronizing threads is paramount, and so an approach that requires a kernel call for most thread operations would be prohibitive. Instead, the library multiplexes user-level threads on top of kernel threads, in exactly the same way that the kernel multiplexes kernel threads on top of physical processors. </P>
<P>When the application starts up, the user-level thread library creates one kernel thread for each processor on the host machine. As long as there is no other activity on the system, the kernel will assign each of these threads a processor. Each kernel thread executes the user-level scheduler in parallel: pull the next thread off the user-level ready list, and run it. Because thread scheduling decisions occur at user level, they can be flexible and application-specific; for example, in a parallel graph algorithm, the programmer might adjust the priority of various threads based on the results of the computation on other parts of the graph. </P>
<P>Of course, most of the downsides of green threads are still present in these systems: </P>
<UL class=itemize1>
<LI class=itemize>
<P>Any time a user-level thread calls into the kernel, its host kernel thread blocks. This prevents the thread library from running a different user-level thread on that processor in the meantime. </P>
<LI class=itemize>
<P>Any time the kernel time-slices a kernel thread, the user-level thread it was running is also suspended. The library cannot resume that thread until the kernel thread resumes.</P></LI></UL>
<P><STRONG>Scheduler Activations. </STRONG>To address these issues, some operating systems have added explicit support for user-level threads. One such model, implemented most recently in Windows, is called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:scheduler activations"}'>scheduler activations</A></EM>. In this approach, the user-level thread scheduler is notified (or activated) for every kernel event that might affect the user-level thread system. For example, if one thread blocks in a system call, the activation informs the user-level scheduler that it should choose another thread to run on that processor. Scheduler activations are like upcalls or signals, except that they do not return to the kernel; instead, they directly perform user-level thread suspend and resume. </P>
<P>Various operations trigger a scheduler activation upcall: </P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-31002x1 name=x1-31002x1></A>
<P>Increasing the number of virtual processors. When a program starts, it receives an activation to inform the program that it has been assigned a virtual processor: that activation runs the main thread and any other threads that might be created. To assign another virtual processor to the program, the kernel makes another activation upcall on the new processor; the user-level scheduler can pull a waiting thread off the ready list and run it. </P>
<LI class=enumerate><A id=x1-31004x2 name=x1-31004x2></A>
<P>Decreasing the number of virtual processors. When the kernel preempts a virtual processor (e.g., to give the processor to a different process), the kernel makes an upcall on one of the other processors assigned to the parallel program. The thread system can then move the preempted user-level thread onto the ready list, so that a different processor can run it. </P>
<LI class=enumerate><A id=x1-31006x3 name=x1-31006x3></A>
<P>Transition to WAITING. When a user-level thread blocks in the kernel waiting for I/O, the kernel similarly makes an upcall to notify the user-level scheduler that it needs to take action, e.g., to choose another thread to run while waiting for the I/O to complete. </P>
<LI class=enumerate><A id=x1-31008x4 name=x1-31008x4></A>
<P>Transition from WAITING&nbsp;to READY. When the I/O completes, the kernel makes an upcall to notify the scheduler that the suspended thread can be resumed. </P>
<LI class=enumerate><A id=x1-31010x5 name=x1-31010x5></A>
<P>Transition from RUNNING&nbsp;to idle. When a user-level activation finds an empty ready list (i.e., it has no more work to do), it can make a system call into the kernel to return the virtual processor for use by some other process.</P></LI></OL>
<P>As a result, most thread management functions &#8212; thread_create, thread_yield, thread_exit, and thread_join, as well as the synchronization functions described in Chapter&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'>5</A> &#8212; are implemented as procedure calls within the process. Yet the user-level thread system always knows exactly how many virtual processors it has been assigned and is in complete control of what runs on those processors.<STRONG> </STRONG></P>
<P></SPAN><A id=x1-31011r53 name=x1-31011r53></A>&nbsp;</P><A id=x1-320009 name=x1-320009>