<STRONG><FONT style="BACKGROUND-COLOR: #7be1e1" color=blue>Operating Systems: Principles and Practice (Second Edition) Volume II : </FONT></STRONG>
<H2 class=chapter_name><I><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=headers>Title:</SPAN></B><SPAN class=RefText> Operating Systems: Principles and Practice (Second Edition) Volume II : 4. Concurrency and Threads</SPAN></FONT></FONT></I></H2></A>
<DIV class=chapterQuote>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Many hands make light work. &#8212;<I>John Heywood (1546)</I> </FONT></P>
<DL>
<DT><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT>
<DD><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></DD></DL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
<BR></FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In the real world &#8212; outside of computers &#8212; different activities often proceed at the same time. Five jazz musicians play their instruments while reacting to each other; one car drives north while another drives south; one part of a drug molecule is attracted to a cell&#8217;s receptor, while another part is repelled; a humanoid robot walks, raises its arms, and turns its head; you fetch one article from the <EM>New York Times</EM> website while someone else fetches another; or millions of people make long distance phone calls on Mother&#8217;s Day. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We use the word <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:concurrency"}'>concurrency</A></EM> to refer to multiple activities that can happen at the same time. The real world is concurrent, and internally, modern computers are also concurrent. For example, a high-end server might have more than a dozen processors, 10 disks, and 4 network interfaces; a workstation might have a dozen active I/O devices including a screen, keyboard, mouse, camera, microphone, speaker, wireless network interface, wired network interface, printer, scanner, and disk drive. Today, even mobile phones often have multi-core processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Correctly managing concurrency is a key challenge for operating system developers. To manage hardware resources, to provide responsiveness to users, and to run multiple applications simultaneously, the operating system needs a structured way of keeping track of the various actions it needs to perform. Over the next several chapters, we will present a set of abstractions for expressing and managing concurrency. These abstractions are in widespread use in commercial operating systems because they reduce implementation complexity, improve system reliability, and improve performance. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Concurrency is also a concern for many application developers. Although the abstractions we discuss were originally developed to make it easier to write correct operating system code, they have become widely used in applications: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Network services need to be able to handle multiple requests from their clients; a Google that could handle only one search request at a time, or an Amazon that could only allow one book to be bought at a time, would be much less useful. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Most applications today have user interfaces; providing good responsiveness to users while simultaneously executing application logic is much easier with a structured approach to concurrency. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Parallel programs need to be able to map work onto multiple processors to get the performance benefits of multicore architectures. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Data management systems need concurrency to mask the latency of disk and network operations.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">From the programmer&#8217;s perspective, it is much easier to think sequentially than to keep track of many simultaneous activities. For example, when reading or writing the code for a procedure, you can identify an initial state and a set of pre-conditions, think through how each successive statement changes the state, and from that determine the post-conditions. How can you write a correct program with dozens of events happening at once? </FONT><A id=x1-100011 name=x1-100011></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00388.gif" data-calibre-src="OEBPS/Images/image00388.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.1: </B>The operating system provides the illusion that programmers can create as many threads as they need, and each thread runs on its own dedicated virtual processor. In reality, of course, a machine only has a finite number of processors, and it is the operating system&#8217;s job to transparently multiplex threads onto the actual processors.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The key idea is to write a concurrent program &#8212; one with many simultaneous activities &#8212; as a set of sequential streams of execution, or <EM>threads</EM>, that interact and share results in very precise ways. Threads let us define a set of tasks that run concurrently while the code for each task is sequential. Each thread behaves as if it has its own dedicated processor, as illustrated in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100011"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. As we will see later, using the thread abstraction often requires the programmer to write additional code for coordinating multiple threads accessing shared data structures; we will discuss this topic in much more detail in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The thread abstraction lets the programmer create as many threads as needed without worrying about the exact number of physical processors, or exactly which processor is doing what at each instant. Of course, threads are only an abstraction: the physical hardware has a limited number of processors (and potentially only one!). The operating system&#8217;s job is to provide the illusion of a nearly infinite number of virtual processors even while the physical hardware is more limited. It sustains this illusion by transparently suspending and resuming threads so that at any given time only a subset of the threads are actively running. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This chapter will define the thread abstraction, illustrate how a programmer can use the abstraction, and explain how the operating system can implement threads on top of a limited number of processors. Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> explains how to coordinate threads when they operate on shared data, and Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-780006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> covers advanced issues when programming with threads. Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-1070007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> discusses the policy question: how should the operating system choose <EM>which</EM> thread to run next when there are more things to run than processors on which to run them. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Chapter roadmap:</B> The rest of this chapter discusses these topics in detail: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread Use Cases.</B> What are threads useful for? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-110001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread Abstraction.</B> What is the thread abstraction as seen by a programmer? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-130002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Simple Thread API.</B> How can programmers use threads? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-160003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread Data Structures.</B> What data structures does the operating system use to manage threads? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-190004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread Life Cycle.</B> What states does a thread go through between initialization and completion? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-220005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementing Kernel Threads.</B> How do we implement the thread abstraction inside the operating system kernel? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-230006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Combining Kernel Threads and Single-Threaded User Processes.</B> How do we extend the implementation of kernel threads to support simple single-threaded processes? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-270007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementing Multi-threaded Processes.</B> How do we implement the thread abstraction for multi-threaded applications? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-280008"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Alternative Abstractions.</B> What other abstractions can we use to express and implement concurrency? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-320009"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.9</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Deja vu all over again?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Threads are widely used, and several modern programming languages directly support writing programs with multiple threads. You may have programmed with threads before or have taken classes that talk about using threads. What is new here? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The discussion in this book is designed to make sense even if you have never seen threads before. If you have seen threads before, great! But we still think you will find the discussion useful. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Beyond describing the basic thread abstraction, we emphasize two points in this chapter and the following ones. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementation.</B> We will describe how operating systems implement threads both for their own use and for use by user-level applications. It is important to understand how threads really work so that you can understand their costs and performance characteristics and can use them effectively. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Practice.</B> We will present a methodology for writing correct multi-threaded programs. Concurrency is increasingly important in many programming tasks, but writing correct multi-threaded programs requires much more care and discipline than writing correct single-threaded programs. That said, following a few simple rules that we will describe can greatly simplify the process of writing robust multi-threaded code. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Multithreaded programming has a well-deserved reputation for being difficult, but we believe the ideas in this chapter and the subsequent ones can help almost anyone become better at programming with threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-10002r1 name=x1-10002r1></A><A id=x1-110001 name=x1-110001>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.1 Thread Use Cases</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">The intuition behind the thread abstraction is simple: in a program, we can represent each concurrent task as a <EM>thread</EM>. Each thread provides the abstraction of sequential execution similar to the traditional programming model. In fact, we can think of a traditional program as <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:single-threaded program"}'>single-threaded</A></EM> with one logical sequence of steps as each instruction follows the previous one. The program executes statements, iterates through loops, and calls/returns from procedures one after another. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:multi-threaded program"}'>multi-threaded program</A></EM> is a generalization of the same basic programming model. Each individual thread follows a single sequence of steps as it executes statements, iterates through loops, calls/returns from procedures, etc. However, a program can now have several such threads executing at the same time. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When is it appropriate to use multiple threads within the same program? Threads have become widely used in both operating system and application code, and based on that experience, we can identify several common themes. We illustrate these themes by describing one application in some detail, to show how and why it leverages threads. </FONT><A id=x1-110012 name=x1-110012></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00389.gif" data-calibre-src="OEBPS/Images/image00389.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.2: </B>In the Earth Visualizer example, two threads each draw part of the scene, a third thread manages the user interface widgets, and a fourth thread fetches new data from a remote server. Satellite Image Credit: NASA Earth Observatory.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Consider an Earth Visualizer application similar to Google Earth (</FONT><A href="http://earth.google.com/"><FONT style="BACKGROUND-COLOR: #7be1e1">http://earth.google.com/</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">). This application lets a user virtually fly anywhere in the world, see aerial images at different resolutions, and view other information associated with each location. A key part of the design is that the user&#8217;s controls are always operable: when the user moves the mouse to a new location, the image is redrawn in the background at successively better resolutions while the program continues to let the user adjust the view, select additional information about the location for display, or enter search terms. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To implement this application, as Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-110012"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates, the programmer might write code to draw a portion of the screen, display user interface (UI) widgets, process user inputs, and fetch higher resolution images for newly visible areas. In a sequential program, these functions would run in turn. With threads, they can run concurrently so that the user interface is responsive even while new data is being fetched and the screen being redrawn. </FONT><A id=x1-11002r1 name=x1-11002r1></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.1.1 </FONT><A id=x1-120001 name=x1-120001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Four Reasons to Use Threads</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Using threads to express and manage concurrency has several advantages: </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Program structure: expressing logically concurrent tasks.</B> Programs often interact with or simulate real-world applications that have concurrent activities. Threads let you express an application&#8217;s natural concurrency by writing each concurrent task as a separate thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In the Earth Visualizer application, threads let different activities &#8212; updating the screen, fetching additional data, and receiving new user inputs &#8212; run at the same time. For example, to get mouse input while also re-drawing the screen and sending and receiving packets off the network, the physical processors need to split their time among these tasks. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although one could imagine manually writing a program that interleaves these activities (e.g., draw a few pixels on the screen, then check to see if the user has moved the mouse, then check to see if new image data have arrived on the network, . . . ), using threads greatly simplifies concurrent code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Another example is on the server side of the Earth Visualizer. The server needs to manage the requests of a large number of clients, each focused on a different point on the planet. Since the clients are likely behind a wide variety of access link technologies (e.g., from dialup to gigabit Ethernet), it would slow everyone down if each request needed to be completely handled before the server could start on the next one. By creating a separate thread for each client, the computation and networking needed for that client can be intermixed with other clients, without affecting the logical structure of the program. This design pattern &#8212; one server thread per client &#8212; is common; for example, the popular Apache web server assigns each client its own thread when it first connects to the server. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Responsiveness: shifting work to run in the background.</B> To improve user responsiveness and performance, a common design pattern is to create threads to perform work in the background, without the user waiting for the result. This way, the user interface can remain responsive to further commands, regardless of the complexity of the user request. In a web browser, for example, the cancel button should continue to work even (or especially!) if the downloaded page is gigantic or a script on the page takes a long time to execute. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">How does this work? Many applications have a loop: get a user command, then execute the command, then get the next command. If some commands take a long time to perform, however, an application that executes everything sequentially will not be able to check for the next operation until the previous one completes. To keep the interface responsive, we can use threads to split each command into two parts: anything that can be done instantly can be done in the main event loop, and a separate thread can perform the rest of the task in the background. In the Earth Visualizer example, we used threads to move the computationally difficult parts of the application logic &#8212; rendering the display &#8212; out of the main loop. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Operating system kernels make extensive use of threads to preserve responsiveness. Many operating systems are designed so that the common case is fast. For example, when writing a file, the operating system stores the modified data in a kernel buffer, and returns immediately to the application. In the background, the operating system kernel runs a separate thread to flush the modified data out to disk. Another example is on file reads: the kernel can have a thread which attempts to anticipate which blocks are likely to be read next (e.g., if the application is reading a large file from beginning to end), and to bring those blocks from disk before the application asks for them. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance: exploiting multiple processors.</B> Programs can use threads on a multiprocessor to do work in parallel; they can do the same work in less time or more work in the same elapsed time. Today, a server might have more than a dozen processors; a desktop or laptop may include eight processor cores; even most smartphones are multicore machines. Looking forward, Moore&#8217;s law makes it likely that the number of processors per system will continue to increase. An advantage to using threads for parallelism is that the number of threads need not exactly match the number of processors in the hardware on which it is running. The operating system transparently switches which threads run on which processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For an 8-processor machine, you could parallelize the Earth Visualizer application by splitting the demanding job of rendering different portions of the image on the screen across six threads. Then, the operating system could run those six rendering threads on six processors and run the various other threads on the two remaining processors to update the on-screen navigation widgets, construct the network messages needed to fetch additional images from the distant servers, and parse reply messages. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance: managing I/O devices.</B> To do useful work, computers must interact with the outside world via I/O devices. By running tasks as separate threads, when one task is waiting for I/O, the processor can make progress on a different task. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The benefit of concurrency between the processor and the I/O is two-fold: First, processors are often much faster than the I/O systems with which they interact, so keeping the processor idle during I/O would waste much of its capacity. For example, the latency to read from disk can be tens of milliseconds, enough to execute more than 10 million instructions on a modern processor. After requesting a block from disk, the operating system can switch to another program, or another thread within the same program, until the disk completes and the original thread is ready to resume. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Second, I/O provides a way for the computer to interact with external entities, such as users pressing keys on a keyboard or a remote computer sending network packets. The arrival of this type of I/O event is unpredictable, so the processor must be able to work on other tasks while still responding quickly to these external events. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In the Earth Visualizer application, a snappy user interface is essential, but much of the imagery is stored on remote servers and fetched by the application only when needed. The application provides a responsive experience when a user changes location by first downloading a small, low-resolution view of the new location. While rendering those images with one thread, another thread simultaneously fetches progressively higher-resolution images, allowing the rendering thread to update the view as the higher-resolution images arrive. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Threads vs. processes</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In Chapter&nbsp;2, we described a process as the execution of a program with restricted rights. A thread is an independent sequence of instructions running within a program. Perhaps the best way to see how these concepts are related, is to see how different operating systems combine them in different ways: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>One thread per process.</B> A simple single-threaded application has one sequence of instructions, executing from beginning to end. The operating system kernel runs those instructions in user mode to restrict access to privileged operations or system memory. The process performs system calls to ask the kernel to perform privileged operations on its behalf. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Many threads per process.</B> Alternately, a program may be structured as several concurrent threads, each executing within the restricted rights of the process. At any given time, a subset of the process&#8217;s threads may be running, while the rest are suspended. Any thread running in a process can make system calls into the kernel, blocking that thread until the call returns but allowing other threads to continue to run. Likewise, when the processor gets an I/O interrupt, it preempts one of the running threads so the kernel can run the interrupt handler; when the handler finishes, the kernel resumes that thread. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Many single-threaded processes.</B> As recently as twenty years ago, many operating systems supported multiple processes but only one thread per process. To the kernel, however, each process looks like a thread: a separate sequence of instructions, executing sometimes in the kernel and sometimes at user level. For example, on a multiprocessor, if multiple processes perform system calls at the same time, the kernel, in effect, has multiple threads executing concurrently in kernel mode. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Many kernel threads.</B> To manage complexity, shift work to the background, exploit parallelism, and hide I/O latency, the operating system kernel itself can benefit from using multiple threads. In this case, each kernel thread runs with the privileges of the kernel: it can execute privileged instructions, access system memory, and issue commands directly to I/O devices. The operating system kernel itself implements the thread abstraction for its own use. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Because of the usefulness of threads, almost all modern operating systems support both multiple threads per process and multiple kernel threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-12001r22 name=x1-12001r22></A><A id=x1-130002 name=x1-130002>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.2 Thread Abstraction</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Thus far, we have described what a thread is and why it is useful. Before we go farther, we must define the thread abstraction and its properties more precisely. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:thread"}'>thread</A></EM> is <EM>a single execution sequence</EM> that represents <EM>a separately schedulable task</EM>. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Single execution sequence.</B> Each thread executes a sequence of instructions &#8212; assignments, conditionals, loops, procedures, and so on &#8212; just as in the familiar sequential programming model. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Separately schedulable task.</B> The operating system can run, suspend, or resume a thread at any time. </FONT></P></LI></UL><A id=x1-13001r24 name=x1-13001r24></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.2.1 </FONT><A id=x1-140001 name=x1-140001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Running, Suspending, and Resuming Threads</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Threads provide the illusion of an infinite number of processors. How does the operating system implement this illusion? It must execute instructions from each thread so that each thread makes progress, but the underlying hardware has only a limited number of processors, and perhaps only one! </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To map an arbitrary set of threads to a fixed set of processors, operating systems include a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:thread scheduler"}'>thread scheduler</A></EM> that can switch between threads that are running and those that are ready but not running. For example, in the previous Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100011"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, a scheduler might suspend thread 1 from processor 1, move it to the list of ready threads, and then resume thread 5 by moving it from the ready list to run on processor 1. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Switching between threads is transparent to the code being executed within each thread. The abstraction makes each thread appear to be a single stream of execution; this means the programmer can pay attention to the sequence of instruction within a thread and not whether or when that sequence may be (temporarily) suspended to let another thread run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Threads thus provide an execution model in which <EM>each thread runs on a dedicated virtual processor with unpredictable and variable speed.</EM> From the point of view of a thread&#8217;s code, each instruction appears to execute immediately after the preceding one. However, the scheduler may suspend a thread between one instruction and the next and resume running it later. It is as if the thread were running on a processor that sometimes becomes very slow. </FONT><A id=x1-140013 name=x1-140013></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00390.gif" data-calibre-src="OEBPS/Images/image00390.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.3: </B>Three possible ways that a thread might execute, all of which are equivalent to the programmer.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-140013"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates a programmer&#8217;s view of a simple program and three (of many) possible ways the program might be executed, depending on what the scheduler does. From the thread&#8217;s point of view, other than the speed of execution, the alternatives are equivalent. Indeed, the thread would typically be unaware of which of these (or other) executions actually occurs. </FONT><A id=x1-140024 name=x1-140024></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00391.gif" data-calibre-src="OEBPS/Images/image00391.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.4: </B>Some of the many possible ways that three threads might be interleaved at runtime.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">How threads are scheduled affects a thread&#8217;s interleavings with other threads. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-140024"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows some of the many possible interleavings of a program with three threads. Thread programmers should therefore not make any assumptions about the relative speed with which different threads execute. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Cooperative vs. preemptive multi-threading</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although most thread systems include a scheduler that can &#8212; at least in principle &#8212; run any thread at any time, some systems provide the abstraction of <EM>cooperative threads</EM>. In these systems, a thread runs without interruption until it explicitly relinquishes control of the processor to another thread. An advantage of cooperative multi-threading is increased control over the interleavings among threads. For example, in most cooperative multi-threading systems, only one thread runs at a time, so while a thread is running, no other thread can run and affect the system&#8217;s state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Unfortunately, cooperative multi-threading has significant disadvantages. For example, a long-running thread can monopolize the processor, starving other threads and making the system&#8217;s user interface sluggish or non-responsive. Additionally, modern multiprocessor machines run multiple threads at a time, so one would still have to reason about the possible interactions between threads even if cooperative multi-threading were used. Thus, although cooperative multi-threading was used in some significant systems in the past, including early versions of Apple&#8217;s MacOS operating system, it is less often used today. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The alternative we describe in this book is sometimes called <EM>preemptive multi-threading</EM> since running threads can be switched at any time. Whenever the book uses the term &#8220;multi-threading,&#8221; it means preemptive multi-threading unless we explicitly state otherwise. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-14003r26 name=x1-14003r26></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.2.2 </FONT><A id=x1-150002 name=x1-150002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Why &#8220;Unpredictable Speed&#8221;?</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">It may seem strange to require programmers to assume that a thread&#8217;s virtual processor runs at an unpredictable speed and that any interleaving with other threads is possible. Surely, the programmer should be able to take advantage of the fact that some interleavings are more likely than others? </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The thread programming model adopts this assumption as a way to guide programmers when reasoning about correctness. Rather than assuming that one thread runs at the same speed as another (or faster or slower) and trying to write programs that coordinate threads based on their relative speed of execution, multi-threaded programs should make no assumptions about the behavior of the thread scheduler. In turn, the kernel&#8217;s scheduling decisions &#8212; when to assign a thread to a processor, and when to preempt it for a different thread &#8212; can be made without worrying whether they might affect program correctness. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If threads are completely independent of each other, sharing no memory or other resources, then the order of execution will not matter &#8212; any schedule will produce the same output as any other. Most multi-threaded programs share data structures, however. In this case, as Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> describes, the programmer must use explicit synchronization to ensure program correctness regardless of the possible interleaving of instructions of different threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Even if we could ignore the issue of scheduling &#8212; e.g., if there are more processors than threads so that each thread is assigned its own physical processor &#8212; the physical reality is that the relative execution speed of different threads can be significantly affected by factors outside their control. An extreme example is that the programmer may be debugging one thread by single-stepping it, while other threads run at full speed on other processors. If the programmer is to have any hope of understanding concurrent program behavior, the program&#8217;s correctness cannot depend on which threads are being observed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Variability in execution speed occurs during normal operation as well. Accessing memory can stall a processor for hundreds or thousands of cycles if a cache miss occurs. Other factors include how frequently the scheduler preempts the thread, how many physical processors are present on a machine, how large the caches are, how fast the memory is, how the energy-saving firmware adjusts the processors&#8217; clock speeds, what network messages arrive, or what input is received from the user. Execution speeds for the different threads of a program are hard to predict, can vary on different hardware, and can even vary from run to run on the same hardware. As a result, we must coordinate thread actions through explicit synchronization rather than by trying to reason about their relative speed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Is a kernel interrupt handler a thread? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>No, an interrupt handler is not a thread.</B> A kernel interrupt handler shares some resemblance to a thread: it is a single sequence of instructions that executes from beginning to end. However, an interrupt handler is not independently schedulable: it is triggered by a hardware I/O event, rather than a decision by the thread scheduler in the kernel. Once started, the interrupt handler runs to completion, unless preempted by another (higher priority) interrupt. &#9633; </FONT><A id=x1-15001r25 name=x1-15001r25></A></P><A id=x1-160003 name=x1-160003>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.3 Simple Thread API</FONT></H3></A><A id=x1-160015 name=x1-160015></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td colSpan=2 align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=multicolumn align=center noWrap><B><FONT style="BACKGROUND-COLOR: #7be1e1">Simple Threads API</FONT></B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">void thread_create (thread, func, arg)</FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Create a new thread, storing information about it in thread. Concurrently with the calling thread, thread executes the function func with the argument arg. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">void thread_yield ()</FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The calling thread voluntarily gives up the processor to let some other thread(s) run. The scheduler can resume running the calling thread whenever it chooses to do so. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">int thread_join (thread)</FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Wait for thread to finish if it has not already done so; then return the value passed to thread_exit by that thread. Note that thread_join may be called only once for each thread. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">void thread_exit (ret)</FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Finish the current thread. Store the value ret in the current thread&#8217;s data structure. If another thread is already waiting in a call to thread_join, resume it. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.5: </B>Simplified API for using threads.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
Figure </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-160015"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows a simple API for using threads. This simplified API is based on the POSIX standard pthreads API, but it omits some POSIX options and error handling for simplicity. Most other thread packages are quite similar; if you understand how to program with this API, you will find it easy to write code with most standard thread APIs. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A good way to understand the simple threads API is that it provides a way to invoke an <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:asynchronous procedure call"}'>asynchronous procedure call</A></EM>. A normal procedure call passes a set of arguments to a function, runs the function immediately on the caller&#8217;s stack, and when the function is completed, returns control back to the caller with the result. An asynchronous procedure call separates the call from the return: with thread_create, the caller starts the function, but unlike a normal procedure call, the caller continues execution concurrently with the called function. Later, the caller can wait for the function completion (with thread_join). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In Chapter&nbsp;3, we saw similar concepts in the UNIX process abstraction. thread_create&nbsp;is analogous to UNIX process fork and exec, while thread_join&nbsp;is analogous to UNIX process wait. UNIX fork creates a new process that runs concurrently with the process calling fork; UNIX exec causes that process to run a specific program. UNIX wait allows the calling process to suspend execution until the completion of the new process. </FONT><A id=x1-16002r29 name=x1-16002r29></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.3.1 </FONT><A id=x1-170001 name=x1-170001></A><FONT style="BACKGROUND-COLOR: #7be1e1">A Multi-Threaded Hello World</FONT></H4><A id=x1-170016 name=x1-170016></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;#include&nbsp;&lt;stdio.h&gt;
&nbsp;#include&nbsp;"thread.h"
&nbsp;
&nbsp;static&nbsp;void&nbsp;go(int&nbsp;n);
&nbsp;
&nbsp;#define&nbsp;NTHREADS&nbsp;10
&nbsp;static&nbsp;thread_t&nbsp;threads[NTHREADS];
&nbsp;
&nbsp;int&nbsp;main(int&nbsp;argc,&nbsp;char&nbsp;**argv)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;i;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;long&nbsp;exitValue;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;NTHREADS;&nbsp;i++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_create(&amp;(threads[i]),&nbsp;&amp;go,&nbsp;i);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;NTHREADS;&nbsp;i++){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exitValue&nbsp;=&nbsp;thread_join(threads[i]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Thread&nbsp;%d&nbsp;returned&nbsp;with&nbsp;%ld\n",
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i,&nbsp;exitValue);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Main&nbsp;thread&nbsp;done.\n");
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;0;
&nbsp;}
&nbsp;
&nbsp;void&nbsp;go(int&nbsp;n)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Hello&nbsp;from&nbsp;thread&nbsp;%d\n",&nbsp;n);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_exit(100&nbsp;+&nbsp;n);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Not&nbsp;reached
&nbsp;}
</FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;%&nbsp;./threadHello
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;0
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;1
&nbsp;Thread&nbsp;0&nbsp;returned&nbsp;100
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;3
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;4
&nbsp;Thread&nbsp;1&nbsp;returned&nbsp;101
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;5
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;2
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;6
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;8
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;7
&nbsp;Hello&nbsp;from&nbsp;thread&nbsp;9
&nbsp;Thread&nbsp;2&nbsp;returned&nbsp;102
&nbsp;Thread&nbsp;3&nbsp;returned&nbsp;103
&nbsp;Thread&nbsp;4&nbsp;returned&nbsp;104
&nbsp;Thread&nbsp;5&nbsp;returned&nbsp;105
&nbsp;Thread&nbsp;6&nbsp;returned&nbsp;106
&nbsp;Thread&nbsp;7&nbsp;returned&nbsp;107
&nbsp;Thread&nbsp;8&nbsp;returned&nbsp;108
&nbsp;Thread&nbsp;9&nbsp;returned&nbsp;109
&nbsp;Main&nbsp;thread&nbsp;done.
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.6: </B>Example multi-threaded program using the simple threads API that prints &#8220;Hello&#8221; ten times. Also shown is the output of one possible run of this program.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
To illustrate how to use the simple threads API, Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows a very simple multi-threaded program written in &#8217;C&#8217;. The main function uses thread_create&nbsp;to create 10 threads. The interesting arguments are the second and third. </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The second argument, go, is a function pointer &#8212; where the newly created thread should begin execution. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The third argument, i, is passed to that function.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thus, thread_create&nbsp;initializes the i&#8217;th thread&#8217;s state so that it is prepared to call the function go with the argument i. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When the scheduler runs the i&#8217;th thread, that thread runs the function go with the value i as an argument and prints Hello from thread i. The thread then returns the value (i + 100) by calling thread_exit. This call stores the specified value in a field in the thread_t object so that thread_join&nbsp;can retrieve it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The main function uses thread_join&nbsp;to wait for each of the threads it created. As each thread finishes, code in main reads the thread&#8217;s exit value and prints it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Why might the &#8220;Hello&#8221; message from thread 2 print <EM>after</EM> the &#8220;Hello&#8221; message for thread 5, even though thread 2 was created before thread 5? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>Creating and scheduling threads are separate operations.</B> Although threads are usually scheduled in the order that they are created, there is no guarantee. Further, even if thread 2 started running before thread 5, it might be preempted before it reaches the printf call. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Rather, the only assumption the programmer can make is that each of the threads runs on its own virtual processor with unpredictable speed. Any interleaving is possible. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Why must the &#8220;Thread returned&#8221; message from thread 2 print <EM>before</EM> the Thread returned message from thread 5? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>Since the threads run on virtual processors with unpredictable speeds, the order in which the threads finish is indeterminate. However, <B>the main thread checks for thread completion in the order they were created.</B> It calls thread_join&nbsp;for thread i +1 only after thread_join&nbsp;for thread i has returned. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What is the <EM>minimum</EM> and <EM>maximum</EM> number of threads that could exist when thread 5 prints &#8220;Hello?&#8221; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>When the program starts, a main thread begins running main. That thread creates NTHREADS = 10 threads. All of those could run and complete before thread 5 prints &#8220;Hello.&#8221; Thus, <B>the minimum is two threads</B> &#8212; the main thread and thread 5. On the other hand, all 10 threads could have been created, while 5 was the first to run. Thus, <B>the maximum is 11 threads.</B> &#9633; </FONT><A id=x1-17002r32 name=x1-17002r32></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.3.2 </FONT><A id=x1-180002 name=x1-180002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Fork-Join Parallelism</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Although the interface in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-160015"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> is simple, it is remarkably powerful. Many multi-threaded applications can be designed using only these thread operations and no additional synchronization. With <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:fork-join parallelism"}'>fork-join parallelism</A></EM>, a thread can create child threads to perform work (&#8220;fork&#8221;, or thread_create), and it can wait for their results (&#8220;join&#8221;). Data may be safely shared between threads, provided it is (a) written by the parent before the child thread starts or (b) written by the child and read by the parent after the join. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If these sharing restrictions are followed, each thread executes independently and in a deterministic fashion, unaffected by the behavior of any other concurrently executing thread. The multiplexing of threads onto processors has no effect other than performance. </FONT><A id=x1-180017 name=x1-180017></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;To&nbsp;pass&nbsp;two&nbsp;arguments,&nbsp;we&nbsp;need&nbsp;a&nbsp;struct&nbsp;to&nbsp;hold&nbsp;them.
&nbsp;typedef&nbsp;struct&nbsp;bzeroparams&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;unsigned&nbsp;char&nbsp;*buffer;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;length;
&nbsp;};
&nbsp;
&nbsp;#define&nbsp;NTHREADS&nbsp;10
&nbsp;
&nbsp;void&nbsp;go&nbsp;(struct&nbsp;bzeroparams&nbsp;*p)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memset(p-&gt;buffer,&nbsp;0,&nbsp;p-&gt;length);
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Zero&nbsp;a&nbsp;block&nbsp;of&nbsp;memory&nbsp;using&nbsp;multiple&nbsp;threads.
&nbsp;void&nbsp;blockzero&nbsp;(unsigned&nbsp;char&nbsp;*p,&nbsp;int&nbsp;length)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;i;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_t&nbsp;threads[NTHREADS];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;struct&nbsp;bzeroparams&nbsp;params[NTHREADS];
&nbsp;
&nbsp;//&nbsp;For&nbsp;simplicity,&nbsp;assumes&nbsp;length&nbsp;is&nbsp;divisible&nbsp;by&nbsp;NTHREADS.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert((length&nbsp;%&nbsp;NTHREADS)&nbsp;==&nbsp;0);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;NTHREADS;&nbsp;i++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;params[i].buffer&nbsp;=&nbsp;p&nbsp;+&nbsp;i&nbsp;*&nbsp;length/NTHREADS;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;params[i].length&nbsp;=&nbsp;length/NTHREADS;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_create_p(&amp;(threads[i]),&nbsp;&amp;go,&nbsp;&amp;params[i]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;NTHREADS;&nbsp;i++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_join(threads[i]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.7: </B>Routine to zero a contiguous region of memory in parallel using multiple threads. To pass two arguments (the pointer to the buffer and the length of the buffer) to the child thread, the program passes a pointer to a struct holding the two parameters.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: Parallel block zero.</B> A simple example of fork-join parallelism in operating systems is the procedure to zero a contiguous block of memory. To prevent unintentional data leakage, whenever a process exits, the operating system must zero the memory that had been allocated to the exiting process. Otherwise, a new process may be re-assigned the memory, enabling it to read potentially sensitive data. For example, an operating system&#8217;s remote login program might temporarily store a user&#8217;s password in memory, but the next process to use the same physical memory might be a memory-scanning program launched by a different, malicious user. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For a large process, parallelizing the zeroing function can make sense. Zeroing 1 GB of memory takes about 50 milliseconds on a modern computer; by contrast, creating and starting a new thread takes a few tens of microseconds. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-180017"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates the code for a parallel zero function using fork-join parallelism. The multi-threaded blockzero creates a set of threads and assigns each a disjoint portion of the memory region; the region is empty when all threads have completed their work. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In practice, the operating system will often create a thread to run blockzero in the background. The memory of an exiting process does not need to be cleared until the memory is needed &#8212; that is, when the next process is created. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To exploit this flexibility, the operating system can create a set of low priority threads to run blockzero. The kernel can then return immediately and resume running application code. Later on, when the memory is needed, the kernel can call thread_join. If the zero is complete by that point, the join will return immediately; otherwise, it will wait until the memory is safe to use. </FONT><A id=x1-18002r30 name=x1-18002r30></A></P><A id=x1-190004 name=x1-190004>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.4 Thread Data Structures and Life Cycle</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">As we have seen, each thread represents a sequential stream of execution. The operating system provides the illusion that each thread runs on its own virtual processor by transparently suspending and resuming threads. For the illusion to work, the operating system must precisely save and restore the state of a thread. However, because threads run either in a process or in the kernel, there is also <EM>shared</EM> state that is not saved or restored when switching the processor between threads. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thus, to understand how the operating system implements the thread abstraction, we must define both the per-thread state and the state that is shared among threads. Then we can describe a thread&#8217;s life cycle &#8212; how the operating system can create, start, stop, and delete threads to provide the abstraction. </FONT><A id=x1-190018 name=x1-190018></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00392.gif" data-calibre-src="OEBPS/Images/image00392.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.8: </B>A multi-threaded process or operating system kernel has both <EM>per-thread state</EM> and <EM>shared state</EM>. The thread control block stores the per-thread state: the current state of the thread&#8217;s computation (e.g., saved processor registers and a pointer to the stack) and metadata needed to manage the thread (e.g., the thread&#8217;s ID, scheduling priority, owner, and resource consumption). Shared state includes the program&#8217;s code, global static variables, and the heap.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><A id=x1-19002r34 name=x1-19002r34></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.4.1 </FONT><A id=x1-200001 name=x1-200001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Per-Thread State and Thread Control Block (TCB)</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The operating system needs a data structure to represent a thread&#8217;s state; a thread is like any other object in this regard. This data structure is called the <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:thread control block"}'>thread control block</A></EM> (TCB). For every thread the operating system creates, it creates one TCB. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The thread control block holds two types of per-thread information: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-20002x1 name=x1-20002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The state of the computation being performed by the thread. </FONT></P>
<LI class=enumerate><A id=x1-20004x2 name=x1-20004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Metadata about the thread that is used to manage the thread.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Per-thread Computation State.</B> To create multiple threads and to be able to start and stop each thread as needed, the operating system must allocate space in the TCB for the current state of each thread&#8217;s computation: a pointer to the thread&#8217;s stack and a copy of its processor registers. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Stack.</B> A thread&#8217;s stack is the same as the stack for a single-threaded computation &#8212; it stores information needed by the nested procedures the thread is currently running. For example, if a thread calls foo(), foo() calls bar(), and bar() calls bas(), then the stack would contain a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:stack frame"}'>stack frame</A></EM> for each of these three procedures; each stack frame contains the local variables used by the procedure, the parameters the procedure was called with, and the return address to jump to when the procedure completes. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Because at any given time different threads can be in different states in their sequential computations &#8212; each can be in a different place in a different procedure called with different arguments from a different nesting of enclosing procedures &#8212; each thread needs its own stack. When a new thread is created, the operating system allocates it a new stack and stores a pointer to that stack in the thread&#8217;s TCB. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Copy of processor registers.</B> A processor&#8217;s registers include not only its general-purpose registers for storing intermediate values for ongoing computations, but they also include special-purpose registers, such as the instruction pointer and stack pointer. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To be able to suspend a thread, run another thread, and later resume the original thread, the operating system needs a place to store a thread&#8217;s registers when that thread is not actively running. In some systems, the general-purpose registers for a stopped thread are stored on the top of the stack, and the TCB contains only a pointer to the stack. In other systems, the TCB contains space for a copy of all processor registers.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>How big a stack?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An implementation question for thread systems is: how large a stack should be allocated for each thread? A stack grows and shrinks as procedure calls are made and those calls return. The size of the stack must be large enough to accommodate the deepest nesting level needed during in the thread&#8217;s lifetime. With hundreds or thousands of threads, it can be wasteful to allocate more than the minimum needed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Most modern operating systems allocate kernel stacks in physical memory, putting space at a premium. However, the maximum procedure nesting depth in the kernel is usually small. Thus, kernels typically allocate a very small fixed sized region for each thread stack, e.g., 8 KB by default in Linux on an Intel x86. The kernel stays within this bound due to an important kernel coding convention: buffers and data structures are always allocated on the heap and never as procedure local variables. Although most programming languages allow arbitrary data structures to be defined as procedure local or &#8220;automatic&#8221; &#8212; allocated when a procedure starts and de-allocated when the procedure exits &#8212; that can cause problems when the stack is of limited size. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">User-level stacks are allocated in virtual memory and so there is less need for a tight space constraint. In a single threaded process, the stack is located at the top end of the address space, where it can grow nearly without bound. To catch program errors, most operating systems will trigger an error if the user program stack grows too large too quickly, as that is usually an indication of unbounded recursion, rather than something that was the programmer&#8217;s intent. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In a multi-threaded user application, it is not possible to have each stack grow without constraint. Although some programming languages, such as Google&#8217;s Go, will automatically grow the stack as needed, this is still uncommon. POSIX allows the default stack size to be library dependent (e.g., larger on a desktop machine, smaller on a smartphone). As one POSIX thread tutorial put it dryly, &#8220;Exceeding the default stack limit is often very easy to do, with the usual results: program termination and/or corrupted data.&#8221;&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "Xbarney"}'><FONT style="BACKGROUND-COLOR: #7be1e1">10</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. Most implementations try to detect when programs exceed the default stack limit by placing a known value at the very top and bottom of the stack to serve as a guard. The guard values can be checked on every context switch; if the value changes, it is likely the thread exceeded its stack. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To support application portability, the POSIX thread standard allows the user to redefine the default stack size to whatever is needed for the correct execution of a particular program. The thread library provided with the textbook sets the default stack size to 1 MB. This is almost certainly large enough provided you adopt the kernel approach of never putting large data objects on the stack. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Per-thread Metadata.</B> The TCB also includes <EM>per-thread metadata</EM> &#8212; information for managing the thread. For example, each thread might have a thread ID, scheduling priority, and status (e.g., whether the thread is waiting for an event or is ready to be placed onto a processor). </FONT><A id=x1-20005r38 name=x1-20005r38></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.4.2 </FONT><A id=x1-210002 name=x1-210002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Shared State</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">As opposed to per-thread state that is allocated for each thread, some state is <EM>shared</EM> between threads running in the same process or within the operating system kernel (Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-190018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">). In particular, program <EM>code</EM> is shared by all threads in a process, although each thread may be executing at a different place within that code. Additionally, statically allocated <EM>global variables</EM> and dynamically allocated <EM>heap variables</EM> can store information that is accessible to all threads. </FONT>
<P></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Other per-thread state: Thread-local variables</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In addition to the per-thread state that corresponds to execution state in the single-threaded case, some systems include additional <EM>thread-local variables</EM>. These variables are similar to global variables in that their scope spans different procedures, but they differ in that each thread has its own copy of these variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Consider these examples: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Errno.</B> In UNIX, the return value of system calls is intentionally kept simple. For example, the UNIX read system call returns either the number of bytes read (if successful) or -1 (if there was a problem). Often, an application needs additional information about the cause of the error (e.g., permission error, disk offline, etc.). To provide this, the kernel sets a variable in the application memory, the errno, with a diagnostic code for the most recent system call. As UNIX originally had only one thread per process, there was no confusion: the errno referred to the most recent system call of that process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In a multi-threaded program, however, multiple threads can perform system calls concurrently. Rather than redefine the entire UNIX system call interface for a multi-threaded environment, errno is now a macro that maps to a thread-local variable containing the error code for that thread&#8217;s most recent system call. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Heap internals.</B> Although a program&#8217;s heap is logically shared &#8212; it is acceptable for one thread to allocate an object on the heap and then pass a pointer to that object to another thread &#8212; for performance reasons heaps may internally subdivide their space into per-thread regions. The advantage of subdividing the heap is that multiple threads can each allocate objects at the same time without interfering with one another. Further, by allocating objects used by the same thread from the same memory region, cache hit rates may improve. To implement these optimizations, each subdivision of the heap has thread-local variables that track what parts of the thread-local heap are in use, what parts are free, and so on. Then, the code that allocates new memory (e.g., malloc and new) is written to use these thread-local data structures and only take memory from the shared heap if the local heap is empty.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thread-local variables are often useful, but, for simplicity, the rest of our discussion focuses only on the TCB, registers, and stack as the core pieces of per-thread state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: Although there is an important logical division between per-thread state and shared state, the operating system typically does not enforce this division. Nothing prevents one buggy thread from accessing another thread&#8217;s (conceptually private) per-thread state. Writing to a bad pointer in one thread can corrupt the stack of another. Or a careless programmer might pass a pointer to a local variable on one thread&#8217;s stack to another thread, giving the second thread a pointer to a stack location whose contents may change as the first thread calls and returns from various procedures. Or the first thread can exit after handing out a pointer to a variable on its stack; the heap will reassign that memory to an unrelated purpose. Because these bugs can depend on the specific interleavings of the threads&#8217; executions, they can be extremely hard to locate and correct. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To avoid unexpected behaviors, it is therefore important when writing multi-threaded programs to know which variables are designed to be shared across threads (global variables, objects on the heap) and which are designed to be private (local/automatic variables). </FONT><A id=x1-21001r36 name=x1-21001r36></A></P><A id=x1-220005 name=x1-220005>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.5 Thread Life Cycle</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">It is useful to consider the progression of states as a thread goes from being created, to being scheduled and de-scheduled onto and off of a processor, and then to exiting. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-220019"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.9</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the states of a thread during its lifetime. </FONT><A id=x1-220019 name=x1-220019></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00393.gif" data-calibre-src="OEBPS/Images/image00393.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.9: </B>The states of a thread during its lifetime.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>INIT.</B> Thread creation puts a thread into its INIT&nbsp;state and allocates and initializes per-thread data structures. Once that is done, thread creation code puts the thread into the READY&nbsp;state by adding the thread to the <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:ready list"}'>ready list</A></EM>. The ready list is the set of runnable threads that are waiting their turn to use a processor. In practice, as discussed in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-1070007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the ready list is not in fact a &#8220;list&#8221;; the operating system typically uses a more sophisticated data structure to keep track of runnable threads, such as a priority queue. Nevertheless, following convention, we will continue to refer to it as the ready list. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>READY.</B> A thread in the <EM>READY</EM> state is available to be run but is not currently running. Its TCB is on the ready list, and the values of its registers are stored in its TCB. At any time, the scheduler can cause a thread to transition from READY&nbsp;to RUNNING&nbsp;by copying its register values from its TCB to a processor&#8217;s registers. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>RUNNING.</B> A thread in the <EM>RUNNING</EM> state is running on a processor. At this time, its register values are stored on the processor rather than in the TCB. A RUNNING&nbsp;thread can transition to the READY&nbsp;state in two ways: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The scheduler can preempt a running thread and move it to the READY&nbsp;state by: (1) saving the thread&#8217;s registers to its TCB and (2) switching the processor to run the next thread on the ready list. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A running thread can voluntarily relinquish the processor and go from RUNNING&nbsp;to READY&nbsp;by calling yield (e.g., thread_yield&nbsp;in the thread library). </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Notice that a thread can transition from READY&nbsp;to RUNNING&nbsp;and back many times. Since the operating system saves and restores the thread&#8217;s registers exactly, only the speed of the thread&#8217;s execution is affected by these transitions. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: By convention in this book, a thread that is RUNNING&nbsp;is not on the ready list; the ready list is for READY&nbsp;and not RUNNING&nbsp;threads. However, some operating systems, such as Linux, use a different convention, where the RUNNING&nbsp;thread is whichever thread is at the front of the ready list. Either convention is equivalent as long as it used consistently. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WAITING.</B> A thread in the <EM>WAITING</EM> state is waiting for some event. Whereas the scheduler can move a thread in the READY&nbsp;state to the RUNNING&nbsp;state, a thread in the WAITING&nbsp;state cannot run until some action by another thread moves it from WAITING&nbsp;to READY. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The threadHello program in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> provides an example of a WAITING&nbsp;thread. After creating its children threads, the main thread must wait for them to complete, by calling thread_join&nbsp;once for each child. If the specific child thread is not yet done at the time of the join, the main thread goes from RUNNING&nbsp;to WAITING&nbsp;until the child thread exits. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">While a thread waits for an event, it cannot make progress; therefore, it is not useful to run it. Rather than continuing to run the thread or storing the TCB on the scheduler&#8217;s ready list, the TCB is stored on the <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:waiting list"}'>waiting list</A></EM> of some <EM>synchronization variable</EM> associated with the event. When the required event occurs, the operating system moves the TCB from the synchronization variable&#8217;s waiting list to the scheduler&#8217;s ready list, transitioning the thread from WAITING&nbsp;to READY. We describe synchronization variables in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>FINISHED.</B> A thread in the FINISHED&nbsp;state never runs again. The system can free some or all of its state for other uses, though it may keep some remnants of the thread in the FINISHED&nbsp;state for a time by putting the TCB on a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:finished list"}'>finished list</A></EM>. For example, the thread_exit&nbsp;call lets a thread pass its exit value to its parent thread via thread_join. Eventually, when a thread&#8217;s state is no longer needed (e.g., after its exit value has been read by the join call), the system can delete and reclaim the thread&#8217;s state. </FONT><A id=x1-2200210 name=x1-2200210></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>State of Thread</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Location of Thread Control Block (TCB)</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Location of Registers</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">INIT </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Being Created </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">READY </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Ready List </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">RUNNING </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Running List </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Processor </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">WAITING </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Synchronization Variable&#8217;s Waiting List </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">FINISHED </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">Finished List then Deleted </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">TCB or Deleted </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.10: </B>Location of thread&#8217;s per-thread state for different life cycle stages.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One way to understand these states is to consider where a thread&#8217;s TCB and registers are stored, as shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2200210"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.10</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. For example, all threads in the READY&nbsp;state have their TCBs on the ready list and their registers in the TCB. All threads in the RUNNING&nbsp;state have their TCBs on the running list and their register values in hardware registers. And all threads in the WAITING&nbsp;state have their TCBs on various synchronization variables&#8217; waiting lists. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>The idle thread</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If a system has k processors, most operating systems ensure that there are exactly k RUNNING&nbsp;threads, by keeping a low priority <EM>idle thread</EM> per processor for when there is nothing else to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">On old machines, the idle thread would spin in a tight loop doing nothing. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Today, the idle thread still spins in a loop, but to save power, on each iteration it puts the processor into a low-power sleep mode. In sleep mode, the processor stops executing instructions until a hardware interrupt occurs. Then, the processor wakes up and handles the interrupt in the normal way &#8212; saving the state of the currently running thread (the idle thread) and running the handler. After running the handler, a thread waiting for that I/O event may now be READY. If so, the scheduler runs that thread next; otherwise, the idle thread resumes execution, putting the processor to sleep again. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Having a low-power idle thread also helps when running the operating system inside a virtual machine. Obviously, it would be inefficient for an idle operating system to consume processing cycles that could be better used by another virtual machine on the same system. Putting the processor into sleep mode is a privileged instruction, so if the operating system is running inside a virtual machine, the hardware will trap to the host kernel. The host kernel can then switch to a different virtual machine. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>For the threadHello program in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, when thread_join&nbsp;returns for thread i, what is thread i&#8217;s thread state? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>When join returns, thread i has finished running and exited. The runtime system saved the exit value in the TCB and moved the TCB to the finished list (so that its exit value can be found by the parent thread). <B>The thread is thus in the FINISHED&nbsp;state.</B> &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>For the threadHello program, what is the minimum and maximum number of times that the main thread enters the READY&nbsp;state on a <EM>uniprocessor</EM>? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>The main thread must go into the READY&nbsp;state when it is first created; otherwise, it would never be scheduled. On a uniprocessor, it must also give up the processor (e.g., due to a time slice or in thread_join) in order for its children threads to run. The children threads could then completely run before the main thread is re-scheduled. Once the children have finished, the main thread can run to completion. Thus, <B>the minimum number of times is two.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>The maximum number of times is (near) infinite.</B> A running thread can be preempted and re-scheduled many times, without affecting the correctness of the execution. In the limit, the thread could conceivably be preempted after each instruction! &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Where is my TCB?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A remarkably tricky implementation question is how to find the current thread&#8217;s TCB. The thread library needs access to the current TCB for a number of reasons, e.g., to change its priority or to access thread-local variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One might think finding the TCB would be simple: just store a pointer to the TCB in a global variable. However, recall that every thread running in the same process uses exactly the same code, and therefore each thread would look in exactly the same place for the TCB. On a uniprocessor, this works: the global variable can hold the value of the current TCB, and the library can change the value whenever it switches between threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This does not work on a multiprocessor, however. Some systems, such as the Intel x86, have hardware support for fetching the ID of the current processor. In these systems, the thread library can maintain a global array of pointers, with the i&#8217;th entry pointing to the TCB of the thread running on the i&#8217;th processor. A running thread can then find its TCB by looking up its processor ID and then finding the corresponding entry in the array. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For systems without this feature, however, there is another approach: the stack pointer is always unique to each thread. The thread library can store a pointer to the thread TCB at the very bottom of the stack, underneath the procedure frames. (Some systems take this one step farther, and put the entire TCB at the bottom of the stack.) As long as thread stacks are aligned to start at a fixed block boundary, the low order bits of the current stack pointer can be masked to locate the pointer to the current TCB. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-22003r40 name=x1-22003r40></A><A id=x1-230006 name=x1-230006>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.6 Implementing Kernel Threads</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">So far, we have described the basic data structures and operation of threads. We now describe how to implement them. The specifics of the implementation vary depending on the context: </FONT><A id=x1-2300111 name=x1-2300111></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00394.gif" data-calibre-src="OEBPS/Images/image00394.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.11: </B>A multi-threaded kernel with three kernel threads and two single-threaded user-level processes. Each kernel thread has its own TCB and its own stack. Each user process has a stack at user-level for executing user code and a kernel interrupt stack for executing interrupts and system calls.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><A id=x1-2300212 name=x1-2300212></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00395.gif" data-calibre-src="OEBPS/Images/image00395.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.12: </B>A multi-threaded kernel with three kernel threads and two user-level processes, each with two threads. Each user-level thread has a user-level stack and an interrupt stack in the kernel for executing interrupts and system calls.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Kernel threads.</B> The simplest case is implementing threads inside the operating system kernel, sharing one or more physical processors. A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:kernel thread"}'>kernel thread</A></EM> executes kernel code and modifies kernel data structures. Almost all commercial operating systems today support kernel threads. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Kernel threads and single-threaded processes.</B> An operating system with kernel threads might also run some single-threaded user processes. As shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2300111"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.11</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, these processes can invoke system calls that run concurrently with kernel threads inside the kernel. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Multi-threaded processes using kernel threads.</B> Most operating systems provide a set of library routines and system calls to allow applications to use multiple threads within a single user-level process. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2300212"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.12</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates this case. These threads execute user code and access user-level data structures. They also make system calls into the operating system kernel. For that, they need a kernel interrupt stack just like a normal single-threaded process. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>User-level threads.</B> To avoid having to make a system call for every thread operation, some systems support a model where user-level thread operations &#8212; create, yield, join, exit, and the synchronization routines described in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> &#8212; are implemented entirely in a user-level library, without invoking the kernel.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We first describe the implementation for the baseline case of kernel threads. In Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-280008"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, we explain how to extend the model to support application multi-threading implemented with kernel threads or with a user-level library. </FONT><A id=x1-23003r39 name=x1-23003r39></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.6.1 </FONT><A id=x1-240001 name=x1-240001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Creating a Thread</FONT></H4><A id=x1-2400113 name=x1-2400113></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;func&nbsp;is&nbsp;a&nbsp;pointer&nbsp;to&nbsp;a&nbsp;procedure&nbsp;the&nbsp;thread&nbsp;will&nbsp;run.
&nbsp;//&nbsp;arg&nbsp;is&nbsp;the&nbsp;argument&nbsp;to&nbsp;be&nbsp;passed&nbsp;to&nbsp;that&nbsp;procedure.
&nbsp;void
&nbsp;thread_create(thread_t&nbsp;*thread,&nbsp;void&nbsp;(*func)(int),&nbsp;int&nbsp;arg)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Allocate&nbsp;TCB&nbsp;and&nbsp;stack
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*tcb&nbsp;=&nbsp;new&nbsp;TCB();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread-&gt;tcb&nbsp;=&nbsp;tcb;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;stack_size&nbsp;=&nbsp;INITIAL_STACK_SIZE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;stack&nbsp;=&nbsp;new&nbsp;Stack(INITIAL_STACK_SIZE);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Initialize&nbsp;registers&nbsp;so&nbsp;that&nbsp;when&nbsp;thread&nbsp;is&nbsp;resumed,&nbsp;it&nbsp;will&nbsp;start&nbsp;running&nbsp;at
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;stub.&nbsp;&nbsp;The&nbsp;stack&nbsp;starts&nbsp;at&nbsp;the&nbsp;top&nbsp;of&nbsp;the&nbsp;allocated&nbsp;region&nbsp;and&nbsp;grows&nbsp;down.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;sp&nbsp;=&nbsp;tcb-&gt;stack&nbsp;+&nbsp;INITIAL_STACK_SIZE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;pc&nbsp;=&nbsp;stub;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;a&nbsp;stack&nbsp;frame&nbsp;by&nbsp;pushing&nbsp;stub&#8217;s&nbsp;arguments&nbsp;and&nbsp;start&nbsp;address
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;onto&nbsp;the&nbsp;stack:&nbsp;func,&nbsp;arg
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*(tcb-&gt;sp)&nbsp;=&nbsp;arg;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;sp--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*(tcb-&gt;sp)&nbsp;=&nbsp;func;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;sp--;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;another&nbsp;stack&nbsp;frame&nbsp;so&nbsp;that&nbsp;thread_switch&nbsp;works&nbsp;correctly.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;This&nbsp;routine&nbsp;is&nbsp;explained&nbsp;later&nbsp;in&nbsp;the&nbsp;chapter.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_dummySwitchFrame(tcb);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;state&nbsp;=&nbsp;READY;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readyList.add(tcb);&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Put&nbsp;tcb&nbsp;on&nbsp;ready&nbsp;list
&nbsp;}
&nbsp;
&nbsp;void
&nbsp;stub(void&nbsp;(*func)(int),&nbsp;int&nbsp;arg)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(*func)(arg);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Execute&nbsp;the&nbsp;function&nbsp;func()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_exit(0);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;func()&nbsp;does&nbsp;not&nbsp;call&nbsp;exit,&nbsp;&nbsp;call&nbsp;it&nbsp;here.
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.13: </B>Pseudo-code for thread creation. The specifics of initializing the stack and the conventions for passing arguments to the initial function are machine-dependent. On the Intel x86 architecture, the stack starts at high addresses and grows down, while arguments are passed on the stack. On other systems, the stack can grow upwards and/or arguments can be passed in registers. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2600114"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.14</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> provides pseudo-code for thread_dummySwitchFrame.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2400113"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.13</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the pseudo-code to allocate a new thread. The goal of thread_create&nbsp;is to perform an asynchronous procedure call to func with arg as the argument to that procedure. When the thread runs, it will execute func(arg) concurrently with the calling thread. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">There are three steps to creating a thread: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-24003x1 name=x1-24003x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Allocate per-thread state.</B> The first step in the thread constructor is to allocate space for the thread&#8217;s per-thread state: the TCB and stack. As we have mentioned, the TCB is the data structure the thread system uses to manage the thread. The stack is an area of memory for storing data about in-progress procedures; it is allocated in memory like any other data structure. </FONT></P>
<LI class=enumerate><A id=x1-24005x2 name=x1-24005x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Initialize per-thread state.</B> To initialize the TCB, the thread constructor sets the new thread&#8217;s registers to what they need to be when the thread starts RUNNING. When the thread is assigned a processor, we want it to start running func(arg). However, instead of having the thread start in func, the constructor starts the thread in a dummy function, stub, which in turn calls func. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We need this extra step in case the func procedure returns instead of calling thread_exit. Without the stub, func would return to whatever random location is stored at the top of the stack! Instead, func returns to stub and stub calls thread_exit&nbsp;to finish the thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To start at the beginning of stub, the thread constructor sets up the stack as if stub was just called by normal code; the specifics will depend on the calling convention of the machine. In the pseudo-code, we push stub&#8217;s two arguments onto the stack: func and arg. When the thread starts running, the code in stub will access its arguments just like a normal procedure. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In addition, we also push a dummy stack frame for thread_switch&nbsp;onto the stack; we defer an explanation of this detail until we discuss the implementation of thread switching. </FONT></P>
<LI class=enumerate><A id=x1-24007x3 name=x1-24007x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Put TCB on ready list.</B> The last step in creating a thread is to set its state to READY&nbsp;and put the new TCB on the ready list, enabling the thread to be scheduled.</FONT></P></LI></OL><A id=x1-24008r46 name=x1-24008r46></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.6.2 </FONT><A id=x1-250002 name=x1-250002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Deleting a Thread</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">When a thread calls thread_exit, there are two steps to deleting the thread: </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Remove the thread from the ready list so that it will never run again. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Free the per-thread state allocated for the thread.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although this seems easy, there is an important subtlety: if a thread removes itself from the ready list and frees its own per-thread state, then the program may break. For example, if a thread removes itself from the ready list but an interrupt occurs before the thread finishes de-allocating its state, there is a memory leak: that thread will never resume to de-allocate its state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Worse, suppose that a thread frees its own state? Can the thread finish running the code in thread_exit&nbsp;if it does not have a stack? What happens if an interrupt occurs just after the running thread&#8217;s stack has been de-allocated? If the context switch code tries to save the current thread&#8217;s state, it will be writing to de-allocated memory, possibly to storage that another processor has re-allocated for some other data structure. The result could be corrupted memory, where the specific behavior depends on the precise sequence of events. Needless to say, such a bug would be very difficult to locate. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Fortunately, there is a simple fix: a thread never deletes its own state. Instead, some other thread must do it. On exit, the thread transitions to the FINISHED&nbsp;state, moves its TCB from the ready list to a list of <EM>finished</EM> threads the scheduler should never run. The thread can then safely switch to the next thread on the ready list. Once the finished thread is no longer running, it is safe for some <EM>other</EM> thread to free the state of the thread. </FONT><A id=x1-25001r48 name=x1-25001r48></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.6.3 </FONT><A id=x1-260003 name=x1-260003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Thread Context Switch</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">To support multiple threads, we also need a mechanism to switch which threads are RUNNING&nbsp;and which are READY. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:thread context switch"}'>thread context switch</A></EM> suspends execution of a currently running thread and resumes execution of some other thread. The switch saves the currently running thread&#8217;s registers to the thread&#8217;s TCB and stack, and then it restores the new thread&#8217;s registers from that thread&#8217;s TCB and stack into the processor. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We need to answer several questions: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">What triggers a context switch? </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">How does a voluntary context switch (e.g., a call to thread_yield) work? </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">How does an involuntary context switch differ from a voluntary one? </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">What thread should the scheduler choose to run next?</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We discuss these in turn, but we defer the last question to Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-1070007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. The <EM>mechanisms</EM> we discuss in this Chapter work regardless of the <EM>policy</EM> the scheduler uses when choosing threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Separating mechanism from policy</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Separating mechanism from policy is a useful and widely applied principle in operating system design. When mechanism and policy are cleanly separated, it is easier to introduce new policies to optimize a system for a new workload or new technology. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, the thread context switch abstraction cleanly separates mechanism (how to switch between threads) from policy (which thread to run) so that the mechanism works no matter what policy is used. Some systems can elect to do something simple (e.g., FIFO scheduling); other systems can optimize scheduling to meet their goals (e.g., a periodic scheduler to smoothly run real-time multimedia streams for a media device, a round-robin scheduler to balance responsiveness and throughput for a server, or a priority scheduler that devotes most resources to the visible application on a smartphone). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We will see this principle many times in this book. For example, thread synchronization mechanisms work regardless of the scheduling policy; file metadata mechanisms for locating a file&#8217;s blocks work regardless of the policy for where to place the file&#8217;s blocks on disk; and page translation mechanisms for mapping virtual to physical addresses work regardless of which physical pages the operating system assigns to each process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>What Triggers a Kernel Thread Context Switch?</B> A thread context switch can be triggered by either a voluntary call into the thread library, or an involuntary interrupt or processor exception. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Voluntary.</B> The thread could call a thread library function that triggers a context switch. For example, most thread libraries provide a thread_yield&nbsp;call that lets the currently running thread voluntarily give up the processor to the next thread on the ready list. Similarly, the thread_join&nbsp;and thread_exit&nbsp;calls suspend execution of the current thread and start running a different one. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Involuntary.</B> An <EM>interrupt</EM> or <EM>processor exception</EM> could invoke an interrupt handler. The interrupt hardware saves the state of the running thread and executes the handler&#8217;s code. The handler can decide that some other thread should run, and then switch to it. Alternatively, if the current thread should continue running, the handler restores the state of the interrupted thread and resumes execution. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, many thread systems are designed to ensure that no thread can monopolize the processor. To accomplish this, they set a hardware timer to interrupt the processor periodically (e.g., every few milliseconds). The timer interrupt handler saves the state of the running thread, chooses another thread to run, and runs that thread by restoring its state to the processor. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Other I/O hardware events (e.g., a keyboard key is pressed, a network packet arrives, or a disk operation completes) also invoke interrupt handlers. In these cases as well, the handlers save the state of the currently running thread so that it can be restored later. They then execute the handler code, and when the handler is done, they either restore the state of the current thread, or switch to a new thread. A new thread will be run if the I/O event moves a thread onto the ready list with a higher priority than the previously running thread.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Regardless, the thread system must save the current processor state, so that when the current thread resumes execution, it appears <EM>to the thread</EM> as if the event never occurred except for some time having elapsed. This provides the abstraction of thread execution on a virtual processor with unpredictable and variable speed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To keep things simple, we do not want to do an involuntary context switch while we are in the middle of a voluntary one. When switching between two threads, we need to temporarily defer interrupts until the switch is complete, to avoid confusion. Processors contain privileged instructions to defer and re-enable interrupts; we make use of these in our implementation below. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Why is it necessary to turn off interrupts during thread switch?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Our implementation of thread_yield&nbsp;defers any interrupts that might occur during the procedure, until the yield is complete. This might seem unnecessary: after all, even if the thread context switch is interrupted, the state of the switch will be saved onto the stack. Eventually the kernel will re-schedule the thread, restore its state, and complete the thread switch. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, a subtle inconsistency might arise. Suppose a low priority thread (e.g., the idle thread) is about to voluntarily switch to a high priority thread. It pulls the high priority thread off the ready list, and at that precise moment, an interrupt occurs. Supppose the interrupt moves a medium priority thread from WAITING&nbsp;to READY. Since it appears that the processor is still running the low priority thread, the interrupt handler immediately switches to the new thread. The high priority thread is in limbo! It is ready to run, but unable to do so until the low priority thread is re-scheduled. And that may not happen for a long time. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Of course, this sequence of events would not occur very often, but when it does, it would be difficult to locate or debug. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Voluntary Kernel Thread Context Switch.</B> Because a voluntary switch is simpler to understand, we start there. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2600114"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.14</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows pseudo-code for a simple implementation of thread_yield&nbsp;for the Intel x86 hardware architecture. A thread calls thread_yield&nbsp;to voluntarily relinquish the processor to another thread. The calling thread&#8217;s registers are copied to its TCB and stack, and it resumes running later, when the scheduler chooses it. </FONT><A id=x1-2600114 name=x1-2600114></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;We&nbsp;enter&nbsp;as&nbsp;oldThread,&nbsp;but&nbsp;we&nbsp;return&nbsp;as&nbsp;newThread.
&nbsp;//&nbsp;Returns&nbsp;with&nbsp;newThread&#8217;s&nbsp;registers&nbsp;and&nbsp;stack.
&nbsp;void&nbsp;thread_switch(oldThreadTCB,&nbsp;newThreadTCB)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pushad;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Push&nbsp;general&nbsp;register&nbsp;values&nbsp;onto&nbsp;the&nbsp;old&nbsp;stack.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldThreadTCB-&gt;sp&nbsp;=&nbsp;%esp;&nbsp;//&nbsp;Save&nbsp;the&nbsp;old&nbsp;thread&#8217;s&nbsp;stack&nbsp;pointer.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;%esp&nbsp;=&nbsp;newThreadTCB-&gt;sp;&nbsp;//&nbsp;Switch&nbsp;to&nbsp;the&nbsp;new&nbsp;stack.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;popad;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Pop&nbsp;register&nbsp;values&nbsp;from&nbsp;the&nbsp;new&nbsp;stack.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;
&nbsp;}
&nbsp;
&nbsp;void&nbsp;thread_yield()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*chosenTCB,&nbsp;*finishedTCB;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Prevent&nbsp;an&nbsp;interrupt&nbsp;from&nbsp;stopping&nbsp;us&nbsp;in&nbsp;the&nbsp;middle&nbsp;of&nbsp;a&nbsp;switch.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Choose&nbsp;another&nbsp;TCB&nbsp;from&nbsp;the&nbsp;ready&nbsp;list.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chosenTCB&nbsp;=&nbsp;readyList.getNextThread();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(chosenTCB&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Nothing&nbsp;else&nbsp;to&nbsp;run,&nbsp;so&nbsp;go&nbsp;back&nbsp;to&nbsp;running&nbsp;the&nbsp;original&nbsp;thread.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Move&nbsp;running&nbsp;thread&nbsp;onto&nbsp;the&nbsp;ready&nbsp;list.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;ready;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readyList.add(runningThread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_switch(runningThread,&nbsp;chosenTCB);&nbsp;//&nbsp;Switch&nbsp;to&nbsp;the&nbsp;new&nbsp;thread.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;running;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Delete&nbsp;any&nbsp;threads&nbsp;on&nbsp;the&nbsp;finished&nbsp;list.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;((finishedTCB&nbsp;=&nbsp;finishedList-&gt;getNextThread())&nbsp;!=&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete&nbsp;finishedTCB-&gt;stack;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete&nbsp;finishedTCB;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;thread_create&nbsp;must&nbsp;put&nbsp;a&nbsp;dummy&nbsp;frame&nbsp;at&nbsp;the&nbsp;top&nbsp;of&nbsp;its&nbsp;stack:
&nbsp;//&nbsp;the&nbsp;return&nbsp;PC&nbsp;and&nbsp;space&nbsp;for&nbsp;pushad&nbsp;to&nbsp;have&nbsp;stored&nbsp;a&nbsp;copy&nbsp;of&nbsp;the&nbsp;registers.
&nbsp;//&nbsp;This&nbsp;way,&nbsp;when&nbsp;someone&nbsp;switches&nbsp;to&nbsp;a&nbsp;newly&nbsp;created&nbsp;thread,
&nbsp;//&nbsp;the&nbsp;last&nbsp;two&nbsp;lines&nbsp;of&nbsp;thread_switch&nbsp;work&nbsp;correctly.
&nbsp;void&nbsp;thread_dummySwitchFrame(newThread)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*(tcb-&gt;sp)&nbsp;=&nbsp;stub;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Return&nbsp;to&nbsp;the&nbsp;beginning&nbsp;of&nbsp;stub.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;sp--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tcb-&gt;sp&nbsp;-=&nbsp;SizeOfPopad;
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.14: </B>Pseudo-code for thread_switch&nbsp;and thread_yield&nbsp;on the Intel x86 architecture. Note that thread_yield&nbsp;is a no-op if there are no other threads to run. Otherwise, it saves the old thread state and restores the new thread state. When the old thread is re-scheduled, it returns from thread_switch&nbsp;as the running thread.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The pseudo-code for thread_yield&nbsp;first turns off interrupts to prevent the thread system from attempting to make two context switches at the same time. The pseudo-code then pulls the next thread to run off the ready list (if any), and switches to it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The thread_switch&nbsp;code may seem tricky, since it is called in the context of the old thread and finishes in the context of the new thread. To make this work, thread_switch&nbsp;saves the state of the registers to the stack and saves the stack pointer to the TCB. It then switches to the stack of the new thread, restores the new thread&#8217;s state from the new thread&#8217;s stack, and returns to whatever program counter is stored on the new stack. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A twist is that the return location may not be to thread_yield! The return is to whatever the new thread was doing beforehand. For example, the new thread might have been WAITING&nbsp;in thread_join&nbsp;and is now READY&nbsp;to run. The thread might have called thread_yield. Or it might be a newly created thread just starting to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">It is essential that any routine that causes the thread to yield or block call thread_switch&nbsp;in the same way. Equally, to create a new thread, thread_create&nbsp;must set up the stack of the new thread to be as if it had suspended execution just before performing its first instruction. Then, if the newly created thread is the next thread to run, a thread can call thread_yield, switch to the newly created thread, switch to its stack pointer, pop the register values off the stack, and &#8220;return&#8221; to the new thread, even though it had never called switch in the first place. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Suppose two threads each loop, calling thread_yield&nbsp;on each iteration. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;go()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while(1)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_yield();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">What is the sequence of steps as seen by the physical processor and by each thread? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>From the processor&#8217;s point of view, one instruction follows the next, but now the instructions from different threads are interleaved (as they must be if they are multiplexed). </FONT></P>
<P><B><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2600215"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.15</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the interleaving:</FONT></B><FONT style="BACKGROUND-COLOR: #7be1e1"> thread_yield&nbsp;is called by one thread but returns in a different thread. thread_yield&nbsp;deliberately violates the procedure call conventions compilers normally follow by manipulating the stack and program counter to switch between threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, the threads themselves can ignore this complexity. From their point of view, they each run this loop on their own (variable-speed) virtual processor. &#9633; </FONT><A id=x1-2600215 name=x1-2600215></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td colSpan=3 align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=multicolumn align=center noWrap><B><FONT style="BACKGROUND-COLOR: #7be1e1">Logical View</FONT></B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread 1</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread 2</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">go(){ </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">go(){ </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; while(1){ </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; while(1){ </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp; thread_yield(); </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp; thread_yield(); </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; } </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; } </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">} </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">} </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR>
<TR class=tr>
<TD class=td colSpan=3 align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=multicolumn align=center noWrap><B><FONT style="BACKGROUND-COLOR: #7be1e1">Physical Reality</FONT></B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><B><FONT style="BACKGROUND-COLOR: #7be1e1">Thread 1&#8217;s instructions </FONT></B></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread 2&#8217;s instructions</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Processor&#8217;s instructions</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&#8220;return&#8221; from thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&#8220;return&#8221; from thread_switch</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; into stub </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; into stub </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call go </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call go</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 1 state to TCB </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 1 state to TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 2 state </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 2 state</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&#8220;return&#8221; from thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&#8220;return&#8221; from thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; into stub </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; into stub </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call go </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call go </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 2 state to TCB </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 2 state to TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 1 state </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 1 state </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 1 state to TCB </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 1 state to TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 2 state </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 2 state </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">choose another thread </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">call thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 2 state to TCB </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">save thread 2 state to TCB </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 1 state </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load thread 1 state </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_switch </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">return from thread_yield </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">... </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">... </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">... </FONT></P></TD></TR></TBODY></TABLE></DIV>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.15: </B>Interleaving of instructions when two threads loop and call thread_yield().</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>A zero-thread kernel</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Not only can we have a single-threaded kernel or a multi-threaded kernel, it is actually possible to have a kernel with no threads of its own &#8212; a zero-threaded kernel! In fact, this used to be quite common&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XLions:1996:LCU"}'><FONT style="BACKGROUND-COLOR: #7be1e1">107</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Consider the simple picture of the operating system described in Chapter&nbsp;2. Once the system has booted, initialized its device drivers, and started some user-level processes like a login shell, everything else the kernel does is event-driven, i.e., done in response to an interrupt, processor exception, or system call. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In a simple operating system like this, there is no need for a &#8220;kernel thread&#8221; or &#8220;kernel thread control block&#8221; to keep track of an ongoing computation. Instead, when an interrupt, trap, or exception occurs, the stack pointer gets set to the base of the interrupt stack, and the instruction pointer gets set to the address of the handler. Then, the handler executes and either returns immediately to the interrupted user-level process or suspends the user-level process and &#8220;returns&#8221; to some other user-level process. In either case, the next event (interrupt, processor exception, or system call) starts this process anew. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Involuntary Kernel Thread Context Switch.</B> Chapter&nbsp;2 explained what happens when an interrupt, exception, or trap interrupts a running user-level process: hardware and software work together to save the state of the interrupted process, run the kernel&#8217;s handler, and restore the state of the interrupted process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The mechanism is almost identical when an interrupt or trap triggers a thread switch between threads in the kernel. The three steps described in Chapter&nbsp;2 are slightly modified (<EM>changes are written in italics</EM>): </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-26004x1 name=x1-26004x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Save the state.</B> Save the currently running <EM>thread&#8217;s</EM> registers so that the handler can run code without disrupting the interrupted <EM>thread</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Hardware saves some state when the interrupt or exception occurs, and software saves the rest of the state when the handler runs. </FONT></P>
<LI class=enumerate><A id=x1-26006x2 name=x1-26006x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Run the kernel&#8217;s handler.</B> Run the kernel&#8217;s handler code to handle the interrupt or exception. <EM>Since we are already in kernel mode, we do not need to change from user to kernel mode in this step.</EM> <EM>We also do not need to change the stack pointer to the base of the kernel&#8217;s interrupt stack. Instead, we can just push saved state or handler variables onto the current stack, starting from the current stack pointer.</EM> </FONT></P>
<LI class=enumerate><A id=x1-26008x3 name=x1-26008x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Restore the state.</B> Restore the <EM>next ready thread&#8217;s</EM> registers so that the thread can resume running where it left off. </FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In short, comparing a switch between kernel threads to what happens on a user-mode transfer: (1) there is no need to switch modes (and therefore no need to switch stacks) and (2) the handler can resume any thread on the ready list rather than always resuming the thread or process that was just suspended. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementation Details.</B> On most processor architectures, a simple (but inefficient) way to swap to the next thread from within an interrupt handler is to call thread_switch&nbsp;just before the handler returns. As we have already seen, thread_switch&nbsp;saves the state of the current thread (that is, the state of the interrupt handler) and switches to the new kernel thread. When the original thread resumes, it will return from thread_switch, and immediately pop the interrupt context off the stack, resuming execution at the point where it was interrupted. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Most systems, such as Linux, make a small optimization to improve interrupt handling performance. The state of the interrupted thread is already saved on the stack, albeit in the format specified by the interrupt hardware. If we modify thread_switch&nbsp;to save and restore registers exactly as the interrupt hardware does, then returning from an interrupt and resuming a thread are the same action: they both pop the interrupt frame off the stack to resume the next thread to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, to be compatible with x86 interrupt hardware, the software implementation of thread_switch&nbsp;would simulate the hardware case, saving the return instruction pointer and eflags register before calling pushad to save the general-purpose registers. After switching to the new stack, it would call iret to resume the new thread, whether the new thread was suspended by a hardware event or a software call. </FONT><A id=x1-26009r43 name=x1-26009r43></A></P><A id=x1-270007 name=x1-270007>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.7 Combining Kernel Threads and Single-Threaded User Processes</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Previously, Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2300111"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.11</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrated a system with both kernel threads and single-threaded user processes. A process is a sequential execution of instructions, so each user-level process includes the process&#8217;s thread. However, a process is more than just a thread because it has its own address space. Process 1 has its own view of memory, its own code, its own heap, and its own global variables that differ from those of process 2 (and from the kernel&#8217;s). </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Because a process contains more than just a thread, each process&#8217;s process control block (PCB) needs more information than a thread control block (TCB) for a kernel thread. Like a TCB, a PCB for a single-threaded process must store the processor registers when the process&#8217;s thread is not running. In addition, the PCB has information about the process&#8217;s address space; when a context switch occurs from one process to another, the operating system must change the virtual memory mappings as well as the register state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since the PCB and TCB each represent one thread, the kernel&#8217;s ready list can contain a mix of PCBs for processes and TCBs for kernel threads. When the scheduler chooses the next thread to run, it can pick either kind. A thread switch is nearly identical whether switching between kernel threads or switching between a process&#8217;s thread and a kernel thread. In both cases, the switch saves the state of the currently running thread and restores the state of the next thread to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As we mentioned in Chapter&nbsp;2, most operating systems dedicate a kernel interrupt stack for each process. This way, when the process needs to perform a system call, or on an interrupt or processor exception, the hardware traps to the kernel, saves the user-level processor state, and starts running at a specific handler in the kernel. Once inside the kernel, the process thread behaves exactly like a kernel thread &#8212; it can create threads (or other processes), block (e.g., in UNIX process wait or on I/O), and even exit. While inside the kernel, the process can be pre-empted by a timer interrupt or I/O event, and a higher priority process or kernel thread can run in its place. The PCB and kernel stack for the preempted process stores both its current kernel state, as well as the user-level state saved when the process initiated the system call. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We can resume a process in the kernel using thread_switch. However, when we resume execution of the user-level process after the completion of a system call or interrupt, we must restore its state precisely as it was beforehand: with the correct value in its registers, executing in user mode, with the appropriate virtual memory mappings, and so forth. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An important detail is that many processor architectures have extra co-processor state, e.g., floating point registers, for user-level code. Typically, the operating system kernel does not make use of floating point operations. Therefore, the kernel does not need to save those registers when switching between kernel threads, but it does save and restore them when switching between processes. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>One small difference</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">You may notice that a mode switch in Chapter&nbsp;2 caused the x86 hardware to save not just the instruction pointer and eflags register but also the <EM>stack pointer</EM> of the interrupted process before starting the handler. For mode switching, the hardware changes the stack pointer to the kernel&#8217;s interrupt stack, so it must save the original user-level stack pointer. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In contrast, when switching from a kernel thread to a kernel handler, the hardware does not switch stacks. Instead, the handler runs on the current stack, not on a separate interrupt stack. Therefore, the hardware does not need to save the original stack pointer; the handler just saves the stack pointer with the other registers as part of the pushad instruction. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thus, x86 hardware works slightly differently when switching between a kernel thread and a kernel handler than when doing a mode switch: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Entering the handler.</B> When an interrupt or exception occurs, if the processor detects that it is already in kernel mode (by inspecting the eflags register), it just pushes the instruction pointer and eflags registers (but not the stack pointer) onto the existing stack. On the other hand, if the hardware detects that it is switching from user-mode to kernel-mode, then the processor also changes the stack pointer to the base of the interrupt stack and pushes the original stack pointer along with the instruction pointer and eflags registers onto the new stack. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Returning from the handler.</B> When the iret instruction is called, it inspects both the current eflags register and the value on the stack that it will use to restore the earlier eflags register. If the mode bit is identical, then iret just pops the instruction pointer and eflags register and continues to use the current stack. On the other hand, if the mode bit differs, then the iret instruction pops not only the instruction pointer and eflags register, but also the saved stack pointer, thus switching the processor&#8217;s stack pointer to the saved one. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-27001r52 name=x1-27001r52></A><A id=x1-280008 name=x1-280008>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8 Implementing Multi-Threaded Processes</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">So far, we have described how to implement multiple threads that run inside the operating system kernel. Of course, we also want to be able to run user programs as well. Since many user programs are single-threaded, we start with the simple case of how to integrate kernel threads and single-threaded processes. We then turn to various ways of implementing <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:multi-threaded process"}'>multi-threaded processes</A></EM>, processes with multiple threads. All widely used modern operating systems support both kernel threads and multi-threaded processes. Both programming languages, such as Java, and standard library interfaces such as POSIX and simple threads, use this operating system support to provide the thread abstraction to the programmer. </FONT><A id=x1-28001r49 name=x1-28001r49></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.1 </FONT><A id=x1-290001 name=x1-290001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Multi-Threaded Processes Using Kernel Threads</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The simplest way to support multiple threads per process is to use the kernel thread implementation we have already described. When a kernel thread creates, deletes, suspends, or resumes a thread, it can use a simple procedure call. When a user-level thread accesses the thread library to do the same things, it uses a system call to ask the kernel to do the operation on its behalf. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As shown earlier in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-2300212"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.12</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, a thread in a process has: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A user-level stack for executing user code. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A kernel interrupt stack for when this thread makes system calls, causes a processor exception, or is interrupted. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A kernel TCB for saving and restoring the per-thread state.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To create a thread, the user library allocates a user-level stack for the thread and then does a system call into the kernel. The kernel allocates a TCB and interrupt stack, and arranges the state of the thread to start execution on the user-level stack at the beginning of the requested procedure. The kernel needs to store a pointer to the TCB in the process control block; if the process exits, the kernel must terminate any other threads running in the process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">After creating the thread, the kernel puts the new thread on the ready list, to be scheduled like any other thread, and returns unique identifier for the user program to use when referring to the newly created thread (e.g., for join). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Thread join, yield, and exit work the same way: by calling into the kernel to perform the requested function. </FONT><A id=x1-29001r54 name=x1-29001r54></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.2 </FONT><A id=x1-300002 name=x1-300002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing User-Level Threads Without Kernel Support</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">It is also possible to implement threads as a library completely at user level, without any operating system support. Early thread libraries took this pure user-level approach for the simple reason that few operating systems supported multi-threaded processes. Even once operating system support for threads became widespread, pure user-level threads were sometimes used to minimize dependencies on specific operating systems and to maximize portability; for example, the earliest implementations of Sun&#8217;s Java Virtual Machine (JVM) implemented what were called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:green threads"}'>green threads</A></EM>, a pure user-level implementation of threads. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The basic idea is simple. The thread library instantiates all of its data structures within the process: TCBs, the ready list, the finished list, and the waiting lists all are just data structures in the process&#8217;s address space. Then, calls to the thread library are just procedure calls, akin to how the same functions are implemented within a multi-threaded kernel. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To the operating system kernel, a multi-threaded application using green threads appears to be a normal, single-threaded process. The process as a whole can make system calls, be time-sliced, etc. Unlike with kernel threads, when a process using green threads is time-sliced, the entire process, including all of its threads, is suspended. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A limitation of green threads is that the operating system kernel is unaware of the state of the user-level ready list. If the application performs a system call that blocks waiting for I/O, the kernel is unable to run a different user-level thread. Likewise, on a multiprocessor, the kernel is unable to run the different threads running within a single process on different processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Preemptive User-level Threads.</B> However, it is possible on most operating systems to implement preemption among user-level threads executing within a process. As we discussed in Chapter&nbsp;2, most operating systems provide an upcall mechanism to deliver asynchronous event notification to a process; on UNIX these are called signal handlers. Typical events or signals include the user hitting &#8220;Escape&#8221; or on UNIX &#8220;Control-C&#8221;; this informs the application to attempt to cleanly exit. Another common event is a timer interrupt to signal elapsed real time. To deliver an event, the kernel suspends the process execution and then resumes it running at a handler specified by the user code, typically on a separate upcall or signal stack. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To implement preemptive multi-threading for some process P : </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-30002x1 name=x1-30002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The user-level thread library makes a system call to register a timer signal handler and signal stack with the kernel. </FONT></P>
<LI class=enumerate><A id=x1-30004x2 name=x1-30004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When a hardware timer interrupt occurs, the hardware saves P &#8217;s register state and runs the kernel&#8217;s handler. </FONT></P>
<LI class=enumerate><A id=x1-30006x3 name=x1-30006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Instead of restoring P &#8217;s register state and resuming P where it was interrupted, the kernel&#8217;s handler copies P &#8217;s saved registers onto P &#8217;s signal stack. </FONT></P>
<LI class=enumerate><A id=x1-30008x4 name=x1-30008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The kernel resumes execution in P at the registered signal handler on the signal stack. </FONT></P>
<LI class=enumerate><A id=x1-30010x5 name=x1-30010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The signal handler copies the processor state of the preempted user-level thread from the signal stack to that thread&#8217;s TCB. </FONT></P>
<LI class=enumerate><A id=x1-30012x6 name=x1-30012x6></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The signal handler chooses the next thread to run, re-enables the signal handler (the equivalent of re-enabling interrupts), and restores the new thread&#8217;s state from its TCB into the processor. execution with the state (newly) stored on the signal stack.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This approach virtualizes interrupts and processor exceptions, providing a user-level process with a very similar picture to the one the kernel gets when these events occur. </FONT><A id=x1-30013r55 name=x1-30013r55></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.8.3 </FONT><A id=x1-310003 name=x1-310003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing User-Level Threads With Kernel Support</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Today, most programs use kernel-supported threads rather than pure user-level threads. Major operating systems support threads using standard abstractions, so the issue of portability is less of an issue than it once was. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, various systems take more of a hybrid model, attempting to combine the lightweight performance and application control over scheduling found in user-level threads, while keeping many of the advantages of kernel threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Hybrid Thread Join.</B> Thread libraries can avoid transitioning to the kernel in certain cases. For example, rather than always making a system call for thread_join&nbsp;to wait for the target thread to finish, thread_exit&nbsp;can store its exit value in a data structure in the process&#8217;s address space. Then, if the call to thread_join&nbsp;happens after the targeted thread has exited, it can immediately return the value without having to make a system call. However, if the call to thread_join&nbsp;precedes the call to thread_exit, then a system call is needed to transition to the WAITING&nbsp;state and let some other thread run. As a further optimization, on a multiprocessor it can sometimes make sense for thread_join&nbsp;to spin for a few microseconds before entering the kernel, in the hope that the other thread will finish in the meantime. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Per-Processor Kernel Threads.</B> It is possible to adapt the green threads approach to work on a multiprocessor. For many parallel scientific applications, the cost of creating and synchronizing threads is paramount, and so an approach that requires a kernel call for most thread operations would be prohibitive. Instead, the library multiplexes user-level threads on top of kernel threads, in exactly the same way that the kernel multiplexes kernel threads on top of physical processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When the application starts up, the user-level thread library creates one kernel thread for each processor on the host machine. As long as there is no other activity on the system, the kernel will assign each of these threads a processor. Each kernel thread executes the user-level scheduler in parallel: pull the next thread off the user-level ready list, and run it. Because thread scheduling decisions occur at user level, they can be flexible and application-specific; for example, in a parallel graph algorithm, the programmer might adjust the priority of various threads based on the results of the computation on other parts of the graph. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Of course, most of the downsides of green threads are still present in these systems: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Any time a user-level thread calls into the kernel, its host kernel thread blocks. This prevents the thread library from running a different user-level thread on that processor in the meantime. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Any time the kernel time-slices a kernel thread, the user-level thread it was running is also suspended. The library cannot resume that thread until the kernel thread resumes.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Scheduler Activations.</B> To address these issues, some operating systems have added explicit support for user-level threads. One such model, implemented most recently in Windows, is called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:scheduler activations"}'>scheduler activations</A></EM>. In this approach, the user-level thread scheduler is notified (or activated) for every kernel event that might affect the user-level thread system. For example, if one thread blocks in a system call, the activation informs the user-level scheduler that it should choose another thread to run on that processor. Scheduler activations are like upcalls or signals, except that they do not return to the kernel; instead, they directly perform user-level thread suspend and resume. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Various operations trigger a scheduler activation upcall: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-31002x1 name=x1-31002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Increasing the number of virtual processors.</B> When a program starts, it receives an activation to inform the program that it has been assigned a virtual processor: that activation runs the main thread and any other threads that might be created. To assign another virtual processor to the program, the kernel makes another activation upcall on the new processor; the user-level scheduler can pull a waiting thread off the ready list and run it. </FONT></P>
<LI class=enumerate><A id=x1-31004x2 name=x1-31004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Decreasing the number of virtual processors.</B> When the kernel preempts a virtual processor (e.g., to give the processor to a different process), the kernel makes an upcall on one of the other processors assigned to the parallel program. The thread system can then move the preempted user-level thread onto the ready list, so that a different processor can run it. </FONT></P>
<LI class=enumerate><A id=x1-31006x3 name=x1-31006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition to WAITING.</B> When a user-level thread blocks in the kernel waiting for I/O, the kernel similarly makes an upcall to notify the user-level scheduler that it needs to take action, e.g., to choose another thread to run while waiting for the I/O to complete. </FONT></P>
<LI class=enumerate><A id=x1-31008x4 name=x1-31008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition from WAITING&nbsp;to READY.</B> When the I/O completes, the kernel makes an upcall to notify the scheduler that the suspended thread can be resumed. </FONT></P>
<LI class=enumerate><A id=x1-31010x5 name=x1-31010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Transition from RUNNING&nbsp;to idle.</B> When a user-level activation finds an empty ready list (i.e., it has no more work to do), it can make a system call into the kernel to return the virtual processor for use by some other process.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As a result, most thread management functions &#8212; thread_create, thread_yield, thread_exit, and thread_join, as well as the synchronization functions described in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> &#8212; are implemented as procedure calls within the process. Yet the user-level thread system always knows exactly how many virtual processors it has been assigned and is in complete control of what runs on those processors. </FONT><A id=x1-31011r53 name=x1-31011r53></A></P><A id=x1-320009 name=x1-320009>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.9 Alternative Abstractions</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Although threads are a common way to express and manage concurrency, they are not the only way. In this section, we describe two popular alternatives, each targeted at a different application domain: </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Asynchronous I/O and event-driven programming.</B> Asynchronous I/O and events allow a single-threaded program to cope with high-latency I/O devices by overlapping I/O with processing and other I/O. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Data parallel programming.</B> With data parallel programming, all processors perform the same instructions in parallel on different parts of a data set.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In each case, the goal is similar: to replace the complexities of multi-threading with a deterministic, sequential model that is easier for the programmer to understand and debug. </FONT><A id=x1-32001r56 name=x1-32001r56></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.9.1 </FONT><A id=x1-330001 name=x1-330001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Asynchronous I/O and Event-Driven Programming</FONT></H4><EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:asynchronous I/O"}'><FONT style="BACKGROUND-COLOR: #7be1e1">Asynchronous I/O</FONT></A></EM><FONT style="BACKGROUND-COLOR: #7be1e1"> is a way to allow a single-threaded process to issue multiple concurrent I/O requests at the same time. The process makes a system call to issue an I/O request but the call returns immediately, without waiting for the result. At a later time, the operating system provides the result to the process by either: (1) calling a signal handler, (2) placing the result in a queue in the process&#8217;s memory, or (3) storing the result in kernel memory until the process makes another system call to retrieve it. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An example use of asynchronous I/O is to overlap reading from disk with other computation in the same process. Reading from disk can take tens of milliseconds. In Linux, rather than issuing a read system call that blocks until the requested data has been read from disk, a process can issue an aio_read (asynchronous I/O read) system call; this call tells the operating system to initiate the read from disk and then to immediately return. Later, the process can call aio_error to determine if the disk read has finished and aio_return to retrieve the read&#8217;s results, as shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-3300116"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.16</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT><A id=x1-3300116 name=x1-3300116></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00396.gif" data-calibre-src="OEBPS/Images/image00396.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.16: </B>An asynchronous file read on Linux. The application calls aio_read to start the read; this system call returns immediately after the disk read is initialized. The application may then do other processing while the disk is completing the requested operation. The disk interrupts the processor when the operation is complete; this causes the kernel disk interrupt handler to run. The application at any time may ask the kernel if the results of the disk read are available, and then retrieve them with aio_return.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One common design pattern lets a single thread interleave different I/O-bound tasks by waiting for different I/O events. Consider a web server with 10 active clients. Rather than creating one thread per client and having each thread do a blocking read on the network connection, an alternative is for the server to have one thread that processes, in turn, the next message to arrive from <EM>any</EM> client. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For this, the server does a select call that blocks until <EM>any</EM> of the 10 network connections has data available to read. When the select call returns, it provides a list of connection with available data. The thread can then read from those connections, knowing that the read will always return immediately. After processing the data, the thread then calls select again to wait for the next data to arrive. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-3300217"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates this design pattern. </FONT><A id=x1-3300217 name=x1-3300217></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00397.gif" data-calibre-src="OEBPS/Images/image00397.gif"></FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.17: </B>A server managing multiple concurrent connections using select. The server calls select to wait for data to arrive on any connection. The server then reads all available data, before returning to select. </FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Asynchronous I/O allows progress by many concurrent operating system requests. This approach gives rise to an <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:event-driven programming"}'>event-driven programming</A></EM> pattern where a thread spins in a loop; each iteration gets and processes the next I/O event. To process each event, the thread typically maintains for each task a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:continuation"}'>continuation</A></EM>, a data structure that keeps track of a task&#8217;s current state and next step. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, handling a web request can involve a series of I/O steps: (a) make a network connection, (b) read a request from the network connection, (c) read the requested data from disk, and (d) write the requested data to the network connection. If a single thread is handling requests from multiple different clients at once, it must keep track of where it is in that sequence for each client. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Further, the network may divide a client&#8217;s request into several packets so that the server needs to make several read calls to assemble the full packet. The server may be doing this request assembly for multiple clients at once. Therefore, it needs to keep several per-client variables (e.g., a request buffer, the number of bytes expected, and the number of bytes received so far). When a new message arrives, the thread uses the network connection&#8217;s port number to identify which client sent the request and retrieves the appropriate client&#8217;s variables using this port number/client ID. It can then process the data. </FONT></P>
<H5 class=subsubsectionHead><A id=x1-340001 name=x1-340001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Event-Driven Programming vs. Threads</FONT></H5><FONT style="BACKGROUND-COLOR: #7be1e1">Although superficially different, overlapping I/O is fundamentally the same whether using asynchronous I/O and event-driven programming or synchronous I/O and threads. In either case, the program blocks until the next task can proceed, restores the state of that task, executes the next step of that task, and saves the task&#8217;s state until it can take its next step. The differences are: (1) whether the state is stored in a continuation or TCB and (2) whether the state save/restore is done explicitly by the application or automatically by the thread system. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Consider a simple server that collects incoming data from several clients into a set of per-client buffers. The pseudo-code for the event-driven and thread-per-client cases is similar: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Event-driven
&nbsp;Hashtable&lt;Buffer*&gt;&nbsp;*hash;
&nbsp;
&nbsp;while(1)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;connection&nbsp;=&nbsp;use&nbsp;select()&nbsp;to&nbsp;find&nbsp;a
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readable&nbsp;connection&nbsp;ID
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buffer&nbsp;=&nbsp;hash.remove(connection);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;got&nbsp;=&nbsp;read(connection,&nbsp;tmpBuf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TMP_SIZE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buffer-&gt;append(tmpBuf,&nbsp;got);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buffer&nbsp;=&nbsp;hash.put(connection,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buffer);
&nbsp;}
 </FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Thread-per-client
&nbsp;Buffer&nbsp;*b;
&nbsp;
&nbsp;while(1)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;got&nbsp;=&nbsp;read(connection,&nbsp;tmpBuf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TMP_SIZE);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buffer-&gt;append(tmpBuf,&nbsp;got);
&nbsp;}
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When these programs execute, the system performs nearly the same work, as shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-3400118"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.18</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. With events, the code uses select to determine which connection&#8217;s packet to retrieve next. With threads, the kernel transparently schedules each thread when data has arrived for it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The state in both cases is also similar. In the event-driven case, the application maintains a hash table containing the buffer state for each client. The server must do a lookup to find the buffer each time a packet arrives for a particular client. In the thread-per-client case, each thread has just one buffer, and the operating system keeps track of the different threads&#8217; states. </FONT><A id=x1-3400118 name=x1-3400118></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00398.gif" data-calibre-src="OEBPS/Images/image00398.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.18: </B>Two alternate implementations of a server. In the upper picture, a single thread uses a hash table to keep track of connection state. In the lower picture, each thread keeps a pointer to the state for one connection.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To compare the two approaches, consider again the various use cases for threads from Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-110001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance: Coping with high-latency I/O devices.</B> Either approach &#8212; event-driven or threads &#8212; can overlap I/O and processing. Which provides better performance? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The common wisdom has been that the event-driven approach was significantly faster for two reasons. First, the space and context switch overheads of this approach could be lower because a thread system must use generic code that allocates a stack for each thread&#8217;s state and that saves and restores all registers on each context switch, while the event-driven approach lets programmers allocate and save/restore just the state needed for each task. Second, some past operating systems had inefficient or unscalable implementations of their thread systems, making it important not to create too many threads for each process. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Today, the comparison is less clear cut. Many systems now have large memories, so the cost of allocating a thread stack for each task is less critical. For example, allocating 1000 threads with an 8 KB stack per thread on a machine with 1 GB of memory would consume less than 1% of the machine&#8217;s memory. Also, most operating systems now have efficient and scalable threads libraries. For example, while the Linux 2.4 kernel had poor performance when processes had many threads, Linux 2.6 revamped the thread system, improving its scalability and absolute performance. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Anecdotal evidence suggests that the performance gap between the two approaches has greatly narrowed. For some applications, highly optimized thread management code and synchronous I/O paths can out-perform less-optimized application code and asynchronous I/O paths. In most cases, the performance difference is small enough that other factors (e.g., code simplicity and ease of maintenance) are more important than raw performance. If performance is crucial for a particular application, then, as is often the case, there is no substitute for careful benchmarking before making your decision. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance: Exploiting multiple processors.</B> By itself, the event-driven approach does not help a program exploit multiple processors. In practice, event-driven and thread approaches are often combined: a program that uses n processors can have n threads, each of which uses the event-driven pattern to multiplex multiple I/O-bound tasks on each processor. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Responsiveness: Shifting work to run in the background.</B> While event-driven programming can be effective when tasks are usually short-lived, threads can be more convenient when there is a mixture of foreground and background tasks. At some cost in coding complexity, the event-driven model can be adapted to this case, e.g., by cutting long tasks into smaller chunks whose state can be explicitly saved when higher priority work is pending. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Program structure: Expressing logically concurrent tasks.</B> Whenever there are two viable programming styles, there are strong advocates for each approach. The situation is no different here, with some advocates of event-driven programming arguing that the synchronization required when threads share data makes threads more complex than events. Advocates for threads argue that they provide a more natural way to express the control flow of a program than having to explicitly store a computation&#8217;s state in a continuation. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In our opinion, there remain cases where both styles are appropriate, and we use both styles in our own programs. That said, for most I/O-intensive programs, threads are preferable: they are often more natural, reasonably efficient, and simpler when running on multiple processors. </FONT><A id=x1-34002r58 name=x1-34002r58></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.9.2 </FONT><A id=x1-350002 name=x1-350002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Data Parallel Programming</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Another important application area is parallel computing, and there is an ongoing debate as to the effectiveness of threads versus other models for expressing and managing parallelism. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One popular model is <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:data parallel programming"}'>data parallel programming</A></EM>, also known as SIMD (single instruction multiple data) programming or <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:bulk synchronous parallel programming"}'>bulk synchronous parallel programming</A></EM>. In this model, the programmer describes a computation to apply in parallel across an entire data set at the same time, operating on independent data elements. The work on every data item must complete before moving onto the next step; one processor can use the results of a different processor only in some later step. As a result, the behavior of the program is deterministic. Rather than having programmers divide work among threads, the runtime system decides how to map the parallel work across the hardware&#8217;s processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, taking the earlier example of zeroing a buffer in parallel in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-180017"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, a data parallel program to zero an N item array can be as simple as: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;forall&nbsp;i&nbsp;in&nbsp;0:N-1
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;array[i]&nbsp;=&nbsp;0;</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The runtime system would divide the array among processors to execute the computation in parallel. Of course, the runtime system itself might be implemented using threads, but this is invisible to the programmer. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Large data-analysis tasks often use data parallel programming. For example, Hadoop is an open source system that can process and analyze terabytes of data spread across hundreds or thousands of servers. It applies an arbitrary computation to each data element, such as to update the popularity of a web page based on a previous estimate of the popularity of the pages that refer to it. Hadoop applies the computation in parallel across all web pages, repeatedly, until the popularity of every page has converged. A search engine can then use the results to decide which pages should be returned in response to a search query. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Another example is SQL (Structured Query Language). SQL is a standard language for accessing databases in which programmers specify the database query to perform, and the database maps the query to lower-level thread and disk operations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Multimedia streams (e.g., audio, video, and graphics) often have large amounts of data on which similar operations are repeatedly performed, so data parallel programming is frequently used for media processing; specialized hardware to support this type of parallel processing is common. Because they are optimized for highly structured data parallel programs, GPUs (Graphical Processing Units) can provide significantly higher rates of data processing. For example, in 2013 a mid-range Radeon 7850 GPU was capable of 1.69 TFLOPS (Trillion FLoating point Operations Per Second (double-precision)); for comparison, an Intel i7 3960 CPU (a high-end, six core general-purpose processor) was capable of 0.19 double-precision TFLOPS. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Considerable effort is currently going towards developing and using General Purpose GPUs (GPGPUs) &#8212; GPUs that better support a wider-range of programs. It is still not clear which classes of programs can work well with GPGPUs and which require more traditional CPU architectures, but for those programs that can be ported to the more restrictive GPGPU programming model, performance gains could be dramatic. </FONT><A id=x1-35001r57 name=x1-35001r57></A></P><A id=x1-3600010 name=x1-3600010>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.10 Summary and Future Directions</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Concurrency is ubiquitous &#8212; not only do most smartphones, servers, desktops, laptops, and tablets have multiple cores, but users have come to expect a responsive interface at all times, I/O latencies have become gigantic compared to computer instruction cycle times, and servers must be able to process large numbers of simultaneous requests. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although threads are not the only possible solution to these issues, they are a general-purpose technique that can be applied to a wide range of concurrency issues. In our view, multi-threaded programming is a skill that every professional programmer must master. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In this chapter, we have discussed: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>The thread abstraction.</B> Threads are a set of concurrent activities, each of which executes sequentially at unpredictable speed. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>A simple thread API.</B> Thread libraries, whether for use in the operating system kernel or in application code, provide the ability to perform an asynchronous procedure call. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread implementations.</B> The core of any implementation of preemptive multi-threading is the ability to save one thread&#8217;s state and restore another&#8217;s. The thread system keeps track of the saved state of all threads not currently running; it switches threads between READY&nbsp;and RUNNING&nbsp;as needed. The implementation of multi-threading can be in the kernel or at user-level, depending on the goals of the system. In our view, most systems in the future will have both a kernel-level thread system for managing concurrency in the operating system, and a lightweight thread system for expressing parallelism at the application level. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Alternative abstractions.</B> Practical alternatives to threads exist for two important domains: event-driven programming for servers as well as data parallel programming for multiprocessors.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Technology trends suggest that concurrent programming will only increase in importance over time. After several decades in which computer architects were able to make individual processor cores run faster and faster, we have reached a point where the performance of individual cores is leveling off and where further speedups will have to come from parallel processing. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The best programming model for expressing and managing parallelism is still an active area of research, but it seems likely that threads will remain an important option for decades to come. </FONT><A id=x1-36001r63 name=x1-36001r63></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">4.10.1 </FONT><A id=x1-370001 name=x1-370001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Historical Notes</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The extreme engineering complexity and bugginess of commercial operating systems in the 1960&#8217;s led researchers to investigate alternatives. One direct result of this experience was modern software engineering: the systematic management of complex implementation tasks through the careful control of feature lists, module testing, assertions, and so forth. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Another consequence was the use of threads for managing concurrency. One of the most influential papers in computer science history is Dijkstra&#8217;s description of his THE system&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XDijkstra:1968:SLS:363095.363143"}'><FONT style="BACKGROUND-COLOR: #7be1e1">48</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. Dijkstra argued for constructing operating systems as a series of layered abstractions, with communicating threads implementing each layer. Within a decade, the research community was convinced. When Xerox PARC built the Alto in the late 1970&#8217;s, the Alto&#8217;s operating system was built from the ground up using threads. The Alto demonstrated most of the technology we now take for granted with personal computers: bit-mapped display, menus, windowing, mice, Ethernet, and email. We base much of our description of thread programming on the experiences from that project&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XLampson:1980:EPM:358818.358824"}'><FONT style="BACKGROUND-COLOR: #7be1e1">98</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Widespread commercial adoption of threads took much longer, however. By the early 1990&#8217;s, the widespread adoption of client-server computing led to several commercially important operating systems written from scratch using threads, including Microsoft&#8217;s Windows NT, SUN Microsystems Solaris, and Linux. Client operating systems followed, and by the late 1990&#8217;s, with Apple&#8217;s introduction of OS X, all major commercial operating systems were based on threads. At about the same time, the interface to thread libraries became standardized, starting with POSIX in 1995. Likewise, modern programming languages such as Java were designed with constructs for creating and synchronizing threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The increasing importance of parallel processing led to the development of very lightweight user-level thread implementations, as there is little point to parallelizing an application unless it improves performance. By the early 90&#8217;s, scheduler activations were developed to integrate user-level and kernel threads&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XAnderson:1992:SAE:146941.146944"}'><FONT style="BACKGROUND-COLOR: #7be1e1">2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Even so, the topic of whether threads are a better programming model than the alternatives remains an active one&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "Xtyma"}'><FONT style="BACKGROUND-COLOR: #7be1e1">159</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. Several prominent operating systems researchers have argued that normal programmers should almost never use threads because (a) it is just too hard to write multi-threaded programs that are correct and (b) most things that threads are commonly used for can be accomplished in other, safer ways&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "Xousterhoutbadthreads"}'><FONT style="BACKGROUND-COLOR: #7be1e1">129</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">,&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XvanRenesse:1998:GPC:319195.319208"}'><FONT style="BACKGROUND-COLOR: #7be1e1">160</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. These are important arguments to understand &#8212; even if you disagree with them, they point out pitfalls with using threads that are important to avoid. </FONT><A id=Q1-1-66 name=Q1-1-66></A><A id=Q1-1-67 name=Q1-1-67></A></P><A id=x1-380001 name=x1-380001>
<H3 class=likesectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">Exercises</FONT></H3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<OL class=problems>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For some of the following problems, you will need to download the thread library from </FONT><A href="http://ospp.cs.washington.edu/instructor.html"><FONT style="BACKGROUND-COLOR: #7be1e1">http://ospp.cs.washington.edu/instructor.html</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. The comment at the top of threadHello.c explains how to compile and run a program that uses this library. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Download threadHello.c, compile it, and run it several times. What happens when you run it? Do you get the same result if you run it multiple times? What if you are also running some other demanding processes (e.g., compiling a big program, playing a Flash game on a website, or watching streaming video) when you run this program? </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">For the threadHello program in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, suppose that we delete the second for loop so that the main routine simply creates NTHREADS threads and then prints &#8220;Main thread done.&#8221; What are the possible outputs of the program now. <B>Hint:</B> Fewer than NTHREADS+1 lines may be printed in some runs. Why? </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">How expensive are threads? Write a program that times how long it takes to create and then join 1000 threads, where each thread simply calls thread_exit(0) as soon as it starts running. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Write a program that has two threads. Make the first thread a simple loop that continuously increments a counter and prints a period (&#8220;.&#8221;) whenever the value of that counter is divisible by 10,000,000. Make the second thread repeatedly wait for the user to input a line of text and then print &#8220;Thank you for your input.&#8221; On your system, does the first thread makes rapid progress? Does the second thread respond quickly? </FONT><A id=x1-3800119 name=x1-3800119></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00399.gif" data-calibre-src="OEBPS/Images/image00399.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;4.19: </B>Matrix multiplication.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Write a program that uses threads to perform a parallel matrix multiply. To multiply two matrices, C = A * B, the result entry C<SUB>(i,j)</SUB> is computed by taking the dot product of the ith row of A and the jth column of B: C<SUB>i,j</SUB> = &#931;<SUB>k=0</SUB><SUP>N-1</SUP>A<SUB>(i,k)</SUB>B<SUB>(k,j)</SUB>. We can divide the work by creating one thread to compute each value (or each row) in C, and then executing those threads on different processors in parallel, as shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-3800119"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.19</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Write a program that uses threads to perform a parallel merge sort. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">For the threadHello program in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the procedure go() has the parameter np and the local variable n. Are these variables <EM>per-thread</EM> or <EM>shared</EM> state? Where does the compiler store these variables&#8217; states? </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">For the threadHello program in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-170016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the procedure main() has local variables such as i and exitValue. Are these variables <EM>per-thread</EM> or <EM>shared</EM> state? Where does the compiler store these variables? </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">In the <EM>thread-local variables</EM> sidebar, we described how many thread systems have this type of per-thread state. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Describe how you would implement thread-local variables. Each thread should have an array of 1024 pointers to its thread-local variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<OL class=subproblems>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">What would you add to the TCB? </FONT>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">How would you change the thread creation procedure? (For simplicity, assume that when a thread is created, all 1024 entries should be initialized to NULL.) </FONT>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">How would a running thread allocate a new thread-local variable? </FONT>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">In your design, how would a running thread access a particular thread-local variable? </FONT></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">For the threadHello program, what is the minimum and maximum number of times that the main thread enters the WAITING&nbsp;state? </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Using simple threads, write a program that creates several threads and then determines whether the threads package on your system allocates a fixed-size stack for each thread or whether each thread&#8217;s stack starts at some small size and dynamically grows as needed. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Hints:</B> You probably want to write a recursive procedure that you can use to consume a large amount of stack memory. You may also want to examine the addresses of variables allocated to different threads&#8217; stacks. Finally, you may want to be able to determine how much memory has been allocated to your process; most operating systems have a command or utility that can show the resource consumption of currently running processes (e.g., top in Linux, Activity Monitor in OSX, or Task Manager in Windows). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT>
<DIV style="break-after: always; -webkit-column-break-after: always"><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></DIV><BR><BR><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><A id=x1-390005 name=x1-390005><BR><BR><FONT style="BACKGROUND-COLOR: #7be1e1">