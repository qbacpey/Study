<STRONG><FONT style="BACKGROUND-COLOR: #7be1e1" color=blue>Operating Systems: Principles and Practice (Second Edition) Volume II : </FONT></STRONG>
<H2 class=chapter_name><I><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=headers>Title:</SPAN></B><SPAN class=RefText> Operating Systems: Principles and Practice (Second Edition) Volume II : 5. Synchronizing Access to Shared Objects</SPAN></FONT></FONT></I></H2></A>
<DIV class=chapterQuote>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">It is not enough to be industrious. So are the ants. The question is: What are we industrious about? &#8212;<I>Henry David Thoreau</I> </FONT></P>
<DL>
<DT><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT>
<DD><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></DD></DL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
<BR></FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Multi-threaded programs extend the traditional, single-threaded programming model so that each thread provides a single sequential stream of execution composed of familiar instructions. If a program has <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:independent threads"}'>independent threads</A></EM> that operate on completely separate subsets of memory, we can reason about each thread separately. In this case, reasoning about independent threads differs little from reasoning about a series of independent, single-threaded programs. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, most multi-threaded programs have both <EM>per-thread state</EM> (e.g., a thread&#8217;s stack and registers) and <EM>shared state</EM> (e.g., shared variables on the heap). <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:cooperating threads"}'>Cooperating threads</A></EM> read and write shared state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Sharing state is useful because it lets threads communicate, coordinate work, and share information. For example, in the </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-110001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">Earth Visualizer</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> example in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, once one thread finishes downloading a detailed image from the network, it shares that image data with a rendering thread that draws the new image on the screen. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Unfortunately, when cooperating threads share state, writing correct multi-threaded programs becomes much more difficult. Most programmers are used to thinking &#8220;sequentially&#8221; when reasoning about programs. For example, we often reason about the series of states traversed by a program as a sequence of instructions is executed. However, this sequential model of reasoning does not work in programs with cooperating threads, for three reasons: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-39002x1 name=x1-39002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Program execution depends on the possible interleavings of threads&#8217; access to shared state.</B> For example, if two threads write a shared variable, one thread with the value 1 and the other with the value 2, the final value of the variable depends on which of the threads&#8217; writes finishes last. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although this example is simple, the problem is severe because programs need to work for <EM>any possible interleaving</EM>. In particular, recall that thread programmers </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-150002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">should not make any assumptions about the relative speed at which their threads operate.</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Worse, as programs grow, there is a combinatorial explosion in the number of possible interleavings. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><EM><FONT style="BACKGROUND-COLOR: #7be1e1">How can we reason about all possible interleavings of threads&#8217; actions in a multi-million line program?</FONT></EM></DIV></TD></TR></TBODY></TABLE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<LI class=enumerate><A id=x1-39004x2 name=x1-39004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Program execution can be nondeterministic.</B> Different runs of the same program may produce different results. For example, the scheduler may make different scheduling decisions, the processor may run at a different frequency, or another concurrently running program may affect the cache hit rate. Even common debugging techniques &#8212; such as running a program under a debugger, recompiling with the -g option instead of -O, or adding a printf &#8212; can change how a program behaves. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Jim Gray, the 1998 ACM Turing Award winner, coined the term <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:Heisenbugs"}'>Heisenbugs</A></EM> for bugs that disappear or change behavior when you try to examine them. Multi-threaded programming is a common source of Heisenbugs. In contrast, <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:Bohrbugs"}'>Bohrbugs</A></EM> are deterministic and generally much easier to diagnose. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><EM><FONT style="BACKGROUND-COLOR: #7be1e1">How can we debug programs with behaviors that change across runs?</FONT></EM></DIV></TD></TR></TBODY></TABLE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<LI class=enumerate><A id=x1-39006x3 name=x1-39006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Compilers and processor hardware can reorder instructions.</B> Modern compilers and hardware reorder instructions to improve performance. This reordering is generally invisible to single-threaded programs; compilers and processors take care to ensure that dependencies within a single sequence of instructions &#8212; that is, within a thread &#8212; are preserved. However, reordering can become visible when multiple threads interact through accessing shared variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, consider the following code to compute q as a function of p: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Thread&nbsp;1
&nbsp;
&nbsp;p&nbsp;=&nbsp;someComputation();
&nbsp;pInitialized&nbsp;=&nbsp;true;
&nbsp;</FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Thread&nbsp;2
&nbsp;
&nbsp;while(!pInitialized)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;
&nbsp;q&nbsp;=&nbsp;anotherComputation(p);
&nbsp;</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although it seems that p is always initialized before anotherComputation(p) is called, this is not the case. To maximize instruction level parallelism, the hardware or compiler may set pInitialized = true before the computation to compute p has completed, and anotherComputation(p) may be computed using an unexpected value. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><EM><FONT style="BACKGROUND-COLOR: #7be1e1">How can we reason about thread interleavings when compilers and processor hardware may reorder a thread&#8217;s operations?</FONT></EM></DIV></TD></TR></TBODY></TABLE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Why do compilers and processor hardware reorder operations?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We often find that students are puzzled by the notion that a compiler might produce code, or a processor might execute code, in a way that is correct for a single thread but unpredictable for a multi-threaded program without synchronization. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For compilers, the issue is simple. Modern processors have deep pipelines; they execute many instructions simultaneously by overlapping the instruction fetch, instruction decode, data fetch, arithmetic operation, and conditional branch of a sequence of instructions. The processor stalls when necessary &#8212; e.g., if the result of one instruction is needed by the next. Modern compilers will reorder instructions to reduce these stalls as much as possible, provided the reordering does not change the behavior of the program. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The difficulty arises in what assumptions the compiler can make about the code. If the code is single-threaded, it is much easier to analyze possible dependencies between adjacent instructions, allowing more optimization. By contrast, variables in (unsynchronized) multi-threaded code can potentially be read or written by another thread at any point. As the example in the text demonstrated, the precise sequence of seemingly unrelated instructions can potentially affect the behavior of the program. To preserve semantics, instruction re-ordering may no longer be feasible, resulting in more processor stalls and slower code execution. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As long as the programmer uses structured synchronization for protecting shared data, the compiler can reorder instructions as needed without changing program behavior, provided that the compiler does not reorder across synchronization operations. A compiler making the more conservative assumption that all memory is shared would produce slow code even when it was not necessary. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For processor architectures, the issue is also performance. Certain optimizations are possible if the programmer is using structured synchronization but not otherwise. For example, modern processors buffer memory writes to allow instruction execution to continue while the memory is written in the background. If two adjacent instructions issue memory writes to different memory locations, they can occur in parallel and complete out of order. This optimization is safe on a single processor, but potentially unsafe if multiple processors are simultaneously reading and writing the same locations without intervening synchronization. Some processor architectures make the conservative assumption that optimizations should never change program behavior regardless of the programming style &#8212; in this case, they stall to prevent reordering. Others make a more optimistic assumption that the programmer is using structured synchronization. For your code to be portable, you should assume that the compiler and the hardware can reorder instructions except across synchronization operations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Given these challenges, multi-threaded code can introduce subtle, non-deterministic, and non-reproducible bugs. This chapter describes a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:structured synchronization"}'>structured synchronization</A></EM> approach to sharing state in multi-threaded programs. Rather than scattering access to shared state throughout the program and attempting <EM>ad hoc</EM> reasoning about what happens when the threads&#8217; accesses are interleaved in various ways, a better approach is to: (1) structure the program to facilitate reasoning about concurrency, and (2) use a set of standard synchronization primitives to control access to shared state. This approach gives up some freedom, but if you consistently follow the rules we describe in this chapter, then reasoning about programs with shared state becomes much simpler. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The first part of this chapter elaborates on the challenges faced by multi-threaded programmers and on why it is dangerous to try to reason about all possible thread interleavings in the general, unstructured case. The rest of the chapter describes how to structure shared objects in multi-threaded programs so that we can reason about them. First, we structure a multi-threaded program&#8217;s shared state as a set of <EM>shared objects</EM> that encapsulate the shared state as well as define and limit how the state can be accessed. Second, to avoid <EM>ad hoc</EM> reasoning about the possible interleavings of access to the state variables within a shared object, we describe how shared objects can use a small set of <EM>synchronization primitives</EM> &#8212; locks and condition variables &#8212; to coordinate access to their state by different threads. Third, to simplify reasoning about the code in shared objects, we describe a set of <EM>best practices</EM> for writing the code that implements each shared object. Finally, we dive into the details of how to implement synchronization primitives. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Multi-threaded programming has a reputation for being difficult. We agree that it takes care, but this chapter provides a set of simple rules that anyone can follow to implement objects that can be safely shared by multiple threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Chapter roadmap:</B> </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Challenges.</B> Why is it difficult to reason about multi-threaded programs with unstructured use of shared state? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-400001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Structuring Shared Objects.</B> How should we structure access to shared state by multiple threads? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-460002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Locks: Mutual Exclusion.</B> How can we enforce a logical sequence of operations on shared state? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-490003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Condition Variables: Waiting for a Change.</B> How does a thread wait for a change in shared state? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Designing and Implementing Shared Objects.</B> Given locks and condition variables, what is a good way to write and reason about the code for shared objects? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-580005"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Three Case Studies.</B> We illustrate our methodology by using it to develop solutions to three concurrent programming challenges. (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-620006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementing Synchronization Primitives.</B> How are locks and condition variables implemented? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-660007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Semaphores Considered Harmful.</B> What other synchronization primitives are possible, and how do they relate to locks and condition variables? (Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-740008"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">)</FONT></P></LI></UL><A id=x1-39007r64 name=x1-39007r64></A><A id=x1-400001 name=x1-400001>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1 Challenges</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">We began this chapter with the core challenge of multi-threaded programming: a multi-threaded program&#8217;s execution depends on the interleavings of different threads&#8217; access to shared memory, which can make it difficult to reason about or debug these programs. In particular, cooperating threads&#8217; execution may be affected by <EM>race conditions.</EM> </FONT><A id=x1-40001r65 name=x1-40001r65></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.1 </FONT><A id=x1-410001 name=x1-410001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Race Conditions</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:race condition"}'>race condition</A></EM> occurs when the behavior of a program depends on the interleaving of operations of different threads. In effect, the threads run a race between their operations, and the results of the program execution depends on who wins the race. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Reasoning about even simple programs with race conditions can be difficult. To appreciate this, we now look at three extremely simple multi-threaded programs. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>The world&#8217;s simplest cooperating-threads program.</B> Suppose we run a program with two threads that do the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">x = 1; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; x = 2;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV></DIV></TD></TR></TBODY></TABLE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What are the possible final values of x? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>The result can be <B>x = 1 or x = 2</B> depending on which thread wins or loses the &#8220;race&#8221; to set x. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">That was easy, so let&#8217;s try one that is a bit more interesting. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>The world&#8217;s second-simplest cooperating-threads program.</B> Suppose that initially y = 12, and we run a program with two threads that do the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">x = y + 1; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; y = y * 2;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV></DIV></TD></TR></TBODY></TABLE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What are the possible final values of x? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>The result is <B>x = 13 if Thread A executes first or x = 25 if Thread B executes first.</B> More precisely, we get x = 13 if Thread A reads y before Thread B updates y, or we get x = 25 if Thread B updates y before Thread A reads y. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>The world&#8217;s third-simplest cooperating-threads program.</B> Suppose that initially x = 0 and we run a program with two threads that do the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">x = x + 1; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; x = x + 2;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV></DIV></TD></TR></TBODY></TABLE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What are the possible final values of x? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>Obviously, <B>one possible outcome is x = 3.</B> For example, Thread A runs to completion and then Thread B starts and runs to completion. However, <B>we can also get x = 2 or x = 1.</B> In particular, when we write a single statement like x = x + 1, compilers on many processors produce multiple instructions, such as: (1) load memory location x into a register, (2) add 1 to that register, and (3) store the result to memory location x. If we disassemble the above program into simple pseudo-assembly-code, we can see some of the possibilities. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><FONT style="BACKGROUND-COLOR: #7be1e1"><B>One Interleaving</B> </FONT>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load r1, x </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">add r2, r1, 1 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">store x, r2 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; load r1, x </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; add r2, r1, 2</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; store x, r2 </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV><B><FONT style="BACKGROUND-COLOR: #7be1e1">final: x == 3</FONT></B></DIV></TD></TR></TBODY></TABLE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Another Interleaving</B> </FONT>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load r1, x </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; load r1, x </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">add r2, r1, 1 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; add r2, r1, 2 </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">store x, r2 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; store x, r2 </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV><B><FONT style="BACKGROUND-COLOR: #7be1e1">final: x == 2</FONT></B></DIV></TD></TR></TBODY></TABLE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<TABLE width="100%" border=0>
<TBODY>
<TR>
<TD>
<DIV align=center><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Yet Another Interleaving</B><BR></FONT>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Thread A</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; <B>Thread B</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">load r1, x </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; load r1, x </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">add r2, r1, 1 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; add r2, r1, 2 </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; store x, r2 </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">store x, r2 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;&nbsp;&nbsp; </FONT></P></TD></TR></TBODY></TABLE></DIV><B><FONT style="BACKGROUND-COLOR: #7be1e1">final: x == 1</FONT></B></DIV></TD></TR></TBODY></TABLE><BR><FONT style="BACKGROUND-COLOR: #7be1e1">&#9633; </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Even for this 2-line program, the complexity of reasoning about race conditions and interleavings is beginning to grow. Not only would one have to reason about all possible interleavings of statements, but one would also have to disassemble the program and reason about all possible interleavings of assembly instructions. (And if the compiler and hardware can reorder instructions, there are even more possibilities to consider.) </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>The Case of the Therac-25</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The Therac-25 was a cancer therapy device, designed to deliver very high doses of radiation to a targeted region of the body in an attempt to eliminate cancer cells before they had a chance to spread. Over a several year period in the mid-1980&#8217;s, a computer malfunction caused six separate patients to receive an estimated 100 times the intended dose of radiation. Three of the patients later died as a result; the others sustained serious but non-fatal injuries. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although there were many contributing factors to the malfunction, a race condition was at the heart of both the overdose and the delay in recognizing and repairing the problem. The Therac-25 was designed to check in software that the entered dosage was medically safe before using it to configure the radiation beam. However, the software was also concurrent: the operator interface code could run at the same time that the dosage was being checked and used, with no locking or other synchronization. In rare cases, the dosage could be changed after the check and before the use, and due to a separate user interface bug, the operator could enter an overdose without either intending or realizing it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Because the problem required a rare sequence of events, the machine appeared to work successfully for almost all patients. Years elapsed between the first incident and the final one, and during this period, the manufacturer repeatedly insisted that no overdose was possible and that the patient injuries must be due to some other factor. It took the second occurrence of the race condition at the same hospital to help reveal the system&#8217;s design flaw. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-41001r72 name=x1-41001r72></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.2 </FONT><A id=x1-420002 name=x1-420002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Atomic Operations</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">When we disassembled the code in last example, we could reason about <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:atomic operations"}'>atomic operations</A></EM>, indivisible operations that cannot be interleaved with or split by other operations. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">On most modern architectures, a load or store of a 32-bit word from or to memory is an atomic operation. So, the previous analysis reasoned about interleaving of atomic loads and stores to memory. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Conversely, a load or store is not always an atomic operation. Depending on the hardware implementation, if two threads store the value of a 64-bit floating point register to a memory address, the final result might be the first value, the second value, or a mix of the two. </FONT><A id=x1-42001r73 name=x1-42001r73></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.3 </FONT><A id=x1-430003 name=x1-430003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Too Much Milk</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Although one could, in principle, reason carefully about the possible interleavings of different threads&#8217; atomic loads and stores, doing so is tricky and error-prone. Later, we present a higher level abstraction for synchronizing threads, but first we illustrate the problems with using atomic loads and stores using a simple problem called, &#8220;Too Much Milk.&#8221; The example is intentionally simple; real-world concurrent programs are often much more complex. Even so, the example shows the difficulty of reasoning about interleaved access to shared state. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The Too Much Milk problem models two roommates who share a refrigerator and who &#8212; as good roommates &#8212; make sure the refrigerator is always well stocked with milk. With such responsible roommates, the following scenario is possible: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; <B>Roommate 1&#8217;s actions</B> </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; <B>Roommate 2&#8217;s actions</B> </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:00 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Look in fridge; out of milk. </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:05 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Leave for store. </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:10 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Arrive at store. </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Look in fridge; out of milk.</FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:15 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Buy milk. </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Leave for store. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:20 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Arrive home; put milk away. </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Arrive at store. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:25 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Buy milk. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:30 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Arrive home; put milk away. </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">3:35 </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; </FONT></P></TD>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp; Oh no! </FONT></P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE></DIV><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We can model each roommate as a thread and the number of bottles of milk in the fridge with a variable in memory. If the only atomic operations on shared state are atomic loads and stores to memory, is there a solution to the Too Much Milk problem that ensures both <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:safety property"}'>safety</A></EM> (the program never enters a bad state) and <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:liveness property"}'>liveness</A></EM> (the program eventually enters a good state)? Here, we strive for the following properties: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Safety:</B> Never more than one person buys milk. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Liveness:</B> If milk is needed, someone eventually buys it.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: <B>Simplifying Assumption.</B> Throughout the analysis in this section, we assume that the instructions are executed in exactly the order written, i.e., neither the compiler nor the architecture reorders instructions. This assumption is crucial for reasoning about the order of atomic load and store operations, but many modern compilers and architectures violate it, so be extremely careful applying the style of analysis we present here to your own programs. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Solution 1.</B> The basic idea is for a roommate to leave a note on the fridge before going to the store. The simplest way to leave this note &#8212; given our programming model that we have shared memory on which we can perform atomic loads and stores &#8212; is to set a flag when going to buy milk and to check this flag before going to buy milk. Each thread might run the following code: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;if&nbsp;(milk==0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;milk
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(note==0)&nbsp;{&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;note
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;1;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;leave&nbsp;note
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;0;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;remove&nbsp;note
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Unfortunately, this implementation can violate safety. For example, the first thread could execute everything up to and including the check of the milk value and then get context switched. Then, the second thread could run through all of this code and buy milk. Finally, the first thread could be re-scheduled, see that note is zero, leave the note, buy more milk, and remove the note, leaving the system with milk == 2. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;//&nbsp;Thread&nbsp;A&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Thread&nbsp;B
   &nbsp;if&nbsp;(milk==0)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(milk==0)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(note==0)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;1;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;0;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(note==0)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;1;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;note&nbsp;=&nbsp;0;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;}
   &nbsp;
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Oh&nbsp;no!</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This &#8220;solution&#8221; makes the problem worse! The preceding code usually works, but it may fail occasionally when the scheduler does just the right (or wrong) thing. We have created a Heisenbug that causes the program to occasionally fail in ways that may be very difficult to reproduce (e.g., probably only when the grader is looking at it or when the CEO is demonstrating a new product at a trade show). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Solution 2.</B> In solution 1, the roommate checks the note before setting it. This opens up the possibility that one roommate has already made a decision to buy milk before notifying the other roommate of that decision. If we use two variables for the notes, a roommate can create a note before checking the other note and the milk and making a decision to buy. For example, we can do the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Path A </FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;noteA&nbsp;=&nbsp;1;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;leave&nbsp;note
&nbsp;if&nbsp;(noteB==0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;note&nbsp;&nbsp;A1
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(milk==0)&nbsp;{&nbsp;//&nbsp;if&nbsp;no&nbsp;milk&nbsp;&nbsp;A2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk&nbsp;&nbsp;&nbsp;&nbsp;A3
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;noteA&nbsp;=&nbsp;0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;remove&nbsp;note&nbsp;A
 </FONT></PRE><FONT style="BACKGROUND-COLOR: #7be1e1">Path B </FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;noteB&nbsp;=&nbsp;1;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;leave&nbsp;note
&nbsp;if&nbsp;(noteA==0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;note&nbsp;&nbsp;B1
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(milk==0)&nbsp;{&nbsp;//&nbsp;if&nbsp;no&nbsp;milk&nbsp;&nbsp;B2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk&nbsp;&nbsp;&nbsp;&nbsp;B3
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B4
&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B5
&nbsp;noteB&nbsp;=&nbsp;0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;remove&nbsp;note
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If the first thread executes the Path A code and the second thread executes the Path B code, this protocol is safe; by having each thread write a note (&#8220;I might buy milk&#8221;) before deciding to buy milk, we ensure the safety property: at most one thread buys milk. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although this intuition is solid, proving the safety property without enumerating all possible interleavings requires care. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Safety Proof.</B> Assume for the sake of contradiction that the algorithm is <EM>not</EM> safe &#8212; both A and B buy milk. Consider the state of the two variables (noteB, milk) when thread A is at the line marked <B>A1</B>, at the precise moment when the atomic load of noteB from shared memory to A&#8217;s register occurs. There are three cases to consider: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Case 1:</B> (noteB = 1, milk = any value). This state contradicts the assumption that thread A buys milk and reaches <B>A3</B>. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Case 2:</B> (noteB = 0, milk &gt; 0). In this simple program, the property milk &gt; 0 is a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:stable property"}'>stable property</A></EM> &#8212; once it becomes true, it remains true forever. Thus, if milk &gt; 0 is true when A is at <B>A1</B>, A&#8217;s test at line <B>A2</B> will fail, and A will not buy milk, contradicting our assumption. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Case 3:</B> (noteB = 0, milk = 0). We know that thread B must not currently be executing any of the lines marked <B>B1-B5</B>. We also know that either noteA == 1 or milk &gt; 0 will be true from this time forward (noteA OR milk is also a stable property). This means that B cannot buy milk in the future (either the test at B1 or B2 must fail), which contradicts our assumption that both A and B buy milk. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since every case contradicts the assumption, the algorithm is safe. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Liveness.</B> Unfortunately, Solution 2 does not ensure liveness. In particular, it is possible for both threads to set their respective notes, for each thread to check the other thread&#8217;s note, and for both threads to decide not to buy milk. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This brings us to Solution 3. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Solution 3.</B> Solution 2 was safe because a thread would avoid buying milk if there were any chance that the other thread <EM>might</EM> buy milk. For Solution 3, we ensure that at least one of the threads determines whether the other thread has bought milk or not before deciding whether or not to buy. In particular, we do the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Path A </FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;noteA&nbsp;=&nbsp;1;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;leave&nbsp;note&nbsp;A
&nbsp;while&nbsp;(noteB==1)&nbsp;{&nbsp;//&nbsp;wait&nbsp;for&nbsp;no&nbsp;note&nbsp;B
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;spin
&nbsp;}
&nbsp;if&nbsp;(milk==0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;milk&nbsp;M
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk
&nbsp;}
&nbsp;noteA&nbsp;=&nbsp;0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;remove&nbsp;note&nbsp;A
 </FONT></PRE><FONT style="BACKGROUND-COLOR: #7be1e1">Path B </FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;noteB&nbsp;=&nbsp;1;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;leave&nbsp;note&nbsp;B
&nbsp;if&nbsp;(noteA==0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;note&nbsp;A
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(milk==0)&nbsp;{&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;milk
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//
&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//
&nbsp;noteB&nbsp;=&nbsp;0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;remove&nbsp;note&nbsp;B
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We can show that Solution 3 is safe using an argument similar to the one we used for Solution 2. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To show that Solution 3 is live, observe that code path B has no loops, so eventually thread B must finish executing the listed code. Eventually, noteB == 0 becomes true and remains true. Therefore, thread A must eventually reach line <B>M</B> and decide whether to buy milk. If it finds M == 1, then milk has been bought. If it finds M == 0, then it will buy milk. Either way, the liveness property &#8212; that if needed, some milk is bought &#8212; is met. </FONT><A id=x1-43001r74 name=x1-43001r74></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.4 </FONT><A id=x1-440004 name=x1-440004></A><FONT style="BACKGROUND-COLOR: #7be1e1">Discussion</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Assuming that the compiler and processor execute instructions in program order, the preceding proof shows that it is possible to devise a solution to Too Much Milk that is both safe and live using nothing but atomic load and store operations on shared memory. Although the solution we presented only works for two roommates, there is a generalization, called Peterson&#8217;s algorithm, which works with any fixed number of n threads. More details on Peterson&#8217;s algorithm can be found elsewhere (e.g., </FONT><A href="http://en.wikipedia.org/wiki/Peterson's_algorithm"><FONT style="BACKGROUND-COLOR: #7be1e1">http://en.wikipedia.org/wiki/Peterson&#8217;s_algorithm</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">). </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, our solution for Too Much Milk (and likewise Peterson&#8217;s algorithm) is not terribly satisfying: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The solution is <EM>complex</EM> and requires careful reasoning to be convinced that it works. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The solution is <EM>inefficient</EM>. In Too Much Milk, while thread A is waiting, it is <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:busy-waiting"}'>busy-waiting</A></EM> and consuming CPU resources. In Peterson&#8217;s generalized solution, <EM>all</EM> n threads can busy-wait. Busy-waiting is particularly problematic on modern systems with preemptive multi-threading, as the spinning thread may be holding the processor waiting for an event that cannot occur until some preempted thread is re-scheduled to run. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The solution <EM>may fail</EM> if the compiler or hardware reorders instructions. This limitation can be addressed by using <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:memory barrier"}'>memory barriers</A></EM> (see sidebar). Adding memory barriers would further increase the implementation complexity of the algorithm; barriers do not address the other limitations just mentioned. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Memory barriers</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose you are writing low-level code that must reason about the ordering of memory operations. How can this be done on modern hardware and with modern compilers? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM>memory barrier</EM> instruction prevents the compiler and hardware from reordering memory accesses across the barrier &#8212; no accesses before the barrier are moved after the barrier and no accesses after the barrier are moved before the barrier. One can add memory barriers to the Too Much Milk solution or to Peterson&#8217;s algorithm to get code that works on modern machines with modern compilers. Of course, this makes the code even more complex. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Details of how to issue a memory barrier instruction depend on hardware and compiler details. However, a good example is gcc&#8217;s __sync_synchronize() builtin, which tells the compiler not to reorder memory accesses across the barrier and to issue processor-specific instructions that the underlying hardware treats as a memory barrier. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-44001r75 name=x1-44001r75></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.5 </FONT><A id=x1-450005 name=x1-450005></A><FONT style="BACKGROUND-COLOR: #7be1e1">A Better Solution</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The next section describes a better approach to writing programs in which multiple threads access shared state. We write <EM>shared objects</EM> that use <EM>synchronization objects</EM> to coordinate different threads&#8217; access to shared state. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose, for example, we had a primitive called a <EM>lock</EM> that only one thread at a time can own. Then, we can solve the Too Much Milk problem by defining the class for a Kitchen object with the following method: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;Kitchen::buyIfNeeded()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(milk&nbsp;==&nbsp;0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;milk
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">After outlining a strategy for managing synchronization in the next section, we define locks and condition variables (another type of synchronization object) in Sections&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-490003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> and </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT><A id=x1-45001r71 name=x1-45001r71></A></P><A id=x1-460002 name=x1-460002>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.2 Structuring Shared Objects</FONT></H3></A><A id=x1-460011 name=x1-460011></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00400.gif" data-calibre-src="OEBPS/Images/image00400.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.1: </B>In a multi-threaded program, threads are separate from and operate concurrently on shared objects. Shared objects contain both shared state and synchronization variables, used for controlling concurrent access to shared state.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
Decades of work have developed a much simpler approach to writing multi-threaded programs than using just atomic loads and stores. This approach extends the modularity of object-oriented programming to multi-threaded programs. As Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-460011"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates, a multi-threaded program is built using <EM>shared objects</EM> and a set of threads that operate on them. </FONT>
<P><EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:shared object"}'><FONT style="BACKGROUND-COLOR: #7be1e1">Shared objects</FONT></A></EM><FONT style="BACKGROUND-COLOR: #7be1e1"> are objects that can be accessed safely by multiple threads. All shared state in a program &#8212; including variables allocated on the heap (e.g., objects allocated with malloc or new) and static, global variables &#8212; should be encapsulated in one or more shared objects. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Programming with shared objects extends traditional object-oriented programming, in which objects hide their implementation details behind a clean interface. In the same way, shared objects hide the details of synchronizing the actions of multiple threads behind a clean interface. The threads using shared objects need only understand the interface; they do not need to know how the shared object internally handles synchronization. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Like regular objects, programmers can design shared objects for whatever modules, interfaces, and semantics an application needs. Each shared object&#8217;s class defines a set of public methods on which threads operate. To assemble the overall program from these shared objects, each thread executes a &#8220;main loop&#8221; written in terms of actions on public methods of shared objects. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since shared objects encapsulate the program&#8217;s shared state, the main loop code that defines a thread&#8217;s high-level actions need not concern itself with synchronization details. The programming model thus looks very similar to that for single-threaded code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Shared objects, monitors, and syntactic sugar</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We focus on <EM>shared objects</EM> because object-oriented programming provides a good way to think about shared state: hide shared state behind public methods that provide a clean interface to threads and that handle the details of synchronization. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although we use object-oriented terminology in our discussion, the ideas are equally applicable to non-object-oriented languages. For example, where a C++ program might define a class of shared objects with public methods, a C program might define a struct with synchronization variables and state variables as fields. Rather than scattering the code that accesses the struct&#8217;s fields, a well-designed C program will have a fixed set of functions that operate on the struct&#8217;s fields. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Conversely, some programming languages build in even more support for shared objects than we describe here. When a programming language includes support for shared objects, a shared object is often called a <EM>monitor</EM>. Early languages with monitors include Brinch Hansen&#8217;s Concurrent Pascal and Xerox PARC&#8217;s Mesa; today, Java supports monitors via the synchronized keyword. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We regard the distinctions between procedural languages, object-oriented languages, and languages with built-in support for monitors as relatively unimportant syntactic sugar &#8212; they are just a different way of writing the same thing. We use the terms &#8220;shared objects&#8221; or &#8220;monitors&#8221; broadly to refer to a conceptual approach that can and should be used to manage concurrency regardless of the particular programming language. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In this book, our code and pseudo-code are based on C++&#8217;s syntax. We believe provides the right level of detail for teaching the shared objects or monitors approach. We prefer teaching with C++ to Java because we want to explicitly show where locks and condition variables are allocated and accessed rather than relying on operations hidden by a language&#8217;s built in monitor syntax. Conversely, we prefer C++ to C because we think C++&#8217;s support for object-oriented programming may help you internalize the underlying philosophy of the shared object approach. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-46002r76 name=x1-46002r76></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.2.1 </FONT><A id=x1-470001 name=x1-470001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Shared Objects</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Of course, internally the shared objects must handle the details of synchronization. As Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-470012"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows, shared objects are implemented in layers. </FONT><A id=x1-470012 name=x1-470012></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00401.gif" data-calibre-src="OEBPS/Images/image00401.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.2: </B>Multi-threaded programs are built with shared objects. Shared objects are built using synchronization variables and state variables. Synchronization variables are implemented using specialized processor instructions to manage interrupt delivery and to atomically read-modify-write memory locations.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Shared object layer.</B> As in standard object-oriented programming, shared objects define application-specific logic and hide internal implementation details. Externally, they appear to have the same interface as you would define for a single-threaded program. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Synchronization variable layer.</B> Rather than implementing shared objects directly with carefully interleaved atomic loads and stores, shared objects include <EM>synchronization variables</EM> as member variables. Synchronization variables, stored in memory just like any other object, can be included in any data structure. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:synchronization variable"}'>synchronization variable</A></EM> is a data structure used for coordinating concurrent access to shared state. Both the interface and the implementation of synchronization variables must be carefully designed. In particular, we build shared objects using two types of synchronization variables: <EM>locks</EM> and <EM>condition variables.</EM> We define these and describe how to construct them in Sections&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-490003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> and </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Synchronization variables coordinate access to <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:state variable"}'>state variables</A></EM>, which are just the normal member variables of an object that you are familiar with from single-threaded programming (e.g., integers, strings, arrays, and pointers). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Using synchronization variables simplifies implementing shared objects. In fact, not only do shared objects externally resemble traditional single-threaded objects, but, by implementing them with synchronization variables, their internal implementations are quite similar to those of single-threaded programs. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Atomic instruction layer.</B> Although the layers above benefit from a simpler programming model, it is not turtles all the way down. Internally, synchronization variables must manage the interleavings of different threads&#8217; actions. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Rather than implementing synchronization variables, such as locks and condition variables, using atomic loads and stores as we tried to do for the Too Much Milk problem, modern implementations build synchronization variables using <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:atomic read-modify-write instruction"}'>atomic read-modify-write instructions</A></EM>. These processor-specific instructions let one thread have temporarily exclusive and atomic access to a memory location while the instruction executes. Typically, the instruction atomically reads a memory location, does some simple arithmetic operation to the value, and stores the result. The hardware guarantees that any other thread&#8217;s instructions accessing the same memory location will occur either entirely before, or entirely after, the atomic read-modify-write instruction. </FONT></P></LI></UL><A id=x1-47002r79 name=x1-47002r79></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.2.2 </FONT><A id=x1-480002 name=x1-480002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Scope and Roadmap</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">As Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-470012"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> indicates, concurrent programs are built on top of shared objects. The rest of this chapter focuses on the middle layers of the figure &#8212; how to build shared objects using synchronization objects and how to build synchronization objects out of atomic read-modify-write instructions. Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-780006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> discusses issues that arise when composing multiple shared objects into a larger program. </FONT><A id=x1-48001r77 name=x1-48001r77></A><A id=x1-490003 name=x1-490003>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.3 Locks: Mutual Exclusion</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:lock"}'>lock</A></EM> is a synchronization variable that provides <EM>mutual exclusion</EM> &#8212; when one thread holds a lock, no other thread can hold it (i.e., other threads are <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:mutual exclusion"}'>excluded</A></EM>). A program associates each lock with some subset of shared state and requires a thread to hold the lock when accessing that state. Then, only one thread can access the shared state at a time. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Mutual exclusion greatly simplifies reasoning about programs because a thread can perform an arbitrary set of operations while holding a lock, and those operations <EM>appear to be atomic</EM> to other threads. In particular, because a lock enforces mutual exclusion and threads must hold the lock to access shared state, no other thread can observe an intermediate state. Other threads can only observe the state left after the lock release. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: Locking to group multiple operations.</B> Consider, for example, a bank account object that includes a list of transactions and a total balance. To add a new transaction, we acquire the account&#8217;s lock, append the new transaction to the list, read the old balance, modify it, write the new balance, and release the lock. To query the balance and list of recent transactions, we acquire the account&#8217;s lock, read the recent transactions from the list, read the balance, and release the lock. Using locks in this way guarantees that one update or query completes before the next one starts. Every query always reflects the complete set of recent transactions. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Another example of grouping is when printing output. Without locking, if two threads called printf at the same time, the individual characters of the two messages could be interleaved, garbling their meaning. Instead, on modern multi-threaded operating systems, printf uses a lock to ensure that the group of characters in each message prints as a unit. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">It is much easier to reason about interleavings of atomic groups of operations rather than interleavings of individual operations for two reasons. First, there are (obviously) fewer interleavings to consider. Reasoning about interleavings on a coarser-grained basis reduces the sheer number of cases to consider. Second, and more important, we can make each atomic group of operations correspond to the logical structure of the program, which allows us to reason about <EM>invariants</EM> not specific <EM>interleavings</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In particular, shared objects usually have one lock guarding all of an object&#8217;s state. Each public method acquires the lock on entry and releases the lock on exit. Thus, reasoning about a shared class&#8217;s code is similar to reasoning about a traditional class&#8217;s code: we assume a set of invariants when a public method is called and re-establish those invariants before a public method returns. If we define our invariants well, we can then reason about each method independently. </FONT><A id=x1-49001r81 name=x1-49001r81></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.3.1 </FONT><A id=x1-500001 name=x1-500001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Locks: API and Properties</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">A lock enables mutual exclusion by providing two methods: Lock::acquire() and Lock::release(). These methods are defined as follows: </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A lock can be in one of two states: BUSY&nbsp;or FREE. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A lock is initially in the FREE&nbsp;state. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Lock::acquire waits until the lock is FREE&nbsp;and then atomically makes the lock BUSY. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Checking the state to see if it is FREE&nbsp;and setting the state to BUSY&nbsp;are together an <EM>atomic operation</EM>. Even if multiple threads try to acquire the lock, at most one thread will succeed. One thread observes that the lock is FREE&nbsp;and sets it to BUSY; the other threads just see that the lock is BUSY&nbsp;and wait. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Lock::release makes the lock FREE. If there are pending <TT>acquire</TT>&nbsp;operations, this state change causes one of them to proceed. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We describe how to implement locks with these properties in Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-660007"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. Using locks makes solving the Too Much Milk problem trivial. Both threads run the following code: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;lock.acquire();
   &nbsp;if&nbsp;(milk&nbsp;==&nbsp;0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;if&nbsp;no&nbsp;milk
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;milk++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;buy&nbsp;milk
   &nbsp;}
   &nbsp;lock.release();</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Many routines in an operating system kernel need to allocate and de-allocate memory blocks. Assuming you are given the code for a single-threaded kernel memory allocator, explain how to implement a thread-safe memory allocator. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>Using C malloc and free as an example, we can convert them to be thread-safe by acquiring a lock before accessing the heap, and releasing it after the block has been allocated or freed. Since malloc and free read and modify the same data structures, it is essential to use the <EM>same</EM> lock in both procedures, heaplock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;char&nbsp;*malloc&nbsp;(int&nbsp;n)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;char&nbsp;*p;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heaplock.acquire();
&nbsp;&nbsp;//&nbsp;Code&nbsp;for&nbsp;single-threaded&nbsp;malloc()
&nbsp;&nbsp;//&nbsp;p&nbsp;=&nbsp;allocate&nbsp;block&nbsp;of&nbsp;memory
&nbsp;&nbsp;//&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;size&nbsp;n.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heaplock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;p;
&nbsp;}
 </FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;void&nbsp;free&nbsp;(char&nbsp;*p)&nbsp;{
&nbsp;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heaplock.acquire();
&nbsp;&nbsp;//&nbsp;Code&nbsp;for&nbsp;single-threaded&nbsp;free()
&nbsp;&nbsp;//&nbsp;Put&nbsp;p&nbsp;back&nbsp;on&nbsp;free&nbsp;list.
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heaplock.release();
&nbsp;
&nbsp;}
 </FONT></PRE>
<P><BR><FONT style="BACKGROUND-COLOR: #7be1e1">&#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Formal properties.</B> A lock can be defined more precisely as follows. A thread <EM>holds a lock</EM> if it has returned from a lock&#8217;s <TT>acquire</TT>&nbsp;method more often than it has returned from a lock&#8217;s <TT>release</TT>&nbsp;method. A thread <EM>is attempting to acquire</EM> a lock if it has called but not yet returned from a call to <TT>acquire</TT>&nbsp;on the lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A lock should ensure the following three properties: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-50002x1 name=x1-50002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Mutual Exclusion.</B> At most one thread holds the lock. </FONT></P>
<LI class=enumerate><A id=x1-50004x2 name=x1-50004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Progress.</B> If no thread holds the lock and any thread attempts to acquire the lock, then eventually some thread succeeds in acquiring the lock. </FONT></P>
<LI class=enumerate><A id=x1-50006x3 name=x1-50006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Bounded waiting.</B> If thread T attempts to acquire a lock, then there exists a bound on the number of times other threads can successfully acquire the lock before T does. </FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Mutual exclusion is a safety property because locks prevent more than one thread from accessing shared state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Progress and bounded waiting are liveness properties. If a lock is FREE, <EM>some</EM> thread must be able to acquire it. Further, any <EM>particular</EM> thread that wants to acquire the lock must eventually succeed in doing so. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If these definitions sound stilted, it is because we have carefully crafted them to avoid introducing subtle corner cases. For example, if a thread holding a lock never releases it, other threads cannot make progress, so we define the <EM>bounded waiting</EM> condition in terms of successful <TT>acquire</TT>&nbsp;operations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: <B>Non-property: Thread ordering.</B> The <EM>bounded waiting</EM> property defined above guarantees that a thread will eventually get a chance to acquire the lock. However, it does not promise that waiting threads acquire the lock in FIFO order. Most implementations of locks that you will encounter &#8212; for example with POSIX threads &#8212; do not provide FIFO ordering. </FONT><A id=x1-50007r83 name=x1-50007r83></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.3.2 </FONT><A id=x1-510002 name=x1-510002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Case Study: Thread-Safe Bounded Queue</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">As in standard object-oriented programming, each shared object is an instance of a class that defines the class&#8217;s state and the methods that operate on that state. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The class&#8217;s state includes both state variables (e.g., ints, floats, strings, arrays, and pointers) and synchronization variables (e.g., locks). Every time a class constructor produces another instance of a shared object, it allocates both a new lock and new instances of the state protected by that lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:bounded queue"}'>bounded queue</A></EM> is a queue with a fixed size limit on the number of items stored in the queue. Operating system kernels use bounded queues for managing interprocess communication, TCP and UDP sockets, and I/O requests. Because the kernel runs in a finite physical memory, the kernel must be designed to work properly with finite resources. For example, instead of a simple, infinite buffer between a producer and a consumer thread, the kernel will instead use a limited size buffer, or bounded queue. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:thread-safe bounded queue"}'>thread-safe bounded queue</A></EM> is a type of a bounded queue that is safe to call from multiple concurrent threads. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-510013"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> gives an implementation; it lets any number of threads safely insert and remove items from the queue. As Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-510024"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates, a program can allocate multiple such queues (e.g., queue1, queue2, and queue3), each of which includes its own lock and state variables. </FONT><A id=x1-510013 name=x1-510013></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Thread-safe&nbsp;queue&nbsp;interface
&nbsp;
&nbsp;const&nbsp;int&nbsp;MAX&nbsp;=&nbsp;10;
&nbsp;
&nbsp;class&nbsp;TSQueue&nbsp;{
&nbsp;&nbsp;&nbsp;//&nbsp;Synchronization&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;
&nbsp;&nbsp;&nbsp;//&nbsp;State&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;items[MAX];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;front;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;nextEmpty;
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TSQueue();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~TSQueue(){};
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;tryInsert(int&nbsp;item);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;tryRemove(int&nbsp;*item);
&nbsp;};
</FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Initialize&nbsp;the&nbsp;queue&nbsp;to&nbsp;empty
&nbsp;//&nbsp;and&nbsp;the&nbsp;lock&nbsp;to&nbsp;free.
&nbsp;TSQueue::TSQueue()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;front&nbsp;=&nbsp;nextEmpty&nbsp;=&nbsp;0;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Try&nbsp;to&nbsp;insert&nbsp;an&nbsp;item.&nbsp;If&nbsp;the&nbsp;queue&nbsp;is
&nbsp;//&nbsp;full,&nbsp;return&nbsp;false;&nbsp;otherwise&nbsp;return&nbsp;true.
&nbsp;bool
&nbsp;TSQueue::tryInsert(int&nbsp;item)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;success&nbsp;=&nbsp;false;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;((nextEmpty&nbsp;-&nbsp;front)&nbsp;&lt;&nbsp;MAX)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;items[nextEmpty&nbsp;%&nbsp;MAX]&nbsp;=&nbsp;item;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextEmpty++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;success&nbsp;=&nbsp;true;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;success;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Try&nbsp;to&nbsp;remove&nbsp;an&nbsp;item.&nbsp;If&nbsp;the&nbsp;queue&nbsp;is
&nbsp;//&nbsp;empty,&nbsp;return&nbsp;false;&nbsp;otherwise&nbsp;return&nbsp;true.
&nbsp;bool
&nbsp;TSQueue::tryRemove(int&nbsp;*item)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;success&nbsp;=&nbsp;false;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(front&nbsp;&lt;&nbsp;nextEmpty)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*item&nbsp;=&nbsp;items[front&nbsp;%&nbsp;MAX];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;front++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;success&nbsp;=&nbsp;true;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;success;
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.3: </B>A thread-safe bounded queue. For implementation simplicity, we assume the queue stores integers (rather than arbitrary objects) and the total number of items stored is modest.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><A id=x1-510024 name=x1-510024></A>
<CENTER><FONT style="BACKGROUND-COLOR: #7be1e1"><img alt="" src="file:///[PrimaryStorage]Images/image00402.gif" data-calibre-src="OEBPS/Images/image00402.gif"> </FONT></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.4: </B>Three shared objects, each an instance of class TSQueue.</FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The queue stores only a fixed number, MAX, of items. When the queue is full, an insert request returns an error. Similarly, when the queue is empty, a remove request returns an error. Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows how <EM>condition variables</EM> let the calling thread <EM>wait</EM> instead of returning an error. On insert, the thread waits until the queue has space to store the item and, on remove, it waits until the queue has at least one item queued before returning it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The TSQueue implementation defines a circular queue that stores data in a fixed size array, items[MAX]. The state variable, front is the next item in the queue to be removed, if any; nextEmpty is the next location for a new item, if any. To keep the example as simple as possible, only items of type int can be stored in and removed from the queue, and we assume the total number of items stored fits within a 64 bit integer. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">All of these variables are as they would be for a single-threaded version of this object. The lock allows tryInsert and tryRemove to atomically read and write multiple variables just as a single-threaded version would. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What constraints are true of TSQueue at the moment immediately after the lock is acquired? What constraints hold immediately before the lock is released? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>Because the lock enforces mutual exclusion and is always held whenever a thread modifies a state variable, when the lock is acquired the object&#8217;s state variables must be either: (i) in the initial state or (ii) in the state left by a previous thread when it released the lock. These constraints are the same as for single-threaded code using a bounded queue: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The total number of items ever inserted in the queue is nextEmpty. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The total number of items ever removed from the queue is front. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">front &lt;= nextEmpty </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The current number of items in the queue is nextEmpty - front. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">nextEmpty - front &lt;= MAX</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The lock holder always re-establishes these constraints before releasing the lock. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Are these constraints also true if the lock is not held? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>No.</B> It seems intuitive that if the constraints hold immediately before the lock is released, then they must also hold immediately after the lock is released. However, this is not the case. In the meantime, some other thread may have acquired the lock and may be in the process of modifying the state variables. In general, if the lock is not held, one cannot say <EM>anything</EM> about the object&#8217;s state variables. &#9633; </FONT></P>
<H5 class=subsubsectionHead><A id=x1-520002 name=x1-520002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Critical Sections</FONT></H5><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:critical section"}'>critical section</A></EM> is a sequence of code that atomically accesses shared state. By ensuring that a thread holds the object&#8217;s lock while executing any of its critical sections, we ensure that each critical section appears to execute atomically on its shared state. There is a critical section in each of the methods tryInsert and tryRemove. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Notice two things: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Each class can define multiple methods that operate on the shared state defined by the class, so there may be <EM>multiple critical sections per class</EM>. However, for each instance of the class (i.e., for each object), only one thread holds the object&#8217;s lock at a time, so <EM>only one thread actively executes any of the critical sections per shared object instance.</EM> For the TSQueue class, if one thread calls queue1.tryInsert and another calls queue1.tryRemove, the insert occurs either before the remove or vice versa. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A program can create <EM>multiple instances of a class</EM>. Each instance is a shared object, and each shared object has its own lock. Thus, different threads may be active in the critical sections for different shared object instances. For the TSQueue class, if one thread calls queue1.tryInsert, another thread calls queue2.tryRemove, and a third thread calls queue3.tryInsert, all three threads may be simultaneously executing critical section code operating on <EM>different instances</EM> of the TSQueue class. </FONT></P></LI></UL>
<H5 class=subsubsectionHead><A id=x1-530002 name=x1-530002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Using Shared Objects</FONT></H5><FONT style="BACKGROUND-COLOR: #7be1e1">Shared objects are allocated in the same way as other objects. They can be dynamically allocated from the heap using malloc and new, or they can be statically allocated in global memory by declaring static variables in the program. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Multiple threads must be able to access shared objects. If shared objects are global variables, then a thread&#8217;s code can refer to an object&#8217;s global name to reference it; the compiler computes the corresponding address. If shared objects are dynamically allocated, then each thread that uses an object needs a pointer or reference to it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Two common ways to provide a thread a pointer to a shared object are: (1) provide a pointer to the shared object when the thread is created, and (2) store references to shared objects in other shared objects (e.g., containers). For example, a program might have a global, shared (and synchronized!) hash table that threads can use to store and retrieve references to other shared objects. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-530015"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows a simple program that creates three queues and then creates some threads that insert into these queues. It then removes 20 items from each queue and prints the values it removes. The initial main thread allocates the shared queues on the heap using new, and provides each worker thread a pointer to one of the shared queues. </FONT><A id=x1-530015 name=x1-530015></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;TSQueueMain.cc
&nbsp;//&nbsp;&nbsp;&nbsp;Test&nbsp;code&nbsp;for&nbsp;TSQueue.
&nbsp;
&nbsp;int&nbsp;main(int&nbsp;argc,&nbsp;char&nbsp;**argv)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TSQueue&nbsp;*queues[3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sthread_t&nbsp;workers[3];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;i,&nbsp;j;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Start&nbsp;worker&nbsp;threads&nbsp;to&nbsp;insert.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;3;&nbsp;i++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;queues[i]&nbsp;=&nbsp;new&nbsp;TSQueue();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_create_p(&amp;workers[i],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putSome,&nbsp;queues[i]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Wait&nbsp;for&nbsp;some&nbsp;items&nbsp;to&nbsp;be&nbsp;put.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_join(workers[0]);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Remove&nbsp;20&nbsp;items&nbsp;from&nbsp;each&nbsp;queue.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;3;&nbsp;i++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Queue&nbsp;%d:\n",&nbsp;i);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;testRemoval(&amp;queues[i]);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Insert&nbsp;50&nbsp;items&nbsp;into&nbsp;a&nbsp;queue.
&nbsp;void&nbsp;*putSome(void&nbsp;*p)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TSQueue&nbsp;*queue&nbsp;=&nbsp;(TSQueue&nbsp;*)p;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;i;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;50;&nbsp;i++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;queue-&gt;tryInsert(i);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;NULL;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Remove&nbsp;20&nbsp;items&nbsp;from&nbsp;a&nbsp;queue.
&nbsp;void&nbsp;testRemoval(TSQueue&nbsp;*queue)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;i,&nbsp;item;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;20;&nbsp;j++)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(queue-&gt;tryRemove(&amp;item))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Removed&nbsp;%d\n",&nbsp;item);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("Nothing&nbsp;there.\n");
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.5: </B>This code creates three TSQueue objects and then adds and removes some items from these queues. We use thread_create_p instead of thread_create so that we can pass to the newly created thread a pointer to the queue it should use.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: <B>Put shared objects on the heap, not the stack.</B> While nothing prevents you from writing a program that allocates a shared object as an automatic variable in a procedure or method, you should not write programs that do this. The compiler allocates automatic variables (sometimes called &#8220;local variables&#8221;, with good reason) on the stack during procedure invocation. If one thread passes a pointer or reference to one of its automatic variables to another thread and later returns from the procedure where the automatic variable was allocated, then that second thread now has a pointer into a region of the first thread&#8217;s stack that may be used for other purposes. To prevent this error, a few garbage-collected languages, such as Google&#8217;s Go, automatically convert all automatic data to being heap-allocated if the data can be referenced outside of the procedure. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">You might be tempted to argue that, for a particular program, you know that the procedure will never return until all of the threads with which it is sharing an object are done using that object, and that therefore sharing one of the procedure&#8217;s local variables is safe. The problem with this argument is that the code may change over time, introducing a dangerous and subtle bug. When sharing dynamically allocated variables, it is best to stay in the habit of sharing variables only from the heap &#8212; and never sharing variables from the stack &#8212; across threads. </FONT><A id=x1-53002r82 name=x1-53002r82></A></P><A id=x1-540004 name=x1-540004>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.4 Condition Variables: Waiting for a Change</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Condition variables provide a way for one thread to wait for another thread to take some action. For example, in the thread-safe queue example in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-510013"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, rather than returning an error when we try to remove an item from an empty queue, we might wait until the queue is non-empty, and then always return an item. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Similarly, a web server might wait until a new request arrives; a word processor might wait for a key to be pressed; a weather simulator&#8217;s coordinator thread might wait for the worker threads calculating temperatures in each region to finish; or, in our </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-110001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">Earth Visualizer</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> example, a thread in charge of rendering part of the screen might wait for a user command or for new data to update the view. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In all of these cases, we want a thread to wait for some action to change the system state so that the thread can make progress. </FONT><A id=x1-540016 name=x1-540016></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;int
&nbsp;TSQueue::remove()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;item;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;success;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;do&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;success&nbsp;=&nbsp;tryRemove(&amp;item);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;until(success);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;item;
&nbsp;}</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.6: </B>A polling-based implementation of TSQueue::remove. The code retries in a loop until it succeeds in removing an item.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One way for a thread to wait would be to poll &#8212; to repeatedly check the shared state to see if it has changed. As shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, a polling implementation of remove would have a simple wrapper that repeatedly calls tryRemove until it returns success. Unfortunately, this approach is inefficient: the waiting thread continually loops, or busy-waits, consuming processor cycles without making useful progress. Worse, busy-waiting can delay the scheduling of other threads &#8212; perhaps exactly the thread for which the looping thread is waiting. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>The sleep fix?</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We often find that students want to &#8220;fix&#8221; the polling-based approach by adding a delay. For example, in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-540016"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, we could add a call to sleep to yield the processor for (say) 100 ms after each unsuccessful tryRemove call. This would allow some other thread to run while the waiting thread is waiting. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This approach has two problems. First, although it reduces the inefficiency of polling, it does not eliminate it. Suspending and scheduling a thread imposes non-trivial overheads, and a program with many polling threads would still waste significant resources. Second, periodic polling adds latency. In our Earth Visualizer example, if the thread waiting for keyboard input waited 100 ms between each check, the application might become noticeably more sluggish. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As an extreme example, one of the authors once had an employee implement a network server that provided several layers of processing, where each layer had a thread that received work from the layer above and sent the work to the layer below. Measurements of the server showed surprisingly bad performance; we expected each request to take a few milliseconds, but instead each took just over half a second. Fortunately, the performance was so poor that it was easy to track down the problem: layers passed work to each other through bounded queues much like TSQueue, but the queue remove method was implemented as a polling loop with a 100 ms delay. With five such layers of processing, the server became unusable. Fortunately, the fix was simple: use condition variables instead. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-54002r84 name=x1-54002r84></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.4.1 </FONT><A id=x1-550001 name=x1-550001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Condition Variable Definition</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">A <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:condition variable"}'>condition variable</A></EM> is a synchronization object that lets a thread efficiently wait for a change to shared state that is protected by a lock. A condition variable has three methods: </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>CV::wait(Lock *lock).</B> This call atomically <EM>releases the lock</EM> and <EM>suspends execution of the calling thread</EM>, placing the calling thread on the condition variable&#8217;s waiting list. Later, when the calling thread is re-enabled, it <EM>re-acquires the lock</EM> before returning from the <TT>wait</TT>&nbsp;call. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>CV::signal().</B> This call takes one thread off the condition variable&#8217;s waiting list and marks it as eligible to run (i.e., it puts the thread on the scheduler&#8217;s ready list). If no threads are on the waiting list, <TT>signal</TT>&nbsp;has no effect. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>CV::broadcast().</B> This call takes all threads off the condition variable&#8217;s waiting list and marks them as eligible to run. If no threads are on the waiting list, <TT>broadcast</TT>&nbsp;has no effect. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: Note that condition variable <TT>wait</TT>&nbsp;and <TT>signal</TT>&nbsp;are different from the UNIX system calls wait and signal. The nomenclature is unfortunate but longstanding. In this book, we always use the terms, UNIX wait and UNIX signal, to refer to the UNIX variants, and simple <TT>wait</TT>&nbsp;and <TT>signal</TT>&nbsp;to refer to condition variable operations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A condition variable is used to wait for a change to shared state, and a lock must always protect updates to shared state. Thus, the condition variable API is designed to work in concert with locks. All three methods (<TT>wait</TT>, <TT>signal</TT>, and <TT>broadcast</TT>) should only be called while the associated lock is held. </FONT><A id=x1-550017 name=x1-550017></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;SharedObject::someMethodThatWaits()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;//&nbsp;Read&nbsp;and/or&nbsp;write&nbsp;shared&nbsp;state&nbsp;here.
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(!testOnSharedState())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(testOnSharedState());
&nbsp;
&nbsp;//&nbsp;Read&nbsp;and/or&nbsp;write&nbsp;shared&nbsp;state&nbsp;here.
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;SharedObject::someMethodThatSignals()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;//&nbsp;Read&nbsp;and/or&nbsp;write&nbsp;shared&nbsp;state&nbsp;here.
&nbsp;
&nbsp;//&nbsp;If&nbsp;state&nbsp;has&nbsp;changed&nbsp;in&nbsp;a&nbsp;way&nbsp;that
&nbsp;//&nbsp;could&nbsp;allow&nbsp;another&nbsp;thread&nbsp;to&nbsp;make
&nbsp;//&nbsp;progress,&nbsp;signal&nbsp;(or&nbsp;broadcast).
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv.signal();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.7: </B>Design patterns for waiting using a condition variable (top) and for waking up a waiter (bottom). Since many critical sections need to both <TT>wait</TT>&nbsp;and <TT>signal</TT>, these two design patterns are often combined in one method. </FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The standard design pattern for a shared object is a lock and zero or more condition variables. A method that waits using a condition variable works as shown on the top in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-550017"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. In this code, the calling thread first acquires the lock and can then read and write the shared object&#8217;s state variables. To wait until testOnSharedState succeeds, the thread calls <TT>wait</TT>&nbsp;on the shared object&#8217;s condition variable cv. This atomically puts the thread on the waiting list and releases the lock, allowing other threads to enter the critical section. Once the waiting thread is signaled, it re-acquires the lock and returns from <TT>wait</TT>. The monitor can then safely test the state variables to see if testOnSharedState succeeds. If so, the monitor performs its tasks, releases the lock, and returns. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The bottom of Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-550017"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the complementary code that causes a waiting thread to wake up. Whenever a thread changes the shared object&#8217;s state in a way that enables a waiting thread to make progress, the thread must signal the waiting thread using the condition variable. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A thread waiting on a condition variable must inspect the object&#8217;s state in a loop. The condition variable&#8217;s <TT>wait</TT>&nbsp;method releases the lock (to let other threads change the state of interest) and then re-acquires the lock (to check that state again). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Similarly, the only reason for a thread to <TT>signal</TT>&nbsp;(or <TT>broadcast</TT>) is that it has just changed the shared state in a way that may be of interest to a waiting thread. To make a change to shared state, the thread must hold the lock on the state variables, so <TT>signal</TT>&nbsp;and <TT>broadcast</TT>&nbsp;are also always called while holding a lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Discussion.</B> Condition variables have been carefully designed to work in tandem with locks and shared state. The precise definition of condition variables includes three properties worth additional comment: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A condition variable is <EM>memoryless</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The condition variable, itself, has no internal state other than a queue of waiting threads. Condition variables do not need their own state because they are always used inside shared objects that have their own state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If no threads are currently on the condition variable&#8217;s waiting list, a <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;has no effect. No thread calls <TT>wait</TT>&nbsp;unless it holds the lock, checks the state variables, and finds that it needs to wait. Thus, the condition variable has no &#8220;memory&#8221; of earlier calls to <TT>signal</TT>&nbsp;or <TT>broadcast</TT>. After <TT>signal</TT>&nbsp;is called, if sometime later another thread calls <TT>wait</TT>, it will block until the <EM>next</EM> <TT>signal</TT>&nbsp;(or <TT>broadcast</TT>) is called, regardless of how many times <TT>signal</TT>&nbsp;has been called in the past. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><EM>CV::wait atomically releases the lock.</EM> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A thread always calls <TT>wait</TT>&nbsp;while holding a lock. The call to <TT>wait</TT>&nbsp;<EM>atomically</EM> releases the lock and puts the thread on the condition variable&#8217;s waiting list. Atomicity ensures that there is no separation between checking the shared object&#8217;s state, deciding to wait, adding the waiting thread to the condition variable&#8217;s queue, and releasing the lock so that some other thread can access the shared object. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If threads released the lock before calling <TT>wait</TT>, they could miss a signal or broadcast and wait forever. Consider the case where thread T<SUB>1</SUB> checks an object&#8217;s state and decides to wait, so it releases the lock in anticipation of putting itself on the condition variable&#8217;s waiting list. At that precise moment, T<SUB>2</SUB> preempts T<SUB>1</SUB>. T<SUB>2</SUB> acquires the lock, changes the object&#8217;s state to what T<SUB>1</SUB> wants, and calls <TT>signal</TT>, but the waiting list is empty so the call to <TT>signal</TT>&nbsp;has no effect. Finally, T<SUB>1</SUB> runs again, puts itself on the waiting list, and suspends execution. The lack of atomicity means that T<SUB>1</SUB> missed the signal and is now waiting, potentially forever. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Once <TT>wait</TT>&nbsp;releases the lock, any number of threads might run before <TT>wait</TT>&nbsp;re-acquires the lock after a <TT>signal</TT>. In the meantime, the state variables might have changed &#8212; in fact, they are almost <EM>certain</EM> to have changed. Code must not assume just because something was true before <TT>wait</TT>&nbsp;was called, it remains true when <TT>wait</TT>&nbsp;returns. The only assumption you should make on return from <TT>wait</TT>&nbsp;is that the lock is held, and the normal invariants that hold at the start of the critical section are true. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When a waiting thread is re-enabled via <TT>signal</TT>&nbsp;or <TT>broadcast</TT>, <EM>it may not run immediately</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When a waiting thread is re-enabled, it is moved to the scheduler&#8217;s ready queue with no special priority, and the scheduler may run it at some later time. Furthermore, when the thread finally does run, it must re-acquire the lock, which means that other threads may have acquired and released the lock in the meantime, between when the signal occurs and when the waiter re-acquires the lock. Therefore, even if the desired predicate were true when <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;was called, it may no longer be true when <TT>wait</TT>&nbsp;returns. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This may seem like a small window of vulnerability, but concurrent programs must work with all possible schedules. Otherwise, programs may fail sometimes, but not always, making debugging very difficult. See the sidebar on Mesa vs. Hoare semantics for a discussion of the history behind this property. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: The points above have an important implication for programmers: <TT>wait</TT>&nbsp;<EM>must always be called from within a loop</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Because <TT>wait</TT>&nbsp;releases the lock, and because there is no guarantee of atomicity between <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;and the return of a call to <TT>wait</TT>, there is no guarantee that the checked-for state still holds. Therefore, a waiting thread must always wait in a loop, rechecking the state until the desired predicate holds. Thus, the design pattern is: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;...
   &nbsp;while&nbsp;(predicateOnStateVariables(...))&nbsp;{
   &nbsp;&nbsp;&nbsp;wait(&amp;lock);
   &nbsp;}
   &nbsp;...</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">and not: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;...
   &nbsp;if&nbsp;(predicateOnStateVariables(...))&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wait(&amp;lock);
   &nbsp;}
   &nbsp;...</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">There are two fundamental reasons why condition variables impose this requirement: to simplify the implementation and to improve modularity. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Simplifying the implementation.</B> When a waiting thread is re-enabled, it may not run immediately. Other threads may access the shared state before it runs, and the desired predicate on the shared state may no longer hold when <TT>wait</TT>&nbsp;finally does return. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This behavior simplifies the implementation of condition variables without increasing the complexity of the code that uses them. No special code is needed for scheduing; <TT>signal</TT>&nbsp;puts the signaled thread onto the ready list and lets the scheduler choose when to run it. Similarly, no special code is needed to re-acquire the lock at the end of <TT>wait</TT>. The woken thread calls <TT>acquire</TT>&nbsp;when it is re-scheduled. As with any attempt to acquire a lock, it may succeed immediately, or it may wait if some other thread acquired the lock first. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Some implementations go even further and warn that a call to <TT>wait</TT>&nbsp;may return even if no thread has called <TT>signal</TT>&nbsp;or <TT>broadcast</TT>. So, not only is it possible that the desired predicate on the state <EM>is no longer true</EM>, it is possible that the desired predicate on the state <EM>was never true.</EM> For example, the Java definition of condition variables allows for &#8220;spurious wakeups&#8221;: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=makequote><FONT style="BACKGROUND-COLOR: #7be1e1">When waiting upon a Condition, a &#8220;spurious wakeup&#8221; is permitted to occur, in general, as a concession to the underlying platform semantics. This has little practical impact on most application programs as a Condition should always be waited upon in a loop, testing the state predicate that is being waited for. An implementation is free to remove the possibility of spurious wakeups but it is recommended that applications programmers always assume that they can occur and so always wait in a loop.<BR>(From </FONT><A href="https://docs.oracle.com/javase/8/docs/api/"><FONT style="BACKGROUND-COLOR: #7be1e1">https://docs.oracle.com/javase/8/docs/api/</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">)</FONT></DIV>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Improving modularity.</B> Waiting in a loop that checks the shared state makes shared objects&#8217; code more modular because we can reason about when the thread will continue by looking only at the <TT>wait</TT>&nbsp;loop. In particular, we do not need to examine the rest of the shared object&#8217;s code to understand where and why calls to <TT>signal</TT>&nbsp;and <TT>broadcast</TT>&nbsp;are made to know the post-condition for the <TT>wait</TT>&nbsp;loop. For example, in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-550017"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.7</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, we know the assert call will never fail without having to look at any other code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Not only does waiting in a loop simplify writing and reasoning about the code that waits, it simplifies writing and reasoning about the code that signals or broadcasts. Signaling at the wrong time will never cause a waiting thread to proceed when it should not. Signal and <TT>broadcast</TT>&nbsp;can be regarded as <EM>hints</EM> that it <EM>might</EM> be a good time to proceed; if the hints prove to be wrong, no damage is done. You can always convert a <TT>signal</TT>&nbsp;to a <TT>broadcast</TT>, or add any number of <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;calls, without changing the semantics of a shared object. Avoiding extra <TT>signal</TT>&nbsp;and <TT>broadcast</TT>&nbsp;calls may matter for performance, but not for correctness.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Bottom line:</B> Given the range of possible implementations and the modularity benefits, <TT>wait</TT>&nbsp;must always be done from within a loop that tests the desired predicate. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Mesa vs. Hoare semantics</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In modern condition variables, <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;calls take waiting threads from a condition variable&#8217;s waiting list and put them on the ready list. Later, when these threads are scheduled, they may block for some time while they try to re-acquire the lock. Thus, modern condition variables implement what are often called <EM>Mesa Semantics</EM> (for Mesa, an early programming language at Xerox PARC that implemented these semantics). Despite the name, Mesa was not the first system to use &#8220;Mesa&#8221; semantics; Brinch Hansen had proposed their use five years earlier. However, PARC was the first to use Mesa semantics extensively in a very large operating system, and the name stuck. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">C.A.R. &#8220;Tony&#8221; Hoare proposed a different definition for condition variables. Under <EM>Hoare semantics</EM>, when a thread calls <TT>signal</TT>, execution of the signaling thread is suspended, the ownership of the lock is immediately transferred to one of the waiting threads, and execution of that thread is immediately resumed. Later, when the resumed thread releases the lock, ownership of the lock reverts to the signaling thread, whose execution continues. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Under Hoare semantics, signaling is atomic with the resumption of a waiting thread, and a signaled thread may assume that the state has not changed since the signal that woke it up was issued. Under Mesa semantics, waiting is always done in a loop: while (predicate()) {cv.wait(&amp;lock);}. Under Hoare semantics, waiting can be done with a simple conditional: if (predicate()) {cv.wait(&amp;lock);}. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Mesa semantics are much more widely used, but some argue that the atomicity of signaling and resuming a waiting process makes it easier to prove liveness properties of programs under Hoare semantics. If we know that one thread is waiting on a condition, and we do a signal, we know that the waiting thread (and not some other late-arriving thread) will resume and make progress. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The authors of this book come down strongly on the side of Mesa semantics. The modularity advantages of Mesa greatly simplify reasoning about an object&#8217;s core safety properties. For the properties we care most about (i.e., the safety properties that threads proceed only when they are supposed to) and for large programs where modularity matters, Mesa semantics seem vastly preferable. Later in this chapter, we will explain how to implement FIFO queueing with Mesa semantics, for where liveness concerns are paramount. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As a practical matter the debate has been settled: essentially all systems, including both Java and POSIX, use Mesa semantics. We know of no widely used system that implements Hoare semantics. Programmers that assume the weaker Mesa semantics &#8212; always writing while (predicate()) &#8212; will write programs that work under either definition. The overhead of the &#8220;extra&#8221; check of the predicate upon return from wait in a while loop is unlikely to be significant compared to the signaling and scheduling overheads. As a programmer, you will not go wrong if you write your code assuming Mesa semantics. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-55002r92 name=x1-55002r92></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.4.2 </FONT><A id=x1-560002 name=x1-560002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Thread Life Cycle Revisited</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> discussed how a thread can switch between the READY, WAITING, and RUNNING&nbsp;states. We now explain the WAITING&nbsp;state in more detail. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A RUNNING&nbsp;thread that calls <TT>wait</TT>&nbsp;is put in the WAITING&nbsp;state. This is typically implemented by moving the thread control block (TCB) from the ready list to the condition variable&#8217;s list of waiting threads. Later, when some RUNNING&nbsp;thread calls <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;on that condition variable, one (if <TT>signal</TT>) or all (if <TT>broadcast</TT>) of the TCBs on that condition variable&#8217;s waiting list are moved to the ready list. This changes those threads from the WAITING&nbsp;state to the READY&nbsp;state. At some later time, the scheduler selects a READY&nbsp;thread and runs it by moving it to the RUNNING&nbsp;state. Eventually, the signaled thread runs. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Locks are similar. A lock <TT>acquire</TT>&nbsp;on a busy lock puts the caller into the WAITING&nbsp;state, with the caller&#8217;s TCB on a list of waiting TCBs associated with the lock. Later, when the lock owner calls <TT>release</TT>, one waiting TCB is moved to the ready list, and that thread transitions to the READY&nbsp;state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Notice that threads that are RUNNING&nbsp;or READY&nbsp;have their state located at a pre-defined, &#8220;global&#8221; location: the CPU (for a RUNNING&nbsp;thread) or the scheduler&#8217;s list of ready threads (for a READY&nbsp;thread). However, threads that are WAITING&nbsp;typically have their state located on some per-lock or per-condition-variable queue of waiting threads. Then, a <TT>signal</TT>, <TT>broadcast</TT>, or <TT>release</TT>&nbsp;call can easily find and re-enable a waiting thread for that particular condition variable or lock. </FONT><A id=x1-560018 name=x1-560018></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Thread-safe&nbsp;blocking&nbsp;queue.
&nbsp;
&nbsp;const&nbsp;int&nbsp;MAX&nbsp;=&nbsp;10;
&nbsp;
&nbsp;class&nbsp;BBQ{
&nbsp;&nbsp;&nbsp;//&nbsp;Synchronization&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;itemAdded;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;itemRemoved;
&nbsp;
&nbsp;&nbsp;&nbsp;//&nbsp;State&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;items[MAX];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;front;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;nextEmpty;
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BBQ();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~BBQ()&nbsp;{};
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;insert(int&nbsp;item);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;remove();
&nbsp;};
</FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Initialize&nbsp;the&nbsp;queue&nbsp;to&nbsp;empty,
&nbsp;//&nbsp;the&nbsp;lock&nbsp;to&nbsp;free,&nbsp;and&nbsp;the
&nbsp;//&nbsp;condition&nbsp;variables&nbsp;to&nbsp;empty.
&nbsp;BBQ::BBQ()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;front&nbsp;=&nbsp;nextEmpty&nbsp;=&nbsp;0;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Wait&nbsp;until&nbsp;there&nbsp;is&nbsp;room&nbsp;and
&nbsp;//&nbsp;then&nbsp;insert&nbsp;an&nbsp;item.
&nbsp;void
&nbsp;BBQ::insert(int&nbsp;item)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;((nextEmpty&nbsp;-&nbsp;front)&nbsp;==&nbsp;MAX)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itemRemoved.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;items[nextEmpty&nbsp;%&nbsp;MAX]&nbsp;=&nbsp;item;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextEmpty++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itemAdded.signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Wait&nbsp;until&nbsp;there&nbsp;is&nbsp;an&nbsp;item&nbsp;and
&nbsp;//&nbsp;then&nbsp;remove&nbsp;an&nbsp;item.
&nbsp;int
&nbsp;BBQ::remove()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;item;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(front&nbsp;==&nbsp;nextEmpty)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itemAdded.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item&nbsp;=&nbsp;items[front&nbsp;%&nbsp;MAX];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;front++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itemRemoved.signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;item;
&nbsp;}
&nbsp;
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.8: </B>A thread-safe blocking bounded queue using Mesa-style condition variables.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><A id=x1-56002r94 name=x1-56002r94></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.4.3 </FONT><A id=x1-570003 name=x1-570003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Case Study: Blocking Bounded Queue</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">We can use condition variables to implement a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:blocking bounded queue"}'>blocking bounded queue</A></EM>, one where a thread trying to remove an item from an empty queue will wait until an item is available, and a thread trying to put an item into a full queue will wait until there is room. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-560018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> defines the blocking bounded queue&#8217;s interface and implementation. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As in TSQueue, we acquire and release the lock at the beginning and end of the public methods (e.g., insert and remove). Now, however, we can atomically release the lock and wait if there is no room in insert or no item in remove. Before returning, insert signals on itemAdded since a thread waiting in remove may now be able to proceed; similarly, remove signals on itemRemoved before it returns. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We <TT>signal</TT>&nbsp;rather than <TT>broadcast</TT>&nbsp;because each insert allows at most one remove to proceed, and vice versa. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What invariants hold when <TT>wait</TT>&nbsp;returns in BBQ:remove? Is an item guaranteed to be in the queue? Why or why not? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>Exactly the same invariants hold when <TT>wait</TT>&nbsp;returns as when the thread first acquired the lock.</B> These are the same constraints as listed earlier for the thread-safe (non-blocking) bounded queue TSQueue. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In particular, although there is always an item in the queue when insert calls <TT>signal</TT>, there is <EM>no</EM> guarantee that the item is still in the queue when <TT>wait</TT>&nbsp;returns. Even if the language runtime avoids spurious wakeups, some other thread may have run between the <TT>signal</TT>&nbsp;and the return from <TT>wait</TT>. That thread may perform a remove, acquire the BBQ::lock, find the item, and empty the queue, all before <TT>wait</TT>&nbsp;returns. &#9633; </FONT><A id=x1-57001r90 name=x1-57001r90></A></P><A id=x1-580005 name=x1-580005>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.5 Designing and Implementing Shared Objects</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Although multi-threaded programming has a reputation for being difficult, shared objects provide a basis for writing simple, safe code for multi-threaded programs. In this section, we provide a methodology for writing correct multi-threaded code using shared objects. </FONT>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We first define a high-level approach to designing shared objects. Given a concurrent problem, where do you start? (Section </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-590001"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.1</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We provide six specific rules, or best practices, that you should always follow when writing multi-threaded shared objects. (Section </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-600002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We describe three common pitfalls to multi-threading in C, C++, and Java code. (Section </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-610003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">)</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Our experience is that following this approach and these rules makes it much more likely that you will write code that is not only correct but also easy for others to read, understand, and maintain. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>On simplicity</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One of the themes running through this textbook is the importance of simple abstractions in building robust, reliable operating systems. Operating systems place a premium on reliability; if the operating system breaks, the computer becomes temporarily unusable, or worse. And yet, it is nearly impossible to fully test whether some piece of multi-threaded operating system code works under all possible conditions and all possible schedule interleavings. This places a premium on designing solutions that work the first time they are run, by keeping code simple. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Particularly with concurrent code, it is not enough for the code to work. It also needs to be simple enough to understand. We often find students write intricate concurrent code in solutions to our homework assignments and exams. Perhaps the difficulty of the topic suggests to students that their solutions must also be difficult to understand! Sometimes these solutions work; more often the complexity hides a design flaw. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Even if your code is literally correct, we would like to encourage you to not stop there. Is it easy to understand <EM>why</EM> your code works? If not, try again. Even if you can get the code to work this time, someone else may need to come along later and change it. For concurrent code to be maintainable over time, it is essential that the next developer to work on the code be able to understand it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Yet, often in technology circles, simplicity is considered an insult. Someone might say, &#8220;Anyone could have done that!&#8221;, meaning it as a put down. We take the other side: a simple design should be seen as a complement. Complexity should be introduced only where it is absolutely necessary. Consider three possible states for one of your designs (hat tip to John Ousterhout for this list): </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The code is simple enough that anyone can understand it. If someone says this to you, the appropriate response is to take it as a complement and reply, &#8220;Thank you.&#8221; </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The code is so complicated that only the author can understand it. While this might be useful in the short-term as a strategy to keep the author employed (after all, no one else can fix or improve code without understanding it first), it is not such a good idea over the long term. Eventually, you will want to work on something new! </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The code is so complicated not even the author can understand it. Concurrent code often lands in this category, unnecessarily in our view. Using the rules we introduce in this section will help put your code in the first and not the last bucket.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Of course, writing individual shared objects is not enough. Most programs have multiple shared objects, and new issues arise when combining them. But, before trying to compose multiple shared objects, we must make sure that each individual object works. Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-780006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> discusses the issues that arise when programs use multiple shared objects. </FONT><A id=x1-58001r96 name=x1-58001r96></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.1 </FONT><A id=x1-590001 name=x1-590001></A><FONT style="BACKGROUND-COLOR: #7be1e1">High Level Methodology</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">A shared object has public methods, private methods, state variables, and synchronization variables; its synchronization variables include a lock and one or more condition variables. At this level, shared object programming resembles standard object-oriented programming, except that we have added synchronization variables to each shared object. This similarity is deliberate: the interfaces to locks and condition variables have been carefully defined so that we can continue to apply familiar techniques for programming and reasoning about objects. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Therefore, most high-level design challenges for a shared object&#8217;s class are the same as for class design in single-threaded programming: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Decompose the problem into objects. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For each object: </FONT></P>
<UL class=itemize2>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Define a clean interface. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Identify the right internal state and invariants to support that interface. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Implement methods with appropriate algorithms to manipulate that state.</FONT></P></LI></UL></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">These steps require creativity and sound engineering judgment and intuition. Going from single-threaded to multi-threaded programming does not make these steps much more difficult. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Compared to how you implement a class in a single-threaded program, the new steps needed for the multi-threaded case for shared objects are straightforward: </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-59002x1 name=x1-59002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Add a lock. </FONT></P>
<LI class=enumerate><A id=x1-59004x2 name=x1-59004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Add code to <TT>acquire</TT>&nbsp;and <TT>release</TT>&nbsp;the lock. </FONT></P>
<LI class=enumerate><A id=x1-59006x3 name=x1-59006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Identify and add condition variables. </FONT></P>
<LI class=enumerate><A id=x1-59008x4 name=x1-59008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Add loops to wait using the condition variables. </FONT></P>
<LI class=enumerate><A id=x1-59010x5 name=x1-59010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Add <TT>signal</TT>&nbsp;and <TT>broadcast</TT>&nbsp;calls. </FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We discuss each of these steps in turn. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Other than these fairly mechanical changes, writing the rest of your code proceeds as in the single-threaded case. </FONT></P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-59012x1 name=x1-59012x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Add a lock.</B> Each shared object needs a lock as a member variable to enforce mutually exclusive access to the object&#8217;s shared state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This chapter focuses on the simple case where each shared object includes exactly one lock. In Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-780006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, we will talk about more advanced variations, such as an </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-830003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">ownership design pattern</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> where higher-level program structure enforces mutual exclusion by ensuring that at most one thread at a time owns and can access an object. </FONT></P>
<LI class=enumerate><A id=x1-59014x2 name=x1-59014x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Add code to acquire and release the lock.</B> All code accessing the object&#8217;s shared state &#8212; any state shared across more than one thread &#8212; must hold the object&#8217;s lock. Typically, all of an object&#8217;s member variables are shared state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The simplest and most common approach is to acquire the lock at the start of each public method and release it at the end of each public method. Doing so makes it easy to inspect your code to verify that a lock is always held when needed. It also means that the lock is already held when each private method is called, and you do not need to re-acquire it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: You may be tempted to try to avoid acquiring the lock in some methods or parts of some methods. Do not be tempted by this &#8220;optimization&#8221; until you are an experienced programmer and have done sufficient profiling of the code to verify that the optimization will significantly speed up your program, <EM>and</EM> you fully understand the hazards posed by compiler and architecture instruction re-ordering. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Acquiring an uncontended lock is a relatively inexpensive operation. By contrast, reasoning about memory interleavings can be quite difficult &#8212; and the instruction reordering done by modern compilers and processors makes it even harder. Later in this section, we discuss one commonly used (and abused) &#8220;optimization,&#8221; double-checked locking, that is outright dangerous to use. </FONT></P>
<LI class=enumerate><A id=x1-59016x3 name=x1-59016x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Identify and add condition variables.</B> How do you decide what condition variables a shared object needs? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A systematic way to approach this problem is to consider each method and ask, <EM>&#8220;When can this method wait?"</EM> Then, you can map each situation in which a method can wait to a condition variable. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">You have considerable freedom in deciding how many condition variables a class should have and what each should represent. A good option is to add a condition variable for each situation in which the method must wait. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: Blocking bounded queue with two condition variables.</B> In our blocking bounded queue example, if the queue is full, <TT>insert</TT>&nbsp;must wait until another thread removes an item, so we created a condition variable itemRemoved. Similarly, if the queue is empty, <TT>remove</TT>&nbsp;must wait until another thread inserts an item, so we created a condition variable itemAdded. It is natural in this case to create two condition variables, itemAdded to wait until the queue has items, and itemRemoved to wait until the queue has space. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Alternatively, a single condition variable can often suffice. In fact, early versions of Java defined a single condition variable per object and did not let programmers allocate additional ones. Using this approach, any thread that waits for any reason uses that condition variable; if the condition variable is used by different threads waiting for different reasons, then any thread that wakes up a thread must <TT>broadcast</TT>&nbsp;on the condition variable. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: Blocking bounded queue with one condition variable.</B> It is also possible to implement the blocking bounded queue with a single condition variable, i.e., somethingChanged, on which threads in both <TT>insert</TT>&nbsp;or threads in <TT>remove</TT>&nbsp;can wait. With this approach, both <TT>insert</TT>&nbsp;and <TT>remove</TT>&nbsp;need to <TT>broadcast</TT>&nbsp;rather than <TT>signal</TT>&nbsp;to ensure that the right threads get a chance to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Programs that are more complex make these trade-offs more interesting. For example, imagine a ResourceManager class that allows a calling thread to request exclusive access to any subset of n distinct resources. One could imagine creating 2<SUP>n</SUP> condition variables; this would let a requesting thread wait on a condition variable representing exactly its desired combination. However, it would be simpler to have a single condition variable on which requesting threads wait and to broadcast on that condition whenever a resource is freed. Depending on the number of resources and the expected number of waiting threads, this simpler approach may even be more efficient. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The bottom line is that there is no hard and fast rule for how many condition variables to use in a shared object. Selecting condition variables requires thought, and different designers may use different numbers of condition variables for a given class. Like many other design decisions, this is a matter of programmer taste, judgment, and experience. Asking &#8220;When can this method wait?&#8221; will help you identify what is for you a natural way of thinking about a shared object&#8217;s condition variables. </FONT></P>
<LI class=enumerate><A id=x1-59018x4 name=x1-59018x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Add loops to wait using the condition variables.</B> Add a while(...) {cv.wait()} loop into each method that you identified as potentially needing to wait before returning. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Remember that every call to <TT>wait</TT>&nbsp;must be enclosed in a while loop that tests an appropriate predicate. Modern implementations almost invariably provide Mesa semantics and often allow for spurious wakeups (i.e., a thread can return from <TT>wait</TT>&nbsp;even if no thread called <TT>signal</TT>&nbsp;or <TT>broadcast</TT>). Therefore, a thread must always check the condition before proceeding. Even if the condition was true when the <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;call occurred, it may no longer be true when the waiting thread resumes execution. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Modularity benefits.</B> If you always wait in a while loop, your code becomes highly modular. You can look at the code that waits, and when it proceeds, know <EM>without</EM> examining any other code that the condition holds. Even erroneous calls to <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;will not change how the waiting code behaves. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, consider the assertion in the following code: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;...
&nbsp;while&nbsp;(!workAvailable())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cond.wait(&amp;lock);
&nbsp;}
&nbsp;assert(workAvailable());
&nbsp;...</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We know that the assertion holds by local inspection <EM>without knowing anything about the code that calls <TT>signal</TT>&nbsp;or <TT>broadcast</TT>.</EM> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Waiting in a while loop also makes the signal and broadcast code more robust. Adding an extra <TT>signal</TT>, or changing a <TT>signal</TT>&nbsp;to a <TT>broadcast</TT>, will not introduce bugs. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>HINT</B>: <B>Top-down design.</B> As you start writing your code, you may know that a method needs to include a wait loop, but you may not know exactly what the predicate should be. In this situation, it is often useful to name a private method function that will perform the test (e.g., workAvailable in the preceding example) and write the code that defines the function later. </FONT></P>
<LI class=enumerate><A id=x1-59020x5 name=x1-59020x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Add <TT>signal</TT>&nbsp;and <TT>broadcast</TT>&nbsp;calls.</B> Just as you must decide when methods can wait, you must decide when methods can let other waiting threads proceed. It is usually easy to ask, &#8220;Can a call to this method allow another thread to proceed?&#8221; and then add a <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;call if the answer is yes. But which call should you use? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">CV::signal is appropriate when: (1) at most one waiting thread can make progress, and (2) any thread waiting on the condition variable can make progress. In contrast, <TT>broadcast</TT>&nbsp;is needed when: (1) multiple waiting threads may all be able to make progress, or (2) different threads are using the same condition variable to wait for different predicates, so some of the waiting threads can make progress but others cannot. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Consider the n-resource ResourceManager problem described earlier. For the solution with a single condition variable, we must <TT>broadcast</TT>&nbsp;on the condition variable whenever a resource is freed. We do not know which thread(s) can make progress, so we tell them all to check. If, instead, we used <TT>signal</TT>, then the &#8220;wrong&#8221; thread might receive the <TT>signal</TT>, and a thread that could make progress might remain blocked. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">It is always safe to use <TT>broadcast</TT>. Even in cases where <TT>signal</TT>&nbsp;would suffice, at worst, all of the waiting threads would run and check the condition in the while loop, but only one would continue out of the loop. Compared to <TT>signal</TT>, this would consume some additional resources, but it would not introduce any bugs.</FONT></P></LI></OL><A id=x1-59021r98 name=x1-59021r98></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.2 </FONT><A id=x1-600002 name=x1-600002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementation Best Practices</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Above, we described the basic thought process you should follow when designing a shared object. To make things more concrete, we next give a set of six simple rules that we strongly advocate you follow; these are a set of &#8220;best practices&#8221; for writing code for shared objects. </FONT>
<P></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Coding standards, soapboxes, and preaching</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Some programmers rebel against coding standards. We do not understand their logic. For concurrent programming in particular, a few good design patterns have stood the test of time (and many unhappy people who have departed from those patterns). For concurrent programming, <EM>debugging does not work</EM>. You must rely on: (a) writing correct code, and (b) writing code that you and others can read and understand &#8212; not just for now, but also over time as the code changes. Following the rules we provide will help you write correct, readable code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When we teach multi-threaded programming, we treat the six rules described in this section as <EM>required coding standards</EM> for all multi-threaded code that students write in our course. We say, &#8220;We cannot control what you do when you leave this class, but while you are in this class, any solution that violates these standards is, by definition, <EM>wrong</EM>.&#8221; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In fact, we feel so strongly about these rules that one of us actually presents them in class by standing on a table and pronouncing them as the Six Commandments of multi-threaded programming: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">1. Thou shalt always do things the same way. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">and so on. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The particular formulation (and presentation) of these rules evolved from our experience teaching multi-threaded programming dozens of times to hundreds of students and identifying common mistakes. We have found that when we insist that students follow these rules, the vast majority find it easy to write clear and correct code for shared objects. Conversely, in earlier versions of the course, when we phrased these items as &#8220;strong suggestions,&#8221; many students found themselves adrift, unable to write code for even the simplest shared objects. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Our advice to those learning multi-threaded programming is to treat these rules as a given and follow them strictly for a semester or so, until writing shared objects is easy. At that point, you most likely will understand concurrent programming well enough to decide whether to continue to follow the rules. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We also believe that experienced programmers benefit from adhering closely to these rules. Since we began teaching them, we have also disciplined ourselves to follow them unless there is a very good reason not to. We have found exceptions to be rare. Conversely, when we catch ourselves being tempted to deviate from the rules, the vast majority of the time our code improves if we force ourselves to rewrite the code to follow the rules. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although the rules may come across as opinionated (and they are), they are far from novel. Over three decades ago, Lampson and Redell&#8217;s paper, &#8220;Experience with Processes and Monitors in Mesa,&#8221; provided similar advice (in a more measured tone). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-60002x1 name=x1-60002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Consistent structure.</B> The first rule is a meta-rule that underlies the other five rules: <EM>follow a consistent structure.</EM> Although programming with a clean, consistent structure is always useful, it is particularly important to strictly follow tried-and-true design patterns for shared objects. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">At a minimum, even if one way is not inherently better than another, following the same strategy every time: (1) frees you to focus on the core problem because the details of the standard approach become a habit, and (2) makes it easier for those who follow to review, maintain, and debug your code. (And it will make it easier for <EM>you</EM> to maintain and debug your code.) </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As an analogy, electricians follow standards for the colors of wire they use for different tasks. White is neutral. Black or red is hot. Copper is ground. An electrician does not have to decide &#8220;Hm. I have a bit more white on my belt today than black, should I use white or black for my grounds?&#8221; When an electrician walks into a room she wired last month, she does not have to spend time trying to remember which color is which. If an electrician walks into a room she has never seen before, she can immediately determine what the wiring is doing, without having to trace it back into the switchboard. Similar advantages apply to coding standards. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">However, for concurrent programs, the evidence is that the abstractions we describe <EM>are</EM> better than almost all others. Until you become a <EM>very</EM> experienced concurrent programmer, take advantage of the hard-won experience of those that have come before you. Once you are a concurrency guru, you are welcome to invent a better mousetrap. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Sure, you can cut corners and occasionally save a line or two of typing by departing from the standards. However, you will have to spend a few minutes thinking to convince yourself that you are right on a case-by-case basis (and another few minutes typing comments to convince the next person to look at the code that you are right), and a few hours or weeks tracking down bugs when you are wrong. It is just not worth it. </FONT></P>
<LI class=enumerate><A id=x1-60004x2 name=x1-60004x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Always synchronize with locks and condition variables.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Many operating systems, such as Linux, Windows, and MacOS, provide a diversity of synchronization primitives. At the end of this chapter, we will describe one such primitive, semaphores, which is particularly widely used in operating system kernel implementations. Compared to locks and condition variables, semaphores are equally powerful: you can build condition variables using semaphores and vice versa. If so, why pick one over the other? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We recommend that you be able to read and understand semaphores so you can understand legacy code, but that you only write new code using locks and condition variables. Almost always, code using locks and condition variables is clearer than the equivalent code using semaphores because it is more &#8220;self-documenting.&#8221; If the code is well structured, what each synchronization action is doing should be obvious. Admittedly, semaphores sometimes seem to fit what you are doing perfectly because you can map the object&#8217;s invariants exactly onto the internal state of the semaphore; for example, you can write an extremely concise version of our blocking bounded queue using semaphores. But what happens when the code changes next month? Will the fit remain as good? For consistency and simplicity, choose one of the two styles and stick with it. In our opinion, the right one is to use locks and condition variables. </FONT></P>
<LI class=enumerate><A id=x1-60006x3 name=x1-60006x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Always acquire the lock at the beginning of a method and release it right before the return.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This extends the principle of consistent structure: pick one way to do things and always follow it. The benefit here is that it is easy to read code and see where the lock is or is not held because synchronization is structured on a method-by-method basis. Conversely, if <TT>acquire</TT>&nbsp;and <TT>release</TT>&nbsp;calls are buried in the middle of a method, it is harder to quickly inspect and understand the code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Taking a step back, if there is a logical chunk of code that you can identify as a set of actions that require a lock, then that section should probably be its own procedure: it is a set of logically related actions. If you find yourself wanting to acquire a lock in the middle of a procedure, that is usually a red flag that you should break the piece you are considering into a separate procedure. We are all sometimes lazy about creating new procedures when we should. Take advantage of this signal, and the result will be clearer code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">There are two corollaries to this rule. First, if your code is well structured, all shared data will be encapsulated in an object, and therefore all accesses to shared data will be protected by a lock. Since compilers and processors <EM>never</EM> re-order instructions across lock operations, this rule guarantees instruction re-ordering is not a concern for your code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Second, from time to time, we see students attempting to acquire a lock in one procedure, and release it in another procedure, or worse, in a completely different thread. (One popular idea is to acquire a lock in a parent thread, pass it in thread_fork to a child, and have the child release the lock after it has started.) <EM>Do not do this.</EM> For one, it can make it very difficult for someone reading your code to determine which shared variables are protected by which lock; by acquiring at the beginning of the procedure and releasing at the end, which variables go with which locks is obvious. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">While some early thread systems allowed lock passing, most recently designed systems prohibit it. For example, in POSIX, lock release is &#8220;undefined&#8221; when called by a different thread than the thread that acquired the lock. In other words, it might work on some systems, but it is not portable. In Java, it is completely prohibited. </FONT></P>
<LI class=enumerate><A id=x1-60008x4 name=x1-60008x4></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Always hold the lock when operating on a condition variable.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The reason you signal on a condition variable &#8212; after manipulating shared state &#8212; is that another thread is waiting in a loop for some test on shared state to become true. Condition variables are useless without shared state, and shared state should only be accessed while holding a lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Many libraries enforce this rule &#8212; that you cannot call condition variable methods unless you hold the corresponding lock. However, some run-time systems and libraries allow sloppiness, so take care. </FONT></P>
<LI class=enumerate><A id=x1-60010x5 name=x1-60010x5></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Always wait in a while() loop</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The pattern should always be: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;while&nbsp;(predicateOnStateVariables(...))&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;condition-&gt;wait(&amp;lock);
&nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">and never: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;...
&nbsp;if&nbsp;(predicateOnStateVariables(...))&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wait(&amp;lock);
&nbsp;}
&nbsp;...</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Here, predicateOnStateVariables(...) is code that looks at the state variables of the current object to decide if the thread should proceed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">You may be tempted to guard a <TT>wait</TT>&nbsp;call with an if conditional rather than a while loop when you can deduce from the global structure of the program that, despite Mesa semantics, any time a thread returns from wait, it can proceed. Avoid this temptation. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">While works any time if does, and it works in situations when if does not. By the principle of consistent structure, do things the same way every time. But there are three additional issues. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Using if breaks modularity. In the preceding example, to know whether using if will work, you must consider the global structure of the program: what threads there are, where <TT>signal</TT>&nbsp;is called, etc. The problem is that a change in code in one method (say, adding a <TT>signal</TT>) can then cause a bug in another method (where the <TT>wait</TT>&nbsp;is). Using while is self-documenting; anyone can look at the <TT>wait</TT>&nbsp;and see exactly when a thread may proceed. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Always using while gives you incredible freedom about where to put a <TT>signal</TT>. In fact, <TT>signal</TT>&nbsp;becomes a hint &#8212; you can add a signal to an arbitrary place in a correct program and have it remain correct. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Using if breaks portability. Some implementations of condition variables allow spurious wakeups, while others do not. For example, implementations of condition variables in both Java and the POSIX pthreads library are allowed to return from <TT>wait</TT>&nbsp;even though no thread called <TT>signal</TT>&nbsp;or <TT>broadcast</TT>.</FONT></P></LI></UL>
<LI class=enumerate><A id=x1-60012x6 name=x1-60012x6></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>(Almost) never use <TT>thread_sleep</TT>.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Many thread libraries have a <TT>thread_sleep</TT>&nbsp;function that suspends execution of the calling thread for some period of wall clock time. Once that time passes, the thread is returned to the scheduler&#8217;s ready queue and can run again. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Never use <TT>thread_sleep</TT>&nbsp;to have one thread wait for another thread to perform a task. The correct way to wait for a condition to become true is to <TT>wait</TT>&nbsp;on a condition variable. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In general, <TT>thread_sleep</TT>&nbsp;is appropriate only when there is a particular real-time moment when you want to perform some action, such as a timeout for when to declare a remote server non-responsive. If you catch yourself writing while(testOnObjectState()) {thread_sleep();}, treat this as a red flag that you are probably making a mistake. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Similarly, if a thread must wait for an object&#8217;s state to change, it should <TT>wait</TT>&nbsp;on a condition variable, and not just call thread_yield. Use thread_yield&nbsp;only when a low-priority thread <EM>that can still make progress</EM> wants to let a higher-priority thread to run. </FONT></P></LI></OL><A id=x1-60013r99 name=x1-60013r99></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.3 </FONT><A id=x1-610003 name=x1-610003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Three Pitfalls</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">We next describe three common pitfalls. The first, double-checked locking, is a problem in many different programming languages, including C, C++ and Java. The second and third pitfalls are specific to Java. Java is a modern type-safe language that included support for threads from its inception. This built-in support makes multi-threaded programming in Java convenient. However, some aspects of the language are <EM>too</EM> flexible and can encourage bad practices. We highlight those pitfalls here. </FONT>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-61002x1 name=x1-61002x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Double-Checked Locking.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We strongly advise holding a shared object&#8217;s lock across any method that accesses the object&#8217;s member variables. Programmers are often tempted to avoid some of these lock acquire and release operations. Unfortunately, such efforts often result in code that is complex, wrong, or both. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To illustrate the challenges, consider the <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:double-checked locking"}'>double-checked locking</A></EM> design pattern. The canonical example is an object that is allocated and initialized lazily the first time it is needed by any thread. (This example and analysis is taken from Meyers and Alexandrescu, &#8220;C++ and the Perils of Double-Checked Locking.&#8221; </FONT><A href="http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf"><FONT style="BACKGROUND-COLOR: #7be1e1">http://www.aristeia.com/Papers/DDJ_Jul_ Aug_2004_revised.pdf</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">) Being good programmers, we can hide the lazy allocation inside an object, Singleton, which returns a pointer to the object, creating it if needed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The &#8220;optimization&#8221; is to acquire the lock if the object has not already been allocated, but to avoid acquiring the lock if the object already exists. Because there can be a race condition between the first check and acquiring the lock, the check must be made again inside the lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;Singleton&nbsp;{
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;static&nbsp;Singleton*&nbsp;instance();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;static&nbsp;Singleton*&nbsp;pInstance;
&nbsp;};
&nbsp;
&nbsp;Singleton*&nbsp;Singleton::pInstance&nbsp;=&nbsp;NULL;
 </FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;BUG!&nbsp;&nbsp;DON&#8217;T&nbsp;DO&nbsp;THIS!
&nbsp;Singleton*
&nbsp;Singleton::instance()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(pInstance&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(pInstance&nbsp;==&nbsp;NULL){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pInstance&nbsp;=&nbsp;new&nbsp;Instance();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;pInstance;
&nbsp;}
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although the intuition is appealing, <B>this code does not work.</B> The problem is that the statement pInstance = new Instance() is not an atomic operation; in fact, it comprises at least three steps: </FONT></P>
<OL class=enumerate2>
<LI class=enumerate><A id=x1-61004x1 name=x1-61004x1></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Allocate memory for a Singleton object. </FONT></P>
<LI class=enumerate><A id=x1-61006x2 name=x1-61006x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Initialize the Singleton object&#8217;s memory by running the constructor. </FONT></P>
<LI class=enumerate><A id=x1-61008x3 name=x1-61008x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Make pInstance point to this newly constructed object.</FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The problem is that modern compilers and hardware architectures can reorder these events. Thus, it is possible for thread 1 to execute the first step and then the third step; then thread 2 can call instance, see that pInstance is non-null, return it, and begin using this object before thread 1 finishes initializing it. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Discussion.</B> This is just an example of dangers that lurk when you try to elide locks; the lesson applies more broadly. This example is extremely simple &#8212; fewer than 10 lines of code with very simple logic &#8212; yet a number of published solutions have been wrong. As Meyers and Alexandrescu note, some tempting solutions using temporary variables and the volatile keyword do not work. Bacon et al.&#8217;s &#8220;The &#8217;Double-Checked Locking is Broken&#8217; Declaration&#8221; discusses a range of non-solutions in Java. </FONT><A href="http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html"><FONT style="BACKGROUND-COLOR: #7be1e1">http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This type of optimization is risky and often does not provide significant performance gains in practice. Most programmers should not consider them. Even expert programmers should habitually stick to simpler programming patterns, like the ones we have discussed, and only consider optimizations like double-checked locking when performance measurements and profiling indicate that the optimizations would significantly improve overall performance. </FONT></P>
<LI class=enumerate><A id=x1-61010x2 name=x1-61010x2></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Avoid defining a synchronized block in the middle of a method.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Java provides built in language support for shared objects. The base Object class, from which all classes inherit, includes a lock and a condition variable as members. Any method declaration can include the keyword synchronized to indicate that the object&#8217;s lock is to be automatically acquired on entry to the method and automatically released on any return from the method. For example: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;public&nbsp;synchronized&nbsp;foo()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Do&nbsp;something;&nbsp;lock&nbsp;is&nbsp;automatically&nbsp;acquired/released.
&nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This syntax is useful &#8212; it follows rule #2 above, and it frees the programmer from having to worry about details, like making sure the lock is released before every possible return point including exceptions. The pitfall is that Java also allows a <EM>synchronized block</EM> in the middle of a method. For example: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;public&nbsp;bar()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Do&nbsp;something&nbsp;without&nbsp;holding&nbsp;the&nbsp;lock
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Do&nbsp;something&nbsp;while&nbsp;holding&nbsp;the&nbsp;lock
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Do&nbsp;something&nbsp;without&nbsp;holding&nbsp;the&nbsp;lock
&nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This construct violates rule #3 from Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-600002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5.2</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> and suffers from the disadvantages listed there. The solution is the same as discussed above: when you find yourself tempted to write a synchronized block in the middle of a Java method, treat that as a strong hint that you should define a separate method to more clearly encapsulate the logical chunk you have identified. </FONT></P>
<LI class=enumerate><A id=x1-61012x3 name=x1-61012x3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Keep shared state classes separate from thread classes.</B> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Java defines a class called Thread that implements an interface called Runnable that other classes can implement in order to be treated as threads by the runtime system. To write the code that represents a thread&#8217;s &#8220;main loop,&#8221; you typically extend the Thread class or implement a class that implements Runnable. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The pitfall is that, when extending the Thread class (or writing a new class that implements Runnable), you may be tempted to include not only the thread&#8217;s main loop but also state to be shared across multiple threads, blurring the lines between the threads and the shared objects. This is almost always confusing. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, for a blocking bounded queue, rather than defining two classes, BBQ for the shared queue and WorkerThread for the threads, you may be tempted to combine the two into a single class &#8212; for example, a queue with an associated worker thread. If this sounds confusing, it is, but it is a pitfall that we frequently see in student code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The solution is simple. Always make sure threads and shared objects are defined in separate classes. State that can be accessed by multiple threads, locks, and condition variables should never appear in any Java class that extends Thread or implements Runnable.</FONT></P></LI></OL><A id=x1-61013r97 name=x1-61013r97></A><A id=x1-620006 name=x1-620006>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.6 Three Case Studies</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">The best way to learn how to program concurrently is to practice. Multithreaded programming is an important skill, and we anticipate that almost everyone reading this book will over time need to write many multi-threaded programs. To help get you started, this section walks through several examples. </FONT><A id=x1-62001r100 name=x1-62001r100></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.6.1 </FONT><A id=x1-630001 name=x1-630001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Readers/Writers Lock</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">First, we implement a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:readers/writers lock"}'>readers/writers lock</A></EM>. Like a normal mutual exclusion lock, a readers/writers lock (RWLock) protects shared data. However, it makes the following optimization. To maximize performance, an RWLock allows multiple &#8220;reader&#8221; threads to simultaneously access the shared data. Any number of threads can safely read shared data at the same time, as long as no thread is modifying the data. However, only one &#8220;writer&#8221; thread may hold the RWLock at any one time. (While a &#8220;reader&#8221; thread is restricted to only read access, a &#8220;writer&#8221; thread may read <EM>and</EM> write the data structure.) When a writer thread holds the RWLock, it may safely modify the data, as the lock guarantees that no other thread (whether reader or writer) may simultaneously hold the lock. The mutual exclusion is thus between any writer and any other writer, and between any writer and <EM>the set</EM> of readers. </FONT>
<P></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Optimizing for the common case</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Reader/writer locks are an example of an important principle in the design of computer systems: optimizing for the common case. Performance optimizations often have the side effect of making the code more complex to understand and reason about. Code that is more complex is more likely to be buggy, and more likely to have new bugs introduced as features are added. How do we decide when an optimization is worth the cost? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One approach is to profile your code. Then, <EM>and only then</EM>, optimize the code paths that are frequently used. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In the case of locks, it is obviously simpler to use a regular mutual exclusion lock. Replacing a mutual exclusion lock with a reader-writer lock is appropriate when both of the following are true: (i) there is substantial contention for the mutual exclusion lock and (ii) a substantial majority of the accesses are read-only. In other words, it is only appropriate to use if it would make a significant difference. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Reader-writer locks are very commonly used in databases, where they are used to support faster search queries over the database, while also supporting less frequent database updates. Another common use is inside the operating system kernel, where core data structures are often read by many threads and only infrequently updated. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To generalize our mutual exclusion lock into a readers/writers lock, we implement a new kind of shared object, RWLock, to guard access to the shared data and to enforce these rules. The RWLock is implemented using our standard synchronization building blocks: mutual exclusion locks and condition variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A thread that wants to (atomically) read the shared data proceeds as follows: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;rwLock-&gt;startRead();
   &nbsp;//&nbsp;Read&nbsp;shared&nbsp;data
   &nbsp;rwLock-&gt;doneRead();</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Similarly, a thread that wants to (atomically) write the shared data does the following: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;rwLock-&gt;startWrite();
   &nbsp;//&nbsp;Read&nbsp;and&nbsp;write&nbsp;shared&nbsp;data
   &nbsp;rwLock-&gt;doneWrite();</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To design the RWLock class, we begin by defining its interface (already done in this case) and its shared state. For the state, it is useful to keep enough data to allow a precise characterization of the object; especially when debugging, having too much state is better than having too little. Here, the object&#8217;s behavior is fully characterized by the number of threads reading or writing and the number of threads waiting to read or write, so we have chosen to keep four integers to track these values. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-630019"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.9</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the members of and interface to the RWLock class. </FONT><A id=x1-630019 name=x1-630019></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;RWLock{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Synchronization&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;readGo;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;writeGo;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;State&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;activeReaders;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;activeWriters;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;waitingReaders;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;waitingWriters;
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RWLock();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~RWLock()&nbsp;{};
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;startRead();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;doneRead();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;startWrite();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;doneWrite();
&nbsp;
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;readShouldWait();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;writeShouldWait();
&nbsp;};
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.9: </B>The interface and member variables for our readers/writers lock.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Next, we add synchronization variables by asking, &#8220;When can methods wait?&#8221; First, we add a mutual exclusion lock: the RWLock methods must wait whenever another thread is accessing the RWLock state variables. Next, we observe that startRead or startWrite may have to wait, so we add a condition variable for each case: readGo and writeGo. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">RWLock::doneRead and doneWrite do not wait (other than to acquire the mutual exclusion lock). Therefore, these methods do not need any additional condition variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We can now implement RWLock. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6300210"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.10</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows the complete solution, which we develop in a few simple steps. Much of what we need to do is almost automatic. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since we always acquire/release mutual exclusion locks at the beginning/end of a method (and never in the middle), we can write calls to acquire and release the mutual exclusion lock at the start and end of each public method before even thinking in detail about what these methods do. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">At this point, startRead and doneRead look like this:</FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;void&nbsp;RWLock::startRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RWLock::doneRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">RWLock::startWrite and RWLock::doneWrite are similar. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since we know startRead and startWrite may have to wait, we can write a while(...){wait(...);} loop in the middle of each. In fact, we can defer thinking about the details by inserting a private method to be defined later, as the predicate for the while loop (e.g., readShouldWait and writeShouldWait). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">At this point, startRead looks like this: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;void&nbsp;RWLock::startRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(readShouldWait())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readGo.Wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">RWLock::StartWrite() looks similar. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Now things get a bit more complex. We can add code to track activeReaders, activeWriters, waitingReaders, and waitingWriters. Since we hold mutual exclusion locks in all of the public methods, this is easy to do. For example, a call to startRead initially increments the number of waiting readers; when the thread gets past the while loop, the number of waiting readers is decremented, but the number of active readers is incremented. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When reads or writes finish, it may become possible for waiting threads to proceed. We therefore need to add <TT>signal</TT>&nbsp;or <TT>broadcast</TT>&nbsp;calls to doneRead and doneWrite. The simplest solution would be to <TT>broadcast</TT>&nbsp;on both readGo and writeGo in each method, but that would be both inefficient and (to our taste) less clear about how the class actually works. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Instead, we observe that in doneRead, when a read completes, there are two interesting cases: (a) no writes are pending, and nothing needs to be done since this read cannot prevent other reads from proceeding, or (b) a write is pending, and this is the last active read, so one write can proceed. In case (b), we use <TT>signal</TT>&nbsp;since at most one write can proceed, and any write waiting on the condition variable can proceed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Our code for startRead and doneRead is now done: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Wait&nbsp;until&nbsp;no&nbsp;active&nbsp;or&nbsp;waiting
&nbsp;//&nbsp;writes,&nbsp;then&nbsp;proceed.
&nbsp;void&nbsp;RWLock::startRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingReaders++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(readShouldWait())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readGo.Wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingReaders--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeReaders++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Done&nbsp;reading.&nbsp;If&nbsp;no&nbsp;other&nbsp;active
&nbsp;//&nbsp;reads,&nbsp;a&nbsp;write&nbsp;may&nbsp;proceed.
&nbsp;void&nbsp;RWLock::doneRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeReaders--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(activeReaders&nbsp;==&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp;&nbsp;waitingWriters&nbsp;&gt;&nbsp;0)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writeGo.signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
 </FONT></PRE>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Code for startWrite and doneWrite is similar. For doneWrite, if there are any pending writes, we signal on writeGo. Otherwise, we broadcast on readGo. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Finally, we need to define the readShouldWait and writeShouldWait predicates. Here, we implement a <EM>writers preferred</EM> solution: reads should wait if there are any active or pending writers, while writes wait only while there are active readers or active writers. Otherwise, a continuous stream of new readers could starve a write request and prevent if from ever being serviced. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;bool
   &nbsp;RWLock::readShouldWait()&nbsp;{
   &nbsp;&nbsp;&nbsp;return&nbsp;(activeWriters&nbsp;&gt;&nbsp;0&nbsp;||&nbsp;waitingWriters&nbsp;&gt;&nbsp;0);
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The code for writeShouldWait is similar. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since readShouldWait and writeShouldWait are private methods that are always called from public methods that hold the mutual exclusion lock, they do not need to acquire the lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6300210"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.10</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> gives the full code. This solution may not be to your taste. You may decide to use more or fewer condition variables, use different state variables to implement different invariants, or change when to call <TT>signal</TT>&nbsp;or <TT>broadcast</TT>. The shared object approach allows designers freedom in these dimensions. </FONT><A id=x1-6300210 name=x1-6300210></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Wait&nbsp;until&nbsp;no&nbsp;active&nbsp;or&nbsp;waiting
&nbsp;//&nbsp;writes,&nbsp;then&nbsp;proceed.
&nbsp;void&nbsp;RWLock::startRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingReaders++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(readShouldWait())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readGo.Wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingReaders--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeReaders++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Done&nbsp;reading.&nbsp;If&nbsp;no&nbsp;other&nbsp;active
&nbsp;//&nbsp;reads,&nbsp;a&nbsp;write&nbsp;may&nbsp;proceed.
&nbsp;void&nbsp;RWLock::doneRead()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeReaders--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(activeReaders&nbsp;==&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp;&nbsp;waitingWriters&nbsp;&gt;&nbsp;0)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writeGo.signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Read&nbsp;waits&nbsp;if&nbsp;any&nbsp;active&nbsp;or&nbsp;waiting
&nbsp;//&nbsp;write&nbsp;("writers&nbsp;preferred").
&nbsp;bool
&nbsp;RWLock::readShouldWait()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;(activeWriters&nbsp;&gt;&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;||&nbsp;waitingWriters&nbsp;&gt;&nbsp;0);
&nbsp;}
&nbsp;
&nbsp;
&nbsp;//&nbsp;Wait&nbsp;until&nbsp;no&nbsp;active&nbsp;read&nbsp;or
&nbsp;//&nbsp;write&nbsp;then&nbsp;proceed.
&nbsp;void&nbsp;RWLock::startWrite()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingWriters++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(writeShouldWait())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writeGo.Wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingWriters--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeWriters++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Done&nbsp;writing.&nbsp;A&nbsp;waiting&nbsp;write&nbsp;or
&nbsp;//&nbsp;read&nbsp;may&nbsp;proceed.
&nbsp;void
&nbsp;RWLock::doneWrite()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeWriters--;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(activeWriters&nbsp;==&nbsp;0);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waitingWriters&nbsp;&gt;&nbsp;0)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writeGo.signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readGo.broadcast();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Write&nbsp;waits&nbsp;for&nbsp;active&nbsp;read&nbsp;or&nbsp;write.
&nbsp;bool
&nbsp;RWLock::writeShouldWait()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;(activeWriters&nbsp;&gt;&nbsp;0
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;||&nbsp;activeReaders&nbsp;&gt;&nbsp;0);
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.10: </B>An implementation of a readers/writers lock.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Single stepping and model checking your code</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose you have written some concurrent code, and you would like to verify that the solution behaves as you expect. One thing you should <EM>always</EM> do &#8212; whether for sequential or concurrent code &#8212; is to use a debugger to single step through the code on various inputs, to verify that the program logic is doing what you expect it to do, and do the variables have the values you expect. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This is especially useful for concurrent programs. Since the program must work for any possible thread schedule, you can use the debugger to consider what happens when threads are interleaved in different ways. Does your program logic still do what you expect? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For example, for the RWLock class, you can: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Start a single reader. Does it go all the way through? Obviously, it should not wait, since no one has the lock and there are no writers. When it finishes readDone, are the state variables back to their initial state? </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Start a writer, and after it acquires the mutual exclusion lock, start a reader. Does it wait for the lock? When the writer finishes startWrite, does the reader proceed and then wait for the writer to call doneWrite? Does the reader proceed after that? </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Start a reader, followed by a writer, followed by another reader. And so forth. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We encourage you to do this for the examples in this section. The examples are short enough that you can execute them by hand, but we also provide code if you want to try this in a debugger. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A more systematic approach is called model checking. To fully verify that a concurrent program does what it was designed to do, a model checker enumerates all possible sequences of operations, and tries each one in turn. Since this could result in a nearly infinite number of possible tests even for a fairly simple program, to be practical model checking needs to reduce the search space. For code that follows our guidelines &#8212; with locks to protect shared data &#8212; the exact ordering of instructions is no longer important. For example, preempting a thread that holds a lock is immaterial to the behavior of the program. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Rather, the behavior of the program depends on the sequence of synchronization instructions: which thread is first to acquire the lock, which thread waits on a condition variable, and so forth. Thus, a model checker can proceed in two steps: first verify that there are no unlocked accesses to shared data, and then enumerate various sequences of synchronization operations. Even with this, the number of possibilities can be prohibitively large, and so typically the model checker will verify however many different interleavings it can within some time limit. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-63003r102 name=x1-63003r102></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.6.2 </FONT><A id=x1-640002 name=x1-640002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Synchronization Barriers</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">With data parallel programming, as we explained in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the computation executes in parallel across a data set, with each thread operating on a different partition of the data. Once all threads have completed their work, they can safely use each other&#8217;s results in the next (data parallel) step in the algorithm. MapReduce is an example of data parallel programming, but there are many other systems with the same structure. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For this to work, we need an efficient way to check whether all n threads have finished their work. This is called a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:synchronization barrier"}'>synchronization barrier</A></EM>. It has one operation, <TT>checkin</TT>. A thread calls <TT>checkin</TT>&nbsp;when it has completed its work; no thread may return from <TT>checkin</TT>&nbsp;until <EM>all</EM> n threads have checked in. Once all threads have checked in, it is safe to use the results of the previous step. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Note that a synchronization barrier is different from a memory barrier, defined earlier in the chapter. A synchronization barrier is called concurrently by many threads; the barrier prevents any thread from proceeding until all threads reach the barrier. A memory barrier is called by one thread, to prevent the thread from proceeding until all memory operations that occur before the barrier have completed and are visible to other threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An implementation of MapReduce using a synchronization barrier might look like the code in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6400111"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.11</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT><A id=x1-6400111 name=x1-6400111></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;Create&nbsp;n&nbsp;threads.
&nbsp;Create&nbsp;barrier.
&nbsp;
&nbsp;Each&nbsp;thread&nbsp;executes&nbsp;map&nbsp;operation&nbsp;in&nbsp;parallel.
&nbsp;barrier.checkin();
&nbsp;
&nbsp;Each&nbsp;thread&nbsp;sends&nbsp;data&nbsp;in&nbsp;parallel&nbsp;to&nbsp;reducers.
&nbsp;barrier.checkin();
&nbsp;
&nbsp;Each&nbsp;thread&nbsp;executes&nbsp;reduce&nbsp;operation&nbsp;in&nbsp;parallel.
&nbsp;barrier.checkin();</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.11: </B>An implementation of MapReduce using synchronization barriers.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An alternative to using a synchronization barrier would be to create n threads at each step; the main thread could then call thread_join&nbsp;on each thread to ensure its completion. While this would be correct, it might be inefficient. Not only would n new threads need to be started at each step, the partitioning of work among threads would also need to be redone each time. Frequently, each thread in a data parallel computation can work on the same data repeatedly over many steps, maximizing the efficiency of the hardware processor cache. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We can derive an implementation for a synchronization barrier in the same way as we described above for the readers/writers lock. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We create a Barrier class, with a lock to protect its internal state variables: how many have checked in so far (count), and how many we are expecting (numThreads). </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We <TT>acquire</TT>&nbsp;the lock at the beginning of <TT>checkin</TT>, and we <TT>release</TT>&nbsp;it at the end. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since threads may have to wait in <TT>checkin</TT>, we need a condition variable, allCheckedIn. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We put the <TT>wait</TT>&nbsp;in a while loop, checking if all n threads have checked in yet. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The last thread to <TT>checkin</TT>&nbsp;does a <TT>broadcast</TT>&nbsp;to wake up all of the waiters.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6400212"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.12</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> gives the full implementation. Note that we still use a while loop, even though the signal means that the thread can safely exit <TT>checkin</TT>. There is no harm in using a while statement, and it protects against the possibility of the runtime library issuing spurious wakeups. </FONT><A id=x1-6400212 name=x1-6400212></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;A&nbsp;single&nbsp;use&nbsp;synch&nbsp;barrier.
&nbsp;class&nbsp;Barrier{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Synchronization&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;allCheckedIn;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;State&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;numEntered;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;numThreads;
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Barrier(int&nbsp;n);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~Barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;checkin();
&nbsp;};
&nbsp;
&nbsp;Barrier::Barrier(int&nbsp;n)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numEntered&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numThreads&nbsp;=&nbsp;n;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;No&nbsp;one&nbsp;returns&nbsp;until&nbsp;all&nbsp;threads
&nbsp;//&nbsp;have&nbsp;called&nbsp;checkin.
&nbsp;void
&nbsp;checkin()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numEntered++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(numEntered&nbsp;&lt;&nbsp;numThreads)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(numEntered&nbsp;&lt;&nbsp;numThreads)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allCheckedIn.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{&nbsp;//&nbsp;last&nbsp;thread&nbsp;to&nbsp;checkin
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allCheckedIn.broadcast();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.12: </B>Candidate implementation of a synchronization barrier. With this implementation, each instance of a barrier can be safely used only one time.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The design is straightforward, but a problem is that the barrier can only be used once. One way to see this is that the state of the barrier does not revert to the same state it had when it was created. Implementing a reusable barrier is a bit more subtle. </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The <EM>first</EM> thread to leave (the one that wakes up the other threads) cannot reset the state, because until the other threads have woken up, the state is needed so that they know to exit the while loop. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The <EM>last</EM> thread to leave the barrier cannot reset the state for the next iteration, because there is a possible race condition. Suppose a thread finishes <TT>checkin</TT>&nbsp;and calls <TT>checkin</TT>&nbsp;on the next barrier <EM>before</EM> the last thread wakes up and leaves the previous barrier. In that case, the thread would find that n threads have already checked in (because the state hasn&#8217;t been reset), and so it would think it is &#8220;ok to proceed!&#8221;</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A simple way to implement a re-usable barrier is to use two single-use barriers. The first barrier ensures that all threads are checked in, and the second ensures that all threads have woken up from allCheckedIn.wait. The nth thread to leave can safely reset numCheckedIn; the nth thread to call <TT>checkin</TT>&nbsp;can safely reset numLeaving. Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6400313"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.13</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> gives the result. </FONT><A id=x1-6400313 name=x1-6400313></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;A&nbsp;re-usable&nbsp;synch&nbsp;barrier.
&nbsp;class&nbsp;Barrier{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Synchronization&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lock&nbsp;lock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;allCheckedIn;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;allLeaving;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;State&nbsp;variables
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;numEntered;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;numLeaving;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;numThreads;
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Barrier(int&nbsp;n);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~Barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;checkin();
&nbsp;};
&nbsp;
&nbsp;Barrier::Barrier(int&nbsp;n)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numEntered&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numLeaving&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numThreads&nbsp;=&nbsp;n;
&nbsp;}
&nbsp;
&nbsp;//&nbsp;No&nbsp;one&nbsp;returns&nbsp;until&nbsp;all&nbsp;threads
&nbsp;//&nbsp;have&nbsp;called&nbsp;checkin.
&nbsp;void
&nbsp;checkin()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numEntered++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(numEntered&nbsp;&lt;&nbsp;numThreads)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(numEntered&nbsp;&lt;&nbsp;numThreads)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allCheckedIn.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;no&nbsp;threads&nbsp;in&nbsp;allLeaving.wait
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numLeaving&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allCheckedIn.broadcast();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numLeaving++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(numLeaving&nbsp;&lt;&nbsp;numThreads)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(numLeaving&nbsp;&lt;&nbsp;numThreads)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allLeaving.wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;no&nbsp;threads&nbsp;in&nbsp;allCheckedIn.wait
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numEntered&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;allLeaving.broadcast();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.13: </B>Implementation of a re-usable synchronization barrier.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><A id=x1-64004r105 name=x1-64004r105></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.6.3 </FONT><A id=x1-650003 name=x1-650003></A><FONT style="BACKGROUND-COLOR: #7be1e1">FIFO Blocking Bounded Queue</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Assuming Mesa semantics for condition variables, our implementation of the thread-safe blocking bounded queue in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-560018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> does not guarantee freedom from starvation. For example, a thread may call remove and wait in the while loop because the queue is empty. Starvation would occur if every time another thread inserts an item into the queue, a <EM>different</EM> thread calls remove, acquires the lock, sees that the queue is full, and removes the item before the waiting thread resumes. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Often, starvation is not a concern. For example, if we have one thread putting items into the queue, and n equivalent worker threads removing items from the queue, it may not matter which of the worker threads goes first. Even if starvation is a concern, as long as calls to insert and remove are infrequent, or the buffer is rarely empty or full, every thread is highly likely to make progress. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose, however, we do need a thread-safe bounded buffer that does guarantee progress to all threads. We can more formally define the liveness constraint as: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Starvation-freedom.</B> If a thread waits in insert, then it is guaranteed to proceed after a bounded number of remove calls complete, and vice versa. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>First-in-first-out (FIFO).</B> A stronger constraint is that the queue is first-in-first-out, or FIFO. The nth thread to acquire the lock in remove retrieves the item inserted by the nth thread to acquire the lock in insert. </FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Under Hoare semantics, the implementation in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-560018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> is FIFO, and therefore also starvation-free, provided that <TT>signal</TT>&nbsp;wakes up the thread waiting the longest. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Here we consider a related question: can we implement a starvation-free or FIFO bounded buffer using Mesa semantics? We need to ensure that when one thread signals a waiter, the waiting thread (and not any other) removes the item. </FONT><A id=x1-6500114 name=x1-6500114></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;ConditionQueue&nbsp;insertQueue;
&nbsp;ConditionQueue&nbsp;removeQueue;
&nbsp;int&nbsp;numRemoveCalled&nbsp;=&nbsp;0;&nbsp;//&nbsp;#&nbsp;of&nbsp;times&nbsp;remove&nbsp;has&nbsp;been&nbsp;called
&nbsp;int&nbsp;numInsertCalled&nbsp;=&nbsp;0;&nbsp;//&nbsp;#&nbsp;of&nbsp;times&nbsp;insert&nbsp;has&nbsp;been&nbsp;called
&nbsp;
&nbsp;int
&nbsp;FIFOBBQ::remove()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;item;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;myPosition;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CV&nbsp;*myCV,&nbsp;*nextWaiter;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;myPosition&nbsp;=&nbsp;numRemoveCalled++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mycv&nbsp;=&nbsp;new&nbsp;CV;&nbsp;&nbsp;//&nbsp;Create&nbsp;a&nbsp;new&nbsp;condition&nbsp;variable&nbsp;to&nbsp;wait&nbsp;on.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removeQueue.append(myCV);
&nbsp;
&nbsp;//&nbsp;Even&nbsp;if&nbsp;I&nbsp;am&nbsp;woken&nbsp;up,&nbsp;wait&nbsp;until&nbsp;it&nbsp;is&nbsp;my&nbsp;turn.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(front&nbsp;&lt;&nbsp;myPosition&nbsp;||&nbsp;front&nbsp;==&nbsp;nextEmpty)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mycv-&gt;Wait(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete&nbsp;self;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;The&nbsp;condition&nbsp;variable&nbsp;is&nbsp;no&nbsp;longer&nbsp;needed.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item&nbsp;=&nbsp;items[front&nbsp;%&nbsp;size];
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;front++;
&nbsp;
&nbsp;//&nbsp;Wake&nbsp;up&nbsp;the&nbsp;next&nbsp;thread&nbsp;waiting&nbsp;in&nbsp;insert,&nbsp;if&nbsp;any.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextWaiter&nbsp;=&nbsp;insertQueue.removeFromFront();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(nextWaiter&nbsp;!=&nbsp;NULL)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nextWaiter-&gt;Signal(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;item;
&nbsp;}</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.14: </B>An implementation of FIFO Blocking Bounded Buffer using Mesa semantics. ConditionQueue is a linked list of condition variables.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The easiest way to do this is to create a condition variable for each separate waiting thread. Then, you can be precise as to which thread to wake up! Although you might be worried that this would be space inefficient, on modern computer systems a condition variable (or lock) takes up just a few words of DRAM; it is small compared to the rest of the storage needed per thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The outline of the solution is as follows: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Create a condition variable for every waiter. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Put condition variables on a queue in FIFO order. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Signal wakes up the thread at the front of the queue. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Be CAREFUL about spurious wakeups!</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We give an implementation of FIFOBBQ::remove in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6500114"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.14</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">; insert is similar. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The implementation easily extends to the case where we want the queue to be last in first out (LIFO) rather than FIFO, or if want it to wake up threads in some priority order. With Hoare semantics, this is not as easy; we would need to have a different implementation of CV for each different queueing discipline, rather than leaving it to those few applications where the specific order matters. </FONT><A id=x1-65002r101 name=x1-65002r101></A></P><A id=x1-660007 name=x1-660007>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7 Implementing Synchronization Objects</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">Now that we have described locks and condition variables and shown how to use them in shared objects, we turn to how to implement these important building blocks. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Recall from Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> that threads can be implemented in the kernel or at user level. We start by describing how to implement synchronization for kernel threads; at the end of this section we discuss the changes needed to support these abstractions for user-level threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Both locks and condition variables have state. For locks, this is the state of the lock (FREE&nbsp;or BUSY) and a queue of zero or more threads waiting for the lock to become FREE. For condition variables, the state is the queue of threads waiting to be signaled. Either way, the challenge is to atomically modify those data structures. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The Too Much Milk discussion showed that it is both complex and costly to implement atomic actions with just memory reads and writes. Therefore, modern implementations use more powerful hardware primitives that let us atomically read, modify, and write pieces of state. We use two hardware primitives: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Disabling interrupts.</B> On a single processor, we can make a sequence of instructions atomic by disabling interrupts on that single processor. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Atomic read-modify-write instructions.</B> On a multiprocessor, disabling interrupts is insufficient to provide atomicity. Instead, architectures provide special instructions to atomically read and update a word of memory. These instructions are globally atomic with respect to the instructions on every processor.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Each of these primitives also serves as a memory barrier; they inform the compiler and hardware that all prior instructions must complete before the atomic instruction is executed. </FONT><A id=x1-66001r109 name=x1-66001r109></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.1 </FONT><A id=x1-670001 name=x1-670001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Uniprocessor Locks by Disabling Interrupts</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">On a uniprocessor, any sequence of instructions by one thread appears atomic to other threads if no context switch occurs in the middle of the sequence. So, on a uniprocessor, a thread can make a sequence of actions atomic by disabling interrupts (and refraining from calling thread library functions that can trigger a context switch) during the sequence. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This observation suggests a trivial &#8212; but seriously limited &#8212; approach to implementing locks on a uniprocessor: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;Lock::acquire()&nbsp;{&nbsp;disableInterrupts();&nbsp;}
   &nbsp;
   &nbsp;Lock::release()&nbsp;{&nbsp;enableInterrupts();&nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This implementation does provide the mutual exclusion property we need from locks. Some uniprocessor kernels use this simple approach, but it does not suffice as a general implementation for locks. If the code sequence the lock protects runs for a long time, interrupts will be disabled for that long. This will prevent other threads from running, and it will make the system unresponsive to handling user inputs or other real-time tasks. Furthermore, although this approach can work in the kernel where all code is (presumably) carefully crafted and trusted to release the lock quickly, we cannot let untrusted user-level code run with interrupts turned off since a malicious or buggy program could then monopolize the processor. </FONT><A id=x1-67001r112 name=x1-67001r112></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.2 </FONT><A id=x1-680002 name=x1-680002></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Uniprocessor Queueing Locks</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">A more general solution is based on the observation that if the lock is BUSY, there is no point in running the acquiring thread until the lock is free. Instead, we should context switch to the next ready thread. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The implementation briefly disables interrupts to protect the lock&#8217;s data structures, but re-enables them once a thread has acquired the lock or determined that the lock is BUSY. The Lock implementation shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6800115"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.15</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> illustrates this approach. If a lock is BUSY&nbsp;when a thread tries to acquire it, the thread moves its TCB onto the lock&#8217;s waiting list. The thread then suspends itself and switches to the next runnable thread. The call to suspend does not return until the thread is put back on the ready list, e.g., until some thread calls Lock::release. </FONT><A id=x1-6800115 name=x1-6800115></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;Lock&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;value&nbsp;=&nbsp;FREE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;waiting;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;release();
&nbsp;}
&nbsp;
&nbsp;Lock::acquire()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*chosenTCB;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(value&nbsp;==&nbsp;BUSY)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waiting.add(runningThread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;WAITING;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chosenTCB&nbsp;=&nbsp;readyList.remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_switch(runningThread,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chosenTCB);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;RUNNING;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;BUSY;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
&nbsp;
&nbsp;Lock::release()&nbsp;{
&nbsp;//&nbsp;next&nbsp;thread&nbsp;to&nbsp;hold&nbsp;lock
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*next;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waiting.notEmpty())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;move&nbsp;one&nbsp;TCB&nbsp;from&nbsp;waiting
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;to&nbsp;ready
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;next&nbsp;=&nbsp;waiting.remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;next-&gt;state&nbsp;=&nbsp;READY;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readyList.add(next);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;FREE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.15: </B>Pseudo-code for a uniprocessor queueing lock. Temporarily disabling interrupts provides atomic access to the data structures implementing the lock. suspend(oldTCB, newTCB) switches from the current thread to the next to be run. It returns only after some other thread calls release and moves it to the ready list.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In our implementation, if a thread is waiting for the lock, a call to release does not set value to FREE. Instead, it leaves value as BUSY. The woken thread is guaranteed to be the next that executes the critical section. This arrangement ensures freedom from starvation. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>WARNING</B>: This optimization is specific to this implementation. Users of locks should not make assumptions about the order in which waiting threads acquire a lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>In Lock::acquire, thread_switch is called with interrupts turned off. Who turns them back on? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>The next thread to run re-enables interrupts.</B> In particular, most implementations of thread systems enforce the invariant that a thread always disables interrupts before performing a context switch. As a result, interrupts are always disabled when the thread runs again after a context switch. Thus, whenever a thread returns from a context switch, it must re-enable interrupts. For example, the Lock::acquire code in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6800115"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.15</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> re-enables interrupts before returning; the yield implementation in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> disables interrupts before the context switch and then re-enables them afterwards. &#9633; </FONT><A id=x1-68002r113 name=x1-68002r113></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.3 </FONT><A id=x1-690003 name=x1-690003></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Multiprocessor Spinlocks</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">On a multiprocessor, however, disabling interrupts is insufficient. Even when interrupts are turned off on one processor, other threads are running concurrently. Operations by a thread on one processor are interleaved with operations by other threads on other processors. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Since turning off interrupts is insufficient, most processor architectures provide <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:atomic read-modify-write instruction"}'>atomic read-modify-write instructions</A></EM> to support synchronization. These instructions can read a value from a memory location to a register, modify the value, and write the modified value to memory atomically with respect to all instructions on other processors. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Implementing read-modify-write instructions</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Students often ask at this point how the processor hardware implements atomic instructions such as test-and-set. If each processor has its own cache, what is to keep two processors from reading and updating the same location at the same time? Although a complete explanation is beyond the scope of this textbook, the hardware uses the same mechanism as it uses for cache coherence. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Every entry in a processor cache has a state, either <EM>exclusive</EM> or <EM>read-only</EM>. If any other processors have a cached copy of the data, it must be <EM>read-only</EM> everywhere. To modify a shared memory location, the processor must have an <EM>exclusive</EM> copy of the data; no other cache is allowed to have a copy. Otherwise, one processor could read an out-of-date value for some location that another processor has already updated. To read or write a location that is stored <EM>exclusive</EM> in some other cache, the processor needs to fetch the latest value from that cache. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Read-modify-write instructions piggyback on this mechanism. To execute one of these instructions, the hardware acquires an <EM>exclusive</EM> copy of the memory, removing copies from all other caches. Then the instruction executes on the local copy; after the instruction completes, other processors are allowed to read the result by fetching the latest value. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As an example, some architectures provide a <EM>test-and-set</EM> instruction, which atomically reads a value from memory to a register and writes the value 1 to that memory location. </FONT><A id=x1-6900116 name=x1-6900116></A></P><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;SpinLock&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;value&nbsp;=&nbsp;0;&nbsp;//&nbsp;0&nbsp;=&nbsp;FREE;&nbsp;1&nbsp;=&nbsp;BUSY
&nbsp;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;acquire()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(test_and_set(&amp;value))&nbsp;//&nbsp;while&nbsp;BUSY
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;//&nbsp;spin
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;release()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;0;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.16: </B>A multiprocessor spinlock implementation using test-and-set.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-6900116"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.16</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> implements a lock using test_and_set. This lock is called a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:spinlock"}'>spinlock</A></EM> because a thread waiting for a BUSY&nbsp;lock &#8220;spins&#8221; (busy-waits) in a tight loop until some other lock releases the lock. This approach is inefficient if locks are held for long periods. However, for locks that are only held for short periods (i.e., less time than a context switch would take), spinlocks make sense. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<DIV class=sidebar align=center><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD style="BACKGROUND-COLOR: #f0f0f0" align=left>
<P width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><SPAN class=sidebar_name><B><I>Interrupt handlers and spinlocks</I></B></SPAN> </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Whenever an interrupt handler accesses shared data, that data must be protected by a spinlock instead of a queueing lock. As we explained in Chapter&nbsp;2 and Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, interrupt handlers are not threads: they must run to completion without blocking so that the hardware can deliver the next interrupt. With a queueing lock, the lock might be held when the interrupt handler starts, making it impossible for the interrupt handler to work correctly. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Whenever any thread acquires a spinlock used within an interrupt handler, the thread <EM>must</EM> disable interrupts first. Otherwise, deadlock can result if the interrupt arrives at an inopportune moment. The handler could spin forever waiting for a lock held by the thread it interrupted. Most likely, the system would need to be rebooted to clear the problem. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To avoid these types of errors, most operating systems keep interrupt handlers extremely simple. For example, many interrupt handlers simply wake up a thread to do the heavy lifting of managing the I/O device. Waking up a thread requires mutually exclusive access to the ready list, protected by a spinlock that is never used without first disabling interrupts. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></TD></TR></TBODY></TABLE><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT></DIV><A id=x1-69002r115 name=x1-69002r115></A>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.4 </FONT><A id=x1-700004 name=x1-700004></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Multiprocessor Queueing Locks</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Often, we need to support critical sections of varying length. For example, we may want a general solution that does not make assumptions about the running time of methods that hold locks. </FONT><A id=x1-7000117 name=x1-7000117></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;Lock&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;value&nbsp;=&nbsp;FREE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SpinLock&nbsp;spinLock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;waiting;
&nbsp;&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;release();
&nbsp;}
&nbsp;
&nbsp;Lock::acquire()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinLock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(value&nbsp;!=&nbsp;FREE)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waiting.add(runningThread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scheduler.suspend(&amp;spinLock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;scheduler&nbsp;releases&nbsp;spinLock
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;BUSY;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinLock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;
&nbsp;void&nbsp;Lock::release()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*next;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinLock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waiting.notEmpty())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;next&nbsp;=&nbsp;waiting.remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scheduler.makeReady(next);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;FREE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinLock.release();
&nbsp;}
</FONT></PRE><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;Scheduler&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;readyList;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SpinLock&nbsp;schedulerSpinLock;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;suspend(SpinLock&nbsp;*lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;makeReady(Thread&nbsp;*thread);
&nbsp;}
&nbsp;
&nbsp;void
&nbsp;Scheduler::suspend(SpinLock&nbsp;*lock)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCB&nbsp;*chosenTCB;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schedulerSpinLock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;WAITING;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chosenTCB&nbsp;=&nbsp;readyList.getNextThread();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread_switch(runningThread,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chosenTCB);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningThread-&gt;state&nbsp;=&nbsp;RUNNING;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schedulerSpinLock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
&nbsp;
&nbsp;void
&nbsp;Scheduler::makeReady(TCB&nbsp;*thread)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schedulerSpinLock.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readyList.add(thread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread-&gt;state&nbsp;=&nbsp;READY;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;schedulerSpinLock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.17: </B>Pseudo-code for a multiprocessor queueing lock. Both the scheduler and the lock use spinlocks to protect their internal data structures. Any thread that tries to acquire the lock when it is BUSY&nbsp;is put on a queue for later wakeup. Care is needed to prevent the waiting thread from being put back on the ready list before it has completed the thread_switch.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">We cannot completely eliminate busy-waiting on a multiprocessor, but we can minimize it. As we mentioned, the scheduler ready list needs a spinlock. The scheduler holds this spinlock for only a few instructions; further, if the ready list spinlock is BUSY, there is no point in trying to switch to a different thread, as that would require access to the ready list. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To reduce contention on the ready list spinlock, we use a <EM>separate</EM> spinlock to guard access to each lock&#8217;s internal state. Once a thread holds the lock&#8217;s spinlock, the thread can inspect and update the lock&#8217;s state. If the lock is FREE, the thread sets the value and releases its spinlock. If the lock is BUSY, more work is needed: we need to put the current thread on the waiting list for the lock, suspend the current thread, and switch to a new thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Careful sequencing is needed, however, as shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. To suspend a thread on a multiprocessor, we need to first disable interrupts to ensure the thread is not preempted while holding the ready list spinlock. We then acquire the ready list spinlock, and <EM>only then</EM> is it safe to release the lock&#8217;s spinlock and switch to a new thread. The ready list spinlock is released by the next thread to run. Otherwise, a different thread on another processor might put the waiting thread back on the ready list (and start it running) before the waiting thread has completed its context switch. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Later, when the lock is released, if any threads are waiting for the lock, one of them is moved off the lock&#8217;s waiting list to the scheduler&#8217;s ready list. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What might happen if we released the Lock&#8217;s spinlock before the call to suspend? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B>The basic issue is that we want to make sure the acquiring thread finishes suspending itself before a thread releasing the lock tries to reschedule it. If we allowed makeReady to run before suspend, makeReady would mark the acquring thread READY, but suspend would then change the thread&#8217;s state to WAITING. The acquiring thread would then be stuck in the WAITING state forever. Since this sequence would happen very rarely, it would be extremely difficult to locate the problem. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>NOTE</B>: In the implementation in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the single scheduler spinlock can become a bottleneck as the number of processors increases. Instead, as we explain in Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-780006"}'><FONT style="BACKGROUND-COLOR: #7be1e1">6</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, most systems have one ready list per processor, each protected by a different spinlock. Different processors can then simultaneously add and remove threads to different lists. Typically, the WAITING&nbsp;thread is placed on the ready list of the same processor where it had previously been RUNNING; this improves cache performance as that processor&#8217;s cache may still contain code and data from the last time the thread ran. Putting the thread back on the same ready list also prevents the thread from being run by any other processor before the thread has completed its context switch. Once it is READY, any idle processor can run the thread by acquiring the spinlock of the ready list where it is enqueued, removing the thread, and releasing the spinlock. </FONT><A id=x1-70002r117 name=x1-70002r117></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.5 </FONT><A id=x1-710005 name=x1-710005></A><FONT style="BACKGROUND-COLOR: #7be1e1">Case Study: Linux 2.6 Kernel Mutex Lock</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">We illustrate how locks are implemented in practice by examining the Linux 2.6 kernel. The Linux code closely follows the approach we described above, except that it is <EM>optimized for the common case</EM>. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In Linux, most locks are FREE&nbsp;most of the time. Further, even if a lock is BUSY, it is likely that no other thread is waiting for it. The alternative, that locks are often BUSY, or have long queues of threads waiting for them, means that any thread that needs the lock will usually need to wait, slowing the system down. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The Linux implementation of locks takes advantage of this by providing an extremely fast path for the case when the thread does not need to wait for the lock in acquire, and when there is no thread not need to wake up a thread in release. A slow path, similar to Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, is used for all other cases. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Further, having a fast path for acquiring a FREE&nbsp;lock, and releasing a lock with no waiting thread, is also a concern for user-level thread libraries, discussed below. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To optimize the common case path, Linux takes advantage of hardware-specific features of the x86. The x86 supports a large number of different read-modify-write instructions, including atomic decrement (subtract one from the memory location, returning the previous value), atomic increment, atomic exchange (swap the value of the memory location with the value stored in a register), and atomic test-and-set. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The key idea is to design the lock data structures to allow the lock to be acquired and released on the fast path <EM>without</EM> first acquiring the spinlock or disabling interrupts. The slowpath does require acquiring the spinlock. Instead of being binary, the lock value is an integer count with three states: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;struct&nbsp;mutex&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/*&nbsp;1:&nbsp;unlocked,&nbsp;0:&nbsp;locked,&nbsp;negative:&nbsp;locked,&nbsp;possible&nbsp;waiters&nbsp;*/
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;atomic_t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinlock_t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wait_lock;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;struct&nbsp;list_head&nbsp;&nbsp;wait_list;
   &nbsp;};</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The Linux lock acquire code is a macro (to avoid making a procedure call on the fast path) that translates to a short sequence of instructions. The x86 lock prefix before the decl instruction signifies to the processor that the instruction should be executed atomically. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock&nbsp;decl&nbsp;(%eax)&nbsp;&nbsp;//&nbsp;atomic&nbsp;decrement&nbsp;of&nbsp;a&nbsp;memory&nbsp;location
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;address&nbsp;in&nbsp;%eax&nbsp;is&nbsp;pointer&nbsp;to&nbsp;lock-&gt;count
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jns&nbsp;1f&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;jump&nbsp;if&nbsp;not&nbsp;signed&nbsp;(if&nbsp;value&nbsp;is&nbsp;now&nbsp;0)
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;call&nbsp;slowpath_acquire
   &nbsp;1:</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If the lock was FREE, the lock is acquired with only two instructions; if the lock was BUSY, the code leaves count &lt; 0 and invokes a separate routine to handle the slow path. The slow path disables preemption, acquires the spinlock, puts the thread on the lock wait queue, and then re-checks whether the lock has been released in the meantime. For this, it uses the atomic exchange instruction: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;for&nbsp;(;;)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/*
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Lets&nbsp;try&nbsp;to&nbsp;take&nbsp;the&nbsp;lock&nbsp;again&nbsp;-&nbsp;this&nbsp;is&nbsp;needed&nbsp;even&nbsp;if
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;we&nbsp;get&nbsp;here&nbsp;for&nbsp;the&nbsp;first&nbsp;time&nbsp;(shortly&nbsp;after&nbsp;failing&nbsp;to
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;acquire&nbsp;the&nbsp;lock),&nbsp;to&nbsp;make&nbsp;sure&nbsp;that&nbsp;we&nbsp;get&nbsp;a&nbsp;wakeup&nbsp;once
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;it&#8217;s&nbsp;unlocked.&nbsp;Later&nbsp;on,&nbsp;if&nbsp;we&nbsp;sleep,&nbsp;this&nbsp;is&nbsp;the
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;operation&nbsp;that&nbsp;gives&nbsp;us&nbsp;the&nbsp;lock.&nbsp;We&nbsp;xchg&nbsp;it&nbsp;to&nbsp;-1,&nbsp;so
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;that&nbsp;when&nbsp;we&nbsp;release&nbsp;the&nbsp;lock,&nbsp;we&nbsp;properly&nbsp;wake&nbsp;up&nbsp;the
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;other&nbsp;waiters:
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(atomic_xchg(&amp;lock-&gt;count,&nbsp;-1)&nbsp;==&nbsp;1)
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break;
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/*&nbsp;didn&#8217;t&nbsp;get&nbsp;the&nbsp;lock,&nbsp;go&nbsp;to&nbsp;sleep:&nbsp;*/
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If successful, the lock is acquired. If unsuccessful, the thread releases the spinlock and switches to the next ready thread. When the thread returns from suspend, unlike in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the lock may not be FREE, and so the thread must try again. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Eventually, the thread breaks out of the loop, which means that it found a moment when the lock was FREE&nbsp;(lock-&gt;count = 1), and at that moment it set the lock to the &#8220;busy, possible waiters&#8221; state (by setting count = -1). The thread now has the lock, and it cleans up by resetting count = 0 if there are no other waiters. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;/*&nbsp;set&nbsp;it&nbsp;to&nbsp;0&nbsp;if&nbsp;there&nbsp;are&nbsp;no&nbsp;waiters&nbsp;left:&nbsp;*/
   &nbsp;if&nbsp;(list_empty(&amp;lock-&gt;wait_list))
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;atomic_set(&amp;lock-&gt;count,&nbsp;0);</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">It then releases the spinlock and re-enables preemptions. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">On release, the fast path is two inlined instructions if the lock value was 0 (the lock has no waiters). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock&nbsp;incl&nbsp;(%eax)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;atomic&nbsp;increment
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jg&nbsp;1f&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;jump&nbsp;if&nbsp;new&nbsp;value&nbsp;is&nbsp;1
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;call&nbsp;slowpath_release
   &nbsp;1:</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">On the slow path, count was negative. The increment instruction leaves the lock BUSY. Then, the thread acquires the spinlock, sets the count to be FREE, and wakes up one of the waiting threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;spin_lock_mutex(&amp;lock-&gt;wait_lock,&nbsp;flags);
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/*
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;Unlock&nbsp;lock&nbsp;here
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/
   &nbsp;atomic_set(&amp;lock-&gt;count,&nbsp;1);
   &nbsp;if&nbsp;(!list_empty(&amp;lock-&gt;wait_list))&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;struct&nbsp;mutex_waiter&nbsp;*waiter&nbsp;=
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list_entry(lock-&gt;wait_list.next,
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;struct&nbsp;mutex_waiter,&nbsp;list);
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wake_up_process(waiter-&gt;task);
   &nbsp;}
   &nbsp;spin_unlock_mutex(&amp;lock-&gt;wait_lock,&nbsp;flags);</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Notice that this function always sets count to 1, even if there are waiting threads. As a result, a new thread may swoop in and acquire the lock on its fast path, setting count = 0. In this case, the waiting thread is still woken up, and when it eventually runs, the main loop above will set count = -1. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This example demonstrates that acquiring and releasing a lock can be inexpensive. Programmers sometimes go to great lengths to avoid acquiring a lock in a particular situation. However, the reasoning in such cases can be subtle, and omitting needed locks is dangerous. In cases where there is little contention, avoiding locks is unlikely to significantly improve performance, so it is usually better just to keep things simple and rely on locks to ensure mutual exclusion when accessing shared state. </FONT><A id=x1-71001r119 name=x1-71001r119></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.6 </FONT><A id=x1-720006 name=x1-720006></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Condition Variables</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">We can implement condition variables using a similar approach to the one used to implement locks, with one simplification: since the lock is held whenever the <TT>wait</TT>, <TT>signal</TT>, or <TT>broadcast</TT>&nbsp;is called, we already have mutually exclusive access to the condition wait queue. As with locks, care is needed to prevent a waiting thread from being put back on the ready list until it has completed its context switch; we can accomplish this by acquiring the scheduler spinlock <EM>before</EM> we release the monitor lock. Another thread may acquire the monitor lock and start to signal the waiting thread, but it will not be able to complete the signal until the scheduler lock is released immediately after the context switch. </FONT><A id=x1-7200118 name=x1-7200118></A><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;class&nbsp;CV&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;waiting;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;wait(Lock&nbsp;*lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;signal();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;broadcast();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Monitor&nbsp;lock&nbsp;is&nbsp;held&nbsp;by&nbsp;current&nbsp;thread.
&nbsp;void&nbsp;CV::wait(Lock&nbsp;*lock)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(lock.isHeld());
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waiting.add(myTCB);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Switch&nbsp;to&nbsp;new&nbsp;thread&nbsp;and&nbsp;release&nbsp;lock.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scheduler.suspend(&amp;lock);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;acquire();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Monitor&nbsp;lock&nbsp;is&nbsp;held&nbsp;by&nbsp;current&nbsp;thread.
&nbsp;void&nbsp;CV::signal()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waiting.notEmpty())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread&nbsp;=&nbsp;waiting.remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scheduler.makeReady(thread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;
&nbsp;void&nbsp;CV::broadcast()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(waiting.notEmpty())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thread&nbsp;=&nbsp;waiting.remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scheduler.makeReady(thread);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
</FONT></PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Figure&nbsp;5.18: </B>Pseudo-code for implementing a condition variable. suspend and makeReady are defined in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">.</FONT></P></TD></TR></TBODY></TABLE></DIV><FONT style="BACKGROUND-COLOR: #7be1e1">
<HR>
</FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7200118"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.18</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> shows an implementation with Mesa semantics &#8212; when we signal a waiting thread, that thread becomes READY, but it may not run immediately and must still re-acquire the monitor lock. It is possible for another thread to acquire the monitor lock first and to change the state guarded by the lock before the waiting thread returns from CV::wait. </FONT><A id=x1-72002r120 name=x1-72002r120></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.7.7 </FONT><A id=x1-730007 name=x1-730007></A><FONT style="BACKGROUND-COLOR: #7be1e1">Implementing Application-level Synchronization</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">The preceding discussion focused on implementing locks and condition variables for kernel threads. In that case, everything (code, shared state, lock data structures, thread control blocks, and the ready list) is in kernel memory, and all threads run in kernel mode. Fortunately, although some details change, the same basic approach works when we implement locks and condition variables for use by threads that run at user level. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Recall from Chapter&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-100004"}'><FONT style="BACKGROUND-COLOR: #7be1e1">4</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> that there are two ways of supporting application-level concurrency: via system calls to access kernel thread operations or via a user-level thread scheduler. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Kernel-Managed Threads.</B> With kernel-managed threads, the kernel provides threads to a process and manages the thread ready list. The kernel scheduler needs to know when a thread is waiting for a lock or condition variable so that it can suspend the thread and switch to the next ready thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In the simplest case, we can place the lock and condition variable data structures, including the waiting lists, in the kernel&#8217;s address space. Each method call on the synchronization object translates to a system call. Then, the implementations described above for kernel-level locks and condition variables can be used without significant change. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A more sophisticated approach splits the lock&#8217;s state and implementation into a fast path and slow path, similar to the Linux lock described above. For example, each lock has two data structures: (i) the process&#8217;s address space holds something similar to the count field and (ii) the kernel holds the spinlock and wait_list queue. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Then, acquiring a FREE&nbsp;lock or releasing a lock with no waiting threads takes a few instructions at user level, with no system call. The slow path still needs a system call (e.g., when a waiting thread needs to suspend execution). We leave the details of the implementation as an exercise for the reader. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>User-Managed Threads.</B> In a </FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-300002"}'><FONT style="BACKGROUND-COLOR: #7be1e1">thread library that operates completely at user level</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, the library creates multiple kernel threads to serve as virtual processors, and then multiplexes user-level threads over those virtual processors. This situation is similar to kernel threads, except operating inside the process&#8217;s address space rather than in the kernel&#8217;s address space. In particular, the code, shared state, lock and condition variable data structures, thread control blocks, and the ready list are in the process&#8217;s address space. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The only significant change has to do with disabling interrupts. Obviously, a user-level thread package cannot disable system-level interrupts; the kernel cannot allow an untrusted process to disable interrupts and potentially run forever. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Fortunately, the thread library only needs to disable upcalls from the operating system; these are used to trigger thread preemption and other operations in the user-level scheduler, and they could cause inconsistency if they occur while the library is modifying scheduler data structures. Most modern operating systems have a way to temporarily disable upcalls, and then to deliver those upcalls once it is safe to do so. By ensuring the user-level scheduler and upcall handler cannot run at the same time, the fast path mutex implementation described above can be used here as well. </FONT><A id=x1-73001r111 name=x1-73001r111></A></P><A id=x1-740008 name=x1-740008>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.8 Semaphores Considered Harmful</FONT></H3></A>
<DIV class=makequote><FONT style="BACKGROUND-COLOR: #7be1e1">&#8220;During system conception it transpired that we used the semaphores in two completely different ways. The difference is so marked that, looking back, one wonders whether it was really fair to present the two ways as uses of the very same primitives. On the one hand, we have the semaphores used for mutual exclusion, on the other hand, the private semaphores.&#8221;<BR>(From Dijkstra &#8220;The structure of the &#8217;THE&#8217;-Multiprogramming System&#8221; <EM>Communications of the ACM</EM> v. 11 n. 5 May 1968.)</FONT></DIV>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">This book focuses on constructing shared objects using locks and condition variables for synchronization. However, over the years, many different synchronization primitives have been proposed, including communicating sequential processes, event delivery, message passing, and so forth. It is important to realize that none of these are more powerful than using locks and condition variables; a program using any of these paradigms can be mapped to monitors using straightforward transformations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">One type of synchronization, a <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:semaphore"}'>semaphore</A></EM>, is worth discussing in detail since it is still widely used. Semaphores were introduced by Dijkstra to provide synchronization in the THE operating system, which (among other advances) explored structured ways of using concurrency in operating system design. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Semaphores are defined as follows: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A semaphore has a non-negative value. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">When a semaphore is created, its value can be initialized to any non-negative integer. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Semaphore::P() waits until the value is positive. Then, it atomically decrements value by 1 and returns. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Semaphore::V() atomically increments the value by 1. If any threads are waiting in P, one is enabled, so that its call to P succeeds at decrementing the value and returns. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">No other operations are allowed on a semaphore; in particular, no thread can directly read the current value of the semaphore.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Note that Semaphore::P is an atomic operation: the read that observes the positive value is atomic with the update that decrements it. As a result, semaphores can never have a negative value, even when multiple threads call P concurrently. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Likewise, if V occurs when there is a waiting thread in P, then P&#8217;s increment and V&#8217;s decrement of value are atomic: no other thread can observe the incremented value, and the thread in P is guaranteed to decrement the value and return. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Given this definition, semaphores can be used for either mutual exclusion (like locks) or general waiting for another thread to do something (a bit like condition variables). </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To use a semaphore as a mutual exclusion lock, initialize it to 1. Then, Semaphore::P is equivalent to Lock::acquire, and Semaphore::V is equivalent to Lock::release. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Using a semaphore for more general waiting is trickier. A useful analogy for semaphores is thread_join. With thread_join, the precise order of events does not matter: if the forked thread finishes before the parent thread calls thread_join, then the call returns right away. On the other hand, if the parent calls thread_join&nbsp;first, then it waits until the thread finishes, and then returns. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Semaphore P and V can be set up to behave similarly. Typically (but not always), you initialize the semaphore to 0. Then, each call to Semaphore::P waits for the corresponding thread to call V. If the V is called first, then P returns immediately. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">The difficulty comes when trying to coordinate shared state (needing mutual exclusion) with general waiting. From a distance, Semaphore::P is <EM>similar to</EM> CV::wait(&amp;lock) and Semaphore::V is <EM>similar to</EM> CV::signal. However, there are important differences. First, CV::wait(&amp;lock) atomically releases the monitor lock, so that you can safely check the shared object&#8217;s state and then atomically suspend execution. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">By contrast, Semaphore::P does <EM>not</EM> release an associated mutual exclusion lock. Typically, the lock is released before the call to P; otherwise, no other thread can access the shared state until the thread resumes. The programmer must carefully construct the program to work properly in this case. Second, whereas a condition variable is stateless, a semaphore has a value. If no threads are waiting, a call to CV::signal has no effect, while a call to Semaphore::V increments the value. This causes the next call to Semaphore::P to proceed without blocking. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Semaphores considered harmful.</B> Our view is that programming with locks and condition variables is superior to programming with semaphores. We advise you to always write your code using those synchronization variables for two reasons. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">First, using separate lock and condition variable classes makes code more self-documenting and easier to read. As the quote from Dijkstra notes, two different abstractions are needed, and code is clearer when the role of each synchronization variable is made clear through explicit typing. For example, it is much easier to verify that every lock acquire is paired with a lock release, if they are not mixed with other calls to P and V for general waiting. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Second, a stateless condition variable bound to a lock is a better abstraction for generalized waiting than a semaphore. By binding a condition variable to a lock, we can conveniently wait on any arbitrary predicate on an object&#8217;s state. In contrast, semaphores rely on the programmer to carefully map the object&#8217;s state to the semaphore&#8217;s value so that a decision to wait or proceed in P can be made entirely based on the value, without holding a lock or examining the rest of the shared object&#8217;s state. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Although we do not recommend writing new code with semaphores, code based on semaphores is not uncommon, especially in operating systems. So, it is important to understand the semantics of semaphores and be able to read and understand semaphore-based code written by others. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>NOTE</B>: <B>Semaphores in interrupt handlers.</B> In one situation, semaphores are superior to condition variables and locks: synchronizing communication between an I/O device and threads waiting for I/O completion. Typically, the hardware communicates with the device driver via a shared in-memory data structure. This data structure is read and written concurrently by both hardware and the kernel, but the shared access cannot be coordinated with a software lock. Instead, the hardware and device drivers use carefully designed atomic memory operations. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">If a hardware device needs attention, e.g., because a network packet has arrived that needs handling, or a disk request has completed, the hardware updates the shared data structure and starts an interrupt handler. The interrupt handler is often simple: it just wakes up a waiting thread and returns. For this, one might consider using a condition variable and calling <TT>signal</TT>&nbsp;without holding the lock (this is sometimes called a <EM>naked notify</EM>). Unfortunately, there is a corner case: suppose that the operating system thread first checks the data structure, sees that no work is currently needed, and is just about to call <TT>wait</TT>&nbsp;on the condition variable. At that moment, the hardware updates the data structure with the new work and triggers the interrupt handler to call <TT>signal</TT>. Because the thread has not called <TT>wait</TT>&nbsp;yet, the <TT>signal</TT>&nbsp;has no effect. Thus, when the thread calls <TT>wait</TT>, the signal has already occurred, and the thread waits &#8212; possibly for a long time. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A common solution is for device interrupts to use semaphores instead. Because semaphores are stateful, it does not matter whether the thread calls P or the interrupt handler calls V first: the result is the same, the V cannot be lost. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">To help illustrate the difference between semaphores and condition variables, we consider four candidate implementations of condition variables using semaphores. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Suppose you are writing concurrent application software on an operating system that only provides semaphores. Does the following code correctly implement condition variables? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;void&nbsp;CV::wait(Lock&nbsp;*lock)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;release();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.P();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;acquire();
   &nbsp;}
   &nbsp;
   &nbsp;void&nbsp;CV::signal()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.V();
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>No. Condition variables are stateless, while semaphores have state.</B> We can illustrate this difference with a counterexample. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">What happens if a thread calls <TT>signal</TT>&nbsp;and no one is waiting? Nothing. What happens if another thread later calls wait? The thread waits. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">By contrast, consider what happens with a semaphore. What happens if a thread calls V and no one is waiting? The value of the semaphore is incremented. What happens if a thread later calls P? The value of the semaphore is decremented, and the thread continues. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In other words, P and V are commutative. The result is the same no matter what order they occur. Condition variables are not commutative: <TT>wait</TT>&nbsp;does not return until the next <TT>signal</TT>. This is why condition variables must be accessed while holding a lock &#8212; code using a condition variable needs to access shared state variables to do its job. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">With condition variables, if a thread calls <TT>signal</TT>&nbsp;a thousand times, when no one is waiting, the next <TT>wait</TT>&nbsp;will still go to sleep. With the above code, the next thousand threads that <TT>wait</TT>&nbsp;will return immediately. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What about the following code? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;void&nbsp;CV::wait(Lock&nbsp;*lock)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;release();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.P();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;acquire();
   &nbsp;}
   &nbsp;
   &nbsp;void&nbsp;CV::signal()&nbsp;{
   &nbsp;&nbsp;&nbsp;if&nbsp;(!semaphore.queueEmpty())
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.V();
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>Closer, but still no.</B> For one, the definition of a semaphore does not allow users of the semaphore to look at the contents of the semaphore queue. But more importantly, there is a race condition. Once the lock is released, some other thread can slip in, <TT>acquire</TT>&nbsp;the lock and call <TT>signal</TT>&nbsp;before the waiting thread gets to call P. In that case, the queue is empty, so the waiter never exits the while loop. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Instead, the definition of CV::wait is that the lock is released and the thread goes to sleep atomically. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>What about the following code? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;void&nbsp;CV::wait(Lock&nbsp;*lock)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitQueue.append(myTCB);
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;release();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.P();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock-&gt;acquire();
   &nbsp;}
   &nbsp;
   &nbsp;void&nbsp;CV::signal()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!waitQueue.isEmpty())
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.V();
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>Very close but still no.</B> There is still a race condition. Suppose a thread calls <TT>wait</TT>, and releases the lock. Then another thread acquires the lock and calls <TT>signal</TT>. With condition variables, the waiter should wake up, but with the implementation above, a third thread could swoop in, acquire the lock, call <TT>wait</TT>, and decrement the semaphore before the first waiter has a chance to run. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For some programs, this difference would not be noticeable, but for others, it could cause problems. &#9633; </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>EXAMPLE: </B>Is it possible to implement condition variables using semaphores? </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>ANSWER: </B><B>Yes, using the technique we outlined for implementing the FIFO bounded buffer: create a semaphore for each waiter and then wake up exactly the right waiter.</B> This solution was developed by Andrew Birrell in order to implement condition variables on top of Microsoft Windows before it supported them natively. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">&nbsp;//&nbsp;Put&nbsp;thread&nbsp;on&nbsp;queue&nbsp;of&nbsp;waiting
&nbsp;//&nbsp;threads.
&nbsp;void&nbsp;CV::wait(Lock&nbsp;*lock)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore&nbsp;=&nbsp;new&nbsp;Semaphore(0);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitQueue.Append(semaphore);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.release();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.P();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock.acquire();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Wake&nbsp;up&nbsp;one&nbsp;waiter&nbsp;if&nbsp;any.
&nbsp;void&nbsp;CV::signal()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!waitQueue.isEmpty())&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore&nbsp;=&nbsp;queue.Remove();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;semaphore.V();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
   </FONT></PRE><FONT style="BACKGROUND-COLOR: #7be1e1">&#9633; </FONT><A id=x1-74001r123 name=x1-74001r123></A><A id=x1-750009 name=x1-750009>
<H3 class=sectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.9 Summary and Future Directions</FONT></H3></A><FONT style="BACKGROUND-COLOR: #7be1e1">This chapter advocates using a systematic, structured approach to writing multi-threaded code that shares state across threads. The approach, shared objects with concurrent access managed with locks and condition variables, has stood the test of time. Using shared objects makes reasoning about multi-threaded programs vastly simpler than it would be if we tried to reason about the possible interleavings of individual loads and stores. Further, by following a systematic approach, we make it possible for others to read, understand, maintain, and change the multi-threaded code we write. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In this chapter, we have discussed: </FONT></P>
<UL class=itemize1>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Race conditions.</B> The fundamental challenge to writing multi-threaded code that uses shared data is that the behavior of the program may depend on the precise ordering of operations executed by each thread. This non-deterministic behavior is difficult to reason about, reproduce, and debug. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Locks and condition variables.</B> Two useful sychronization abstractions are locks, providing mutual exclusion, and condition variables, for waiting for shared state to change. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>A methodology for writing shared objects.</B> Using locks and condition variables, we outlined a sequence of steps to writing correct synchronization code for coordinating access to shared objects. Following this methodology has proven enormously helpful for students in our classes by reducing the likelihood of design errors. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Implementations of synchronization.</B> Locks and condition variables can be efficiently implemented using hardware support for atomic read-modify-write instructions and, where necessary, the ability to temporarily defer hardware interrupts. In particular, we showed that the overhead of acquiring and releasing a non-contested lock can be as low as four instructions. </FONT></P>
<LI class=itemize>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Semaphores.</B> Semaphores are a widely implemented alternative to locks and condition variables, with a constructive role in managing hardware I/O interrupts.</FONT></P></LI></UL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In short, this chapter defines a set of core skills that almost any programmer will use over and over again during the coming decade or longer. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">That is not the whole story. As the next chapter will discuss, complex systems often include many shared objects and threads. This poses new challenges: synchronizing operations that span multiple shared objects, avoiding deadlocks in which a set of threads are all waiting for each other to do something, and maximizing performance when large numbers of threads are contending for a single object. </FONT><A id=x1-75001r122 name=x1-75001r122></A></P>
<H4 class=subsectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">5.9.1 </FONT><A id=x1-760001 name=x1-760001></A><FONT style="BACKGROUND-COLOR: #7be1e1">Historical Notes</FONT></H4><FONT style="BACKGROUND-COLOR: #7be1e1">Once researchers accepted the need to explicitly manage concurrency using threads, the challenge became how best to coordinate multi-threaded access to shared data. A large number of different abstractions were proposed, and it took some time to work out the different strengths and weaknesses of the various approaches. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Monitors &#8212; that is, managing shared data structures with locks and condition variables &#8212; were proposed in the early 1970&#8217;s in separate papers by Tony Hoare&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XHoare74monitors:an"}'><FONT style="BACKGROUND-COLOR: #7be1e1">83</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">] and Per Brinch Hansen&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XHansen:1970:NMS:362258.362278"}'><FONT style="BACKGROUND-COLOR: #7be1e1">75</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. One early advantage of monitors was the ability to formally prove properties about multi-threaded code; for example with Hoare-style semantics for condition variables, any statement which is true of the shared object immediately before a <TT>signal</TT>&nbsp;is also true of the object immediately after the return from <TT>wait</TT>. As we saw with the Too Much Milk example, without explicit synchronization, it can be quite difficult to reason about concurrent execution. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">By the early 1980&#8217;s, Xerox PARC had built the first personal computer, the Alto, with all of its system software written using threads (called lightweight processes at the time) and monitors. The methodology we present in this chapter originated with that project&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XLampson:1980:EPM:358818.358824"}'><FONT style="BACKGROUND-COLOR: #7be1e1">98</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. It is hard to overstate how radical an approach this was; almost all widely used operating systems of the time, including UNIX, were built using semaphores. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">An alternative line of work advocated completely prohibiting access by threads to shared data, as a way of eliminating race conditions. Instead of shared data, all data was private to a single thread; as a result, locks were never needed. An early example of this approach was Communicating Sequential Processes (CSP), also developed by Tony Hoare&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XHoare:1978:CSP:359576.359585"}'><FONT style="BACKGROUND-COLOR: #7be1e1">84</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. Google&#8217;s Go language for concurrent web programming is a modern language that supports both monitors and the CSP style of programming. With CSP and Go, a thread that needs to perform an operation on some other thread&#8217;s data sends it a message; the receiving thread can either reply with the result, or in data-flow style, forward the result onto some other thread. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">While there was considerable and vigorous debate at the time as to whether message-passing or shared-memory were better models for programming concurrency, the debate was largely resolved by a simple observation made by Lauer and Needham&nbsp;[</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "XLauer79onthe"}'><FONT style="BACKGROUND-COLOR: #7be1e1">101</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">]. Any program using monitors can be recast into CSP using a simple transformation, and vice versa. The execution of a procedure with a monitor lock is equivalent to processing a message in CSP; a monitor is, in effect, single-threaded while it is holding the lock. Thus, the choice of which style to use is largely a matter of taste and convention, and most programmers have chosen to use threads and monitors. </FONT><A id=Q1-1-126 name=Q1-1-126></A><A id=Q1-1-127 name=Q1-1-127></A></P><A id=x1-770001 name=x1-770001>
<H3 class=likesectionHead><FONT style="BACKGROUND-COLOR: #7be1e1">Exercises</FONT></H3></A>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<OL class=problems>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">True or False: If a multi-threaded program runs correctly in all cases on a single time-sliced processor, then it will run correctly if each thread is run on a separate processor of a shared-memory multiprocessor. Justify your answer. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Show that solution 3 to the Too Much Milk problem is safe &#8212; that it guarantees that at most one roommate buys milk. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Precisely describe the set of possible outputs that could occur when the program shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-530015"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.5</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> is run. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose that you mistakenly create an automatic (local) variable v in one thread t1 and pass a pointer to v to another thread t2. Is it possible that a write by t1 to some variable other than v will change the state of v as observed by t2? If so, explain how this can happen and give an example. If not, explain why not. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Suppose that you mistakenly create an automatic (local) variable v in one thread t1 and pass a pointer to v to another thread t2. Is it possible that a write by t2 to v will cause t1 to execute the wrong code? If so, explain how. If not, explain why not. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Assuming Mesa semantics for condition variables, our implementation of the blocking bounded queue in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-560018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> does not guarantee freedom from starvation: if a continuous stream of threads makes insert (or remove) calls, a waiting thread could wait forever. For example, a thread may call insert and wait in the while loop because the queue is full. Starvation would occur if every time another thread removes an item from the queue and signals the waiting thread, a <EM>different</EM> thread calls insert, sees that the queue is not full, and inserts an item before the waiting thread resumes. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Prove that under Hoare semantics and assuming that signal wakes the longest-waiting thread, our implementation of BBQ ensures freedom from starvation. More precisely, prove that if a thread waits in insert, then it is guaranteed to proceed after a bounded number of remove calls complete, and vice versa. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">As noted in the previous problem, our implementation of the blocking bounded queue in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-560018"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.8</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1"> does not guarantee freedom from starvation. Modify the code to ensure freedom from starvation so that if a thread waits in insert, it is guaranteed to proceed after a bounded number of remove() calls complete, and vice versa. <B>Note:</B> Your implementation must work under Mesa semantics for condition variables. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Wikipedia provides an implementation of Peterson&#8217;s algorithm to provide mutual exclusion using loads and stores at </FONT><A href="http://en.wikipedia.org/wiki/Peterson's_algorithm"><FONT style="BACKGROUND-COLOR: #7be1e1">http://en.wikipedia.org/wiki/Peterson&#8217;s_algorithm</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. Unfortunately, this code is not guaranteed to work with modern compilers or hardware. Update the code to include memory barriers where necessary. (Of course, you could add a memory barrier before and after each instruction; your solution should instead add memory barriers only where necessary for correctness.) </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Linux provides a sys_futex() system call to assist in implementing hybrid user-level/kernel-level locks and condition variables. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A call to long sys_futex(void *addr1, FUTEX_WAIT, int val1, NULL, NULL, 0) checks to see if the memory at address addr1 has the same value as val1. If so, the calling thread is suspended. If not, the calling thread returns immediately with the error return value EWOULDBLOCK. In addition, the system call returns with the value EINTR if the thread receives a signal. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">A call to long sys_futex(void *addr1, FUTEX_WAKE, 1, NULL, NULL, 0) causes one thread waiting on addr1 to return. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Consider the following simple implementation of a hybrid user-level/kernel-level lock. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;class&nbsp;TooSimpleFutexLock&nbsp;{
   &nbsp;&nbsp;&nbsp;private:
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;val;
   &nbsp;
   &nbsp;&nbsp;&nbsp;public:
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TooSimpleMutex()&nbsp;:&nbsp;val&nbsp;(0)&nbsp;{&nbsp;}&nbsp;&nbsp;//&nbsp;Constructor
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;acquire&nbsp;()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;c;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;atomic_inc&nbsp;returns&nbsp;*old*&nbsp;value
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;((c&nbsp;=&nbsp;atomic_inc&nbsp;(val))&nbsp;!=&nbsp;0)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;futex_wait&nbsp;(&amp;val,&nbsp;c&nbsp;+&nbsp;1);
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;release&nbsp;()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;=&nbsp;0;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;futex_wake&nbsp;(&amp;val,&nbsp;1);
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;};</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">There are three problems with this code. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<OL class=subproblems>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance.</B> The goal of this code is to avoid making expensive system calls in the uncontested case of an <TT>acquire</TT>&nbsp;on a FREE&nbsp;lock or a <TT>release</TT>&nbsp;of a lock with no other waiting threads. This code fails to meet this goal. Why? </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Performance.</B> A subtle corner case occurs when multiple threads try to acquire the lock at the same time. It can show up as occasional slowdowns and bursts of CPU usage. What is the problem? </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Correctness</B>. A corner case can cause the mutual exclusion correctness condition to be violated, allowing two threads to both believe they hold the lock. What is the problem? </FONT></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">In the readers/writers lock example for the function RWLock::doneRead, why do we use writeGo.Signal rather than writeGo.Broadcast? </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Show how to implement a semaphore by generalizing the multi-processor lock implementation shown in Figure&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-7000117"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.17</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">In Section&nbsp;</FONT><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-430003"}'><FONT style="BACKGROUND-COLOR: #7be1e1">5.1.3</FONT></A><FONT style="BACKGROUND-COLOR: #7be1e1">, we presented a solution to the Too Much Milk problem. To make the problem more interesting, we will also allow roommates to drink milk. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Implement in C++ or Java a Kitchen class with a drinkMilkAndBuyIfNeeded(). This method should randomly (with a 20% probability) change the value of milk from 1 to 0. Then, if the value just became 0, it should buy milk (incrementing milk back to 1). The method should return 1 if the roommate bought milk and 0 otherwise. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Your solution should use locks for synchronization and work for any number of roommates. Test your implementation by writing a program that repeatedly creates a Kitchen object and varying numbers of roommate threads; each roommate thread should call drinkMilkAndBuyIfNeeded() multiple times in a loop. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><B>Hint:</B> You will probably write a main() thread that creates a Kitchen object, creates multiple roommate threads, and then waits for all of the roommates to finish their loops. If you are writing in C++ with the POSIX threads library, you can use pthread_join() to have one thread wait for another thread to finish. If you are writing in Java with the java.lang.Thread class, you can use the join() method. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">For the solution to Too Much Milk suggested in the previous problem, each call to drinkMilkAndBuyIfNeeded() is atomic and holds the lock from the start to the end even if one roommate goes to the store. This solution is analogous to the roommate padlocking the kitchen while going to the store, which seems a bit unrealistic. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Implement a better solution to drinkMilkAndBuyIfNeeded() using both locks and condition variables. Since a roommate now needs to release the lock to the kitchen while going to the store, you will no longer acquire the lock at the start of this function and release it at the end. Instead, this function will call two helper-functions, each of which acquires/releases the lock. For example: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;int&nbsp;Kitchen::drinkMilkAndBuyIfNeeded()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;iShouldBuy&nbsp;=&nbsp;waitThenDrink();
   &nbsp;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(iShoudBuy)&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buyMilk();
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
   &nbsp;}</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In this function, waitThenDrink() should wait if there is no milk (using a condition variable) until there is milk, drink the milk, and if the milk is now gone, return a nonzero value to flag that the caller should buy milk. BuyMilk() should buy milk and then broadcast to let the waiting threads know that they can proceed. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Again, test your code with varying numbers of threads. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Before entering a <EM>priority critical section</EM>, a thread calls PriorityLock::enter(priority). When the thread exits the critical section, it calls PriorityLock::exit(). If several threads are waiting to enter a priority critical section, the one with the numerically highest priority should be the next one allowed in. Implement PriorityLock using monitors (locks and condition variables) and following the programming standards defined in this chapter. </FONT>
<P></P>
<OL class=subproblems>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Define the state and synchronization variables and describe the purpose of each. </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Implement PriorityLock::enter(int priority). </FONT>
<P></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Implement PriorityLock::exit(). </FONT>
<P></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Implement a <EM>priority condition variable.</EM> A priority condition variable (PCV) has three public methods: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;void&nbsp;PCV::wait(Lock&nbsp;*enclosingLock,&nbsp;int&nbsp;priority);
   &nbsp;
   &nbsp;void&nbsp;PCV::signal(Lock&nbsp;*enclosingLock);
   &nbsp;
   &nbsp;void&nbsp;PCV::broadcast(Lock&nbsp;*enclosingLock,&nbsp;int&nbsp;priority);</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">These methods are similar to those of a standard condition variable. The one difference is that a PCV enforces both <EM>priority</EM> and <EM>ordering</EM>. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">In particular, signal(Lock *lock) causes the currently waiting thread with the highest priority to return from wait; if multiple threads with the same priority are waiting, then the one that is waiting the longest should return before any that have been waiting a shorter amount of time. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Similarly, broadcast(Lock *lock, int priority) causes all currently waiting threads whose priority equals or exceeds priority to return from wait. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">For full credit, you must follow the <EM>thread coding standards</EM> described in this chapter. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">A synchronous buffer is one where the thread placing an item into the buffer waits until the thread retrieving the item has gotten it, and only then returns. </FONT>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Implement a synchronous buffer using Mesa-style locks and condition variables, with the following routines: </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"><BR></FONT></P><PRE class=code><FONT style="BACKGROUND-COLOR: #7be1e1">   &nbsp;//&nbsp;Put&nbsp;item&nbsp;into&nbsp;the&nbsp;buffer&nbsp;and&nbsp;return&nbsp;only&nbsp;once&nbsp;the&nbsp;item
   &nbsp;//&nbsp;has&nbsp;been&nbsp;retrieved&nbsp;by&nbsp;some&nbsp;thread.
   &nbsp;SyncBuf::put(item);
   &nbsp;
   &nbsp;//&nbsp;Wait&nbsp;until&nbsp;there&nbsp;is&nbsp;an&nbsp;item&nbsp;in&nbsp;the&nbsp;buffer,&nbsp;and&nbsp;then&nbsp;return&nbsp;it.
   &nbsp;SyncBuf::get();</FONT></PRE><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">Any number of threads can concurrently call SyncBuf::get and SyncBuf::put; the module pairs off puts and gets. Each item should be returned exactly once, and there should be no unnecessary waiting. Once the item is retrieved, the thread that called put with the item should return. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">You have been hired by a company to do climate modelling of oceans. The inner loop of the program matches atoms of different types as they form molecules. In an excessive reliance on threads, each atom is represented by a thread. </FONT>
<P></P>
<OL class=subproblems>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Your task is to write code to form water out of two hydrogen threads and one oxygen thread (H2O). You are to write the two procedures: HArrives() and OArrives(). A water molecule forms when two H threads are present and one O thread; otherwise, the atoms must wait. Once all three are present, one of the threads calls MakeWater(), and only then, all three depart. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">The company wants to extend its work to handle cloud modelling. Your task is to write code to form ozone out of three oxygen threads. Each of the threads calls OArrives(), and when three are present, one calls MakeOzone(), and only then, all three depart. </FONT>
<P></P>
<LI><FONT style="BACKGROUND-COLOR: #7be1e1">Extending the product line into beer production, your task is to write code to form alcohol (C2H6O) out of two carbon atoms, six hydrogens, and one oxygen. </FONT></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1">You must use locks and Mesa-style condition variables to implement your solutions, using the best practices as defined in this chapter. Obviously, an atom that arrives <EM>after</EM> the molecule is made must wait for a different group of atoms to be present. There should be no busy-waiting and you should correctly handle spurious wakeups. There must also be no useless waiting: atoms should not wait if there is a sufficient number of each type. </FONT></P>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P></LI></OL>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT>
<DIV style="break-after: always; -webkit-column-break-after: always"><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></DIV><BR><BR><BR>
<P><FONT style="BACKGROUND-COLOR: #7be1e1"></FONT></P><A id=x1-780006 name=x1-780006><BR><BR><FONT style="BACKGROUND-COLOR: #7be1e1">