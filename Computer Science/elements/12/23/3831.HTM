<strong><font color="blue">Operating Systems: Principles and Practice (Second Edition) Volume II : </font></strong><h3 class=sectionHead>6.3 Lock Contention</H3></A><FONT style="BACKGROUND-COLOR: #ffffff">Sometimes, even after applying the techniques described in the previous section, locking may remain a bottleneck to good performance on a multiprocessor. For example, with fine-grained locking of a hash table, if a bucket contains a particularly popular item, say the cached page for Justin Bieber, then the lock on that bucket can be a source of contention. </FONT>
<P>In this section, we discuss two alternate implementations of the lock abstraction that work better for locks that are bottlenecks: </P>
<UL class=itemize1>
<LI class=itemize>
<P><B>MCS Locks.</B> MCS is an implementation of a spinlock optimized for the case when there are a significant number of waiting threads. </P>
<LI class=itemize>
<P><B>RCU Locks.</B> RCU is an implementation of a reader/writer lock, optimized for the case when there are many more readers than writers. RCU reduces the overhead for readers at a cost of increased overhead for writers. More importantly, RCU has somewhat different semantics than a normal reader/writer lock, placing a burden on the user of the lock to understand its dangers.</P></LI></UL>
<P>Although both approaches are used in modern operating system kernels, we caution that neither is a panacea. They should only be used once profiling has shown that the lock is a source of contention and no other options are available. <A id=x1-85001r137 name=x1-85001r137></A></P>
<H4 class=subsectionHead>6.3.1 <A id=x1-860001 name=x1-860001></A>MCS Locks</H4>Recall that the lock implementation described in Chapter&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-390005"}'>5</A> was tuned for the common case where the lock was usually FREE. Is there an efficient implementation of locks when the lock is usually BUSY? 
<P>Unfortunately, the overhead of acquiring and releasing a lock can <EM>increase</EM> dramatically with the number of threads contending for the lock. For a contended lock, this can further increase the number of threads waiting for the lock. Consider again the example we used earlier, of a spinlock protecting a shared counter: </P>
<P><BR></P><PRE class=code>   &nbsp;void&nbsp;Counter::Increment()&nbsp;{
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(test_and_set(&amp;lock))&nbsp;//&nbsp;while&nbsp;BUSY
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;//&nbsp;spin
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value++;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock&nbsp;=&nbsp;FREE;
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
   &nbsp;}</PRE><BR>
<P>Even if many threads try to increment the same counter, only one thread at a time can execute the critical section; the other threads must wait their turn. As we observed earlier, because the counter value must be communicated from one lock holder to the next, the critical section will take significantly longer on a multiprocessor than on a single processor. <A id=x1-860014 name=x1-860014></A></P>
<HR>

<CENTER><img alt="" src="about:../Images/image00405.gif" data-calibre-src="OEBPS/Images/image00405.gif"> </CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.4: </B>The overhead of three alternative lock implementations as a function of the number of processors contending for the lock: (a) test-and-set, (b) test and test-and-set, and (c) MCS. Measurements taken on a 64-core AMD Opteron 6262. The non-smooth curves are typical of measurements of real systems.</P></TD></TR></TBODY></TABLE>
<HR>

<P>However, the situation with multiple waiting threads is even worse. The time to execute a critical section protected by a spinlock increases linearly with the number of spinning processors. Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-860014"}'>6.4</A> illustrates this effect. The problem is that before a processor can execute an atomic read-modify-write instruction, the hardware must obtain exclusive access to that memory location. Any other read-modify-write instruction must occur either before or afterwards. </P>
<P>Thus, if a number of processors are executing a spin loop, they will all be trying to gain exclusive access to the memory location of the lock. The store instruction to clear the lock also needs exclusive access, and the hardware has no way to know that it should prioritize the lock release ahead of the competing requests to see if the lock is free. </P>
<P>One might think that it would help to check that the lock is free before trying to acquire it with a test-and-set; this is called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:test and test-and-set"}'>test and test-and-set</A></EM>: </P>
<P></P>
<P><BR></P><PRE class=code>&nbsp;void&nbsp;Counter::Increment()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(lock&nbsp;==&nbsp;BUSY&nbsp;||&nbsp;test_and_set(&amp;lock))&nbsp;//&nbsp;while&nbsp;BUSY
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;//&nbsp;spin
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value++;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lock&nbsp;=&nbsp;FREE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;}</PRE><BR>
<P>However, it turns out this does not help. When the lock is released, the new value of the lock, FREE, must be communicated to the other waiting processors. On modern systems, each processor separately fetches the data into its cache. Eventually one of them gets the new value and acquires the lock. If the critical section is not very long, the other processors will still be busy fetching the new value and trying to acquire the lock, preventing the lock release from completing. </P>
<P>One approach is to adjust the frequency of polling to the length of time that the thread has been waiting. A more scalable solution is to assign each waiting thread a separate memory location where it can spin. To release a lock, the bit is set for <EM>one</EM> thread, telling it that it is the next to acquire the lock. </P>
<P>The most widely used implementation of this idea is known as the MCS lock, after the initials of its authors, Mellor-Crummey and Scott. The MCS lock takes advantage of an atomic read-modify-write instruction called <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:compare-and-swap"}'>compare-and-swap</A></EM> that is supported on most modern multiprocessor architectures. Compare-and-swap tests the value of a memory location and swaps in a new value if the old value has not changed. <A id=x1-860025 name=x1-860025></A></P>
<HR>

<P></P><PRE class=code>&nbsp;class&nbsp;MCSLock&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;*tail&nbsp;=&nbsp;NULL;
&nbsp;}
&nbsp;
&nbsp;MCSLock::release()&nbsp;{
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(compare_and_swap(&amp;tail,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;myTCB,&nbsp;NULL))&nbsp;{
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;tail&nbsp;==&nbsp;myTCB,&nbsp;no&nbsp;one&nbsp;is
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;waiting.&nbsp;MCSLock&nbsp;is&nbsp;now&nbsp;free.
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Someone&nbsp;is&nbsp;waiting.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(myTCB-&gt;next&nbsp;==&nbsp;NULL)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;//&nbsp;spin&nbsp;until&nbsp;next&nbsp;is&nbsp;set
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Tell&nbsp;next&nbsp;thread&nbsp;to&nbsp;proceed.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;myTCB-&gt;next-&gt;needToWait&nbsp;=&nbsp;FALSE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
&nbsp;
&nbsp;MCSLock::acquire()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Queue&nbsp;*oldTail&nbsp;=&nbsp;tail;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;myTCB-&gt;next&nbsp;=&nbsp;NULL;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(!compare_and_swap(&amp;tail,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldTail,&nbsp;&amp;myTCB))&nbsp;{
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Try&nbsp;again&nbsp;if&nbsp;someone&nbsp;else
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;changed&nbsp;tail&nbsp;in&nbsp;the&nbsp;meantime.
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldTail&nbsp;=&nbsp;tail;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;oldTail&nbsp;==&nbsp;NULL,&nbsp;lock&nbsp;acquired.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldTail&nbsp;!=&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Need&nbsp;to&nbsp;wait.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;myTCB-&gt;needToWait&nbsp;=&nbsp;TRUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldTail-&gt;next&nbsp;=&nbsp;myTCB;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(myTCB-&gt;needToWait)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;//spin
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
</PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.5: </B>Pseudo-code for an MCS queueing lock, where each waiting thread spins on a separate memory location in its thread control block (myTCB). The operation, compare-and-swap, atomically inserts the TCB at the tail of the queue.</P></TD></TR></TBODY></TABLE></DIV>
<HR>
<A id=x1-860036 name=x1-860036></A>
<CENTER><img alt="" src="about:../Images/image00406.gif" data-calibre-src="OEBPS/Images/image00406.gif"> </CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.6: </B>The behavior of the MCS queueing lock. Initially (a), tail is NULL indicating that the lock is FREE. To acquire the lock (b), thread A atomically sets tail to point to A&#8217;s TCB. Additional threads B and C queue by adding themselves (atomically) to the tail (c) and (d); they then spin on their respective TCB&#8217;s needToWait flag. Thread A hands the lock to B by clearing B&#8217;s needToWait flag (e); B hands the lock to C by clearing C&#8217;s needToWait fla (f). C releases the lock by setting tail back to NULL (a) iff no one else is waiting &#8212; that is, iff tail still points to C&#8217;s TCB.</P></TD></TR></TBODY></TABLE>
<HR>

<P>Compare-and-swap can be used to build a queue of waiting threads, without a separate spinlock. A waiting thread atomically adds itself to the <EM>tail</EM> of the queue, and then spins on a flag in its queue entry. When a thread releases the lock, it sets the flag in the next queue entry, signaling to the thread that its turn is next. Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-860025"}'>6.5</A> provides an implementation, and Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-860036"}'>6.6</A> illustrates the algorithm in action. </P>
<P>Because each thread in the queue spins on its own queue entry, the lock can be passed efficiently from one thread to another along the queue. Of course, the overhead of setting up the queue means that an MCS lock is less efficient than a normal spinlock unless there are a large number of waiting threads. <A id=x1-86004r140 name=x1-86004r140></A></P>
<H4 class=subsectionHead>6.3.2 <A id=x1-870002 name=x1-870002></A>Read-Copy-Update (RCU)</H4><EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:read-copy-update"}'>Read-copy-update</A></EM> (RCU) provides high-performance synchronization for data structures that are frequently read and occasionally updated. In particular, RCU optimizes the read path to have extremely low synchronization costs even with a large number of concurrent readers. However, writes can be delayed for a long time &#8212; tens of milliseconds in some implementations. 
<H5 class=subsubsectionHead><A id=x1-880002 name=x1-880002></A>Why Not Use a Readers/Writers Lock?</H5>Standard readers/writers locks are a poor fit for certain types of read-dominated workloads. Recall that these locks allow an arbitrary number of concurrent active readers, but when there is an active writer, no other writer or reader can be active. 
<P>The problem occurs when there are many concurrent reads with short critical sections. Before reading, each reader must acquire a readers/writers lock in read mode and release it afterwards. On both entrance and exit, the reader must update some state in the readers/writers synchronization object. Even when there are only readers, the readers/writers synchronization object can become a bottleneck. This limits the rate at which readers can enter the critical section, because they can only acquire the lock one at a time. For critical sections of less than a few thousand cycles, and for programs with dozens of threads simultaneously reading a shared object, the standard readers/writers lock can limit performance. </P>
<P>While the readers/writers synchronization object could be implemented with an MCS lock and thereby reduce some of the effects of lock contention, it does not change the inherent serial access of the readers/writers control structure. </P>
<H5 class=subsubsectionHead><A id=x1-890002 name=x1-890002></A>The RCU Approach</H5>How can concurrent reads access a data structure &#8212; one that can also be written &#8212; without having to update the state of a synchronization variable on each read? 
<P>To meet this challenge, an RCU lock retains the basic structure of a reader/writers lock: readers (and writers) surround each critical section with calls to acquire and release the RCU lock in read-mode (or write-mode). An RCU lock makes three important changes to the standard interface: </P>
<OL class=enumerate1>
<LI class=enumerate><A id=x1-89002x1 name=x1-89002x1></A>
<P><B>Restricted update.</B> With RCU, the writer thread must <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:publish"}'>publish</A></EM> its changes to the shared data structure with a single, atomic memory write. Typically, this is done by updating a single pointer, as we illustrate below by using RCU to update a shared list. </P>
<P>Although restricted updates might seem to severely limit the types of data structure operations that are possible under RCU, this is not the case. A common pattern is for the writer thread to make a <EM>copy</EM> of a complex data structure (or a portion of it), update the copy, and then publish a pointer to the copy into a shared location where it can be accessed by new readers. </P>
<LI class=enumerate><A id=x1-89004x2 name=x1-89004x2></A>
<P><B>Multiple concurrent versions.</B> RCU allows any number of read-only critical sections to be in progress at the same time as the update. These read-only critical sections may see the old or new version of the data structure. </P>
<LI class=enumerate><A id=x1-89006x3 name=x1-89006x3></A>
<P><B>Integration with the thread scheduler.</B> Because there may be readers still in progress when an update is made, the shared object must maintain multiple versions of its state, to guarantee that an old version is not freed until all readers have finished accessing it. The time from when an update is published until the last reader is done with the previous version is called the <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:grace period"}'>grace period</A></EM>. The RCU lock uses information provided by the thread scheduler to determine when a grace period ends. </P></LI></OL><A id=x1-890077 name=x1-890077></A>
<HR>

<CENTER><img alt="" src="about:../Images/image00407.gif" data-calibre-src="OEBPS/Images/image00407.gif"> </CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.7: </B>Timeline for an update concurrent with several reads for a data structure accessed with read-copy-update (RCU) synchronization.</P></TD></TR></TBODY></TABLE>
<HR>

<P>Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-890077"}'>6.7</A> shows the timeline for the critical sections of a writer and several reader threads under RCU. If a function that reads the data structure completes before a write is published, it sees the old version of the data structure; if a reader begins after a write is published, it sees the new version. But, if a reader begins <EM>before</EM> and ends <EM>after</EM> a write is published, it may see either the old version or the new one. If it reads the updated pointer more than once, it may see the old one and then the new one. Which version it sees depends on which version of the single, atomically-updated memory location it observes. However, the system guarantees that the old version is not deleted until the grace period expires. The deletion of the old version must be delayed until all reads that might observe the old version have completed. </P>
<H5 class=subsubsectionHead><A id=x1-900002 name=x1-900002></A>RCU API and Use</H5>RCU is a synchronization abstraction that allows concurrent access to a data structure by multiple readers and a single writer at a time. Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-900018"}'>6.8</A> shows a typical API. <A id=x1-900018 name=x1-900018></A>
<HR>

<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td colSpan=2 align=left>
<P class=tabp></P>
<DIV class=multicolumn align=center noWrap><B>Reader API</B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>readLock() </P></TD>
<TD class=td align=left>
<P class=tabp>Enter read-only critical section. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>readUnlock() </P></TD>
<TD class=td align=left>
<P class=tabp>Exit read-only critical section. </P></TD></TR>
<TR class=tr>
<TD class=td colSpan=2 align=left>
<P class=tabp></P>
<DIV class=multicolumn align=center noWrap><B>Writer API</B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>writeLock() </P></TD>
<TD class=td align=left>
<P class=tabp>Enter read-write critical section. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>publish() </P></TD>
<TD class=td align=left>
<P class=tabp>Atomically update shared data structure. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>writeUnlock() </P></TD>
<TD class=td align=left>
<P class=tabp>Exit read-write critical section. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>synchronize() </P></TD>
<TD class=td align=left>
<P class=tabp>Wait for all currently active readers to exit critical section, to allow for garbage collection of old versions of the object. </P></TD></TR>
<TR class=tr>
<TD class=td colSpan=2 align=left>
<P class=tabp></P>
<DIV class=multicolumn align=center noWrap><B>Scheduler API</B></DIV></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>quiescentState() </P></TD>
<TD class=td align=left>
<P class=tabp>Of the read-only threads on this processor who were active during the most recent RCU::publish, all have exited the critical section. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp></P></TD></TR></TBODY></TABLE></DIV>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.8: </B>Sample programming interface for read-copy-update (RCU) synchronization. In Java&#8217;s implementation of RCU locks, synchronize and quiescentState are not needed because the language-level garbage collector automatically detects when old versions can no longer be accessed. In the implementation of RCU in the Linux kernel, synchronize is split into two calls: one to start the grace period, and one to wait until the grace period completes.</P></TD></TR></TBODY></TABLE></DIV>
<HR>

<P>A reader calls RCU::readLock and RCU::readUnlock before and after accessing the shared data structure. A writer calls: RCU::writeLock to exclude other writers; RCU::publish to issue the write that atomically updates the data structure so that reads can see the updates; RCU::writeUnlock to let other writers proceed; and RCU::synchronize to wait for the grace period to expire so that the old version of the object can be freed. </P>
<P>As Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-900029"}'>6.9</A> illustrates, writes are serialized &#8212; only one write can proceed at a time. However, a write can be concurrent with any number of reads. A write can also be concurrent with another write&#8217;s grace period: there may be any number of versions of the object until multiple overlapping grace periods expire. <A id=x1-900029 name=x1-900029></A></P>
<HR>

<P></P>
<CENTER><img alt="" src="about:../Images/image00408.gif" data-calibre-src="OEBPS/Images/image00408.gif"></CENTER>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.9: </B>RCU allows one write at a time, and it allows reads to overlap each other and writes. The initial version is v0, and overlapping writes update the version to v1, v2, and then v3.</P></TD></TR></TBODY></TABLE>
<HR>

<P><B>EXAMPLE: </B>For each read in Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-900029"}'>6.9</A>, which version(s) of the shared state can the read observe? </P>
<P><B>ANSWER: </B>If a read overlaps a publish, it can return the published value or the previous value: </P>
<P><BR></P>
<DIV align=center>
<TABLE class=texttable border=0>
<TBODY>
<TR class=tr>
<TD class=td align=left>
<P class=tabp><B>Read</B> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; <B>Value Returned</B> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; <B>Reason</B> </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>1</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v0 or v1 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; Overlaps publish v1. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>2</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v2 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; After publish v2, before publish v3. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>3</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v3 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; After publish v3. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>4</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v0 or v1 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; Overlaps publish v1. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>5</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v1 or v2 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; Overlaps publish v2. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>6</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v0, v1, or v2 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; Overlaps publish v1 and v2. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp>read<SUB>7</SUB> </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; v3 </P></TD>
<TD class=td align=left>
<P class=tabp>&nbsp;&nbsp;&nbsp; After publish v2. </P></TD></TR>
<TR class=tr>
<TD class=td align=left>
<P class=tabp></P></TD></TR></TBODY></TABLE></DIV><BR>&#9633; <A id=x1-9000310 name=x1-9000310></A>
<HR>
<PRE class=code>&nbsp;typedef&nbsp;struct&nbsp;ElementS{
&nbsp;&nbsp;&nbsp;int&nbsp;key;
&nbsp;&nbsp;&nbsp;int&nbsp;value;
&nbsp;&nbsp;&nbsp;struct&nbsp;ElementS&nbsp;*next;
&nbsp;}&nbsp;Element;
&nbsp;
&nbsp;class&nbsp;RCUList&nbsp;{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RCULock&nbsp;rcuLock;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Element&nbsp;*head;
&nbsp;&nbsp;&nbsp;public:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;search(int&nbsp;key,&nbsp;int&nbsp;*value);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;insert(Element&nbsp;*item,&nbsp;value);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;remove(int&nbsp;key);
&nbsp;};</PRE><PRE class=code>&nbsp;bool
&nbsp;RCUList::search(int&nbsp;key,&nbsp;int&nbsp;*valuep)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;result&nbsp;=&nbsp;FALSE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Element&nbsp;*current;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.readLock();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;=&nbsp;head;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(current&nbsp;=&nbsp;head;&nbsp;current&nbsp;!=&nbsp;NULL;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;=&nbsp;current-&gt;next)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(current-&gt;key&nbsp;==&nbsp;key)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*valuep&nbsp;=&nbsp;current-&gt;value;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result&nbsp;=&nbsp;TRUE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.readUnlock();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;result;
&nbsp;}</PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.10: </B>Declaration of data structures and API for a linked list that uses RCU for synchronization, and the implementation of a read-only method for searching the linked list using RCU.</P></TD></TR></TBODY></TABLE></DIV>
<HR>

<P><B>EXAMPLE: RCU linked list.</B> Figures&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-9000310"}'>6.10</A> and <A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-9000411"}'>6.11</A> show how to use RCU locks to implement a linked list that can be accessed concurrently by many readers, while also being updated by one writer. </P>
<P>The list data structure comprises an RCU lock and a pointer to the head of the list. Each entry in the list has two data fields &#8212; key and value &#8212; as well as a pointer to the next record on the list. </P>
<P>The search method is read-only: after registering with readLock, it scans down the list until it finds an element with a matching key. If the element is found, the method uses the parameter to return the value field and then returns TRUE. Otherwise, the method returns FALSE&nbsp;to indicate that no matching record was found. </P>
<P>The methods to update the list are more subtle. Each of them is arranged so that a single pointer update is sufficient to publish the new version of the list to the readers. In particular, it is important that insert initialize the data structure <EM>before</EM> updating the head pointer to make the new element visible to readers. <A id=x1-9000411 name=x1-9000411></A></P>
<HR>
<PRE class=code>&nbsp;void
&nbsp;RCUList::insert(int&nbsp;key,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;value)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Element&nbsp;*item;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;One&nbsp;write&nbsp;at&nbsp;a&nbsp;time.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.writeLock();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Initialize&nbsp;item.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item&nbsp;=&nbsp;(Element*)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;malloc(sizeof(Element));
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item-&gt;key&nbsp;=&nbsp;key;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item-&gt;value&nbsp;=&nbsp;value;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;item-&gt;next&nbsp;=&nbsp;head;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Atomically&nbsp;update&nbsp;list.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.publish(&amp;head,&nbsp;item);
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Allow&nbsp;other&nbsp;writes
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;to&nbsp;proceed.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.writeUnlock();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Wait&nbsp;until&nbsp;no&nbsp;reader
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;has&nbsp;old&nbsp;version.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.synchronize();
&nbsp;}</PRE><PRE class=code>&nbsp;bool
&nbsp;RCUList::remove(int&nbsp;key)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bool&nbsp;found&nbsp;=&nbsp;FALSE;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Element&nbsp;*prev,&nbsp;*current;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;One&nbsp;write&nbsp;at&nbsp;a&nbsp;time.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.WriteLock();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(prev&nbsp;=&nbsp;NULL,&nbsp;current&nbsp;=&nbsp;head;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;!=&nbsp;NULL;&nbsp;prev&nbsp;=&nbsp;current,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current&nbsp;=&nbsp;current-&gt;next)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(current-&gt;key&nbsp;==&nbsp;key)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;found&nbsp;=&nbsp;TRUE;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Publish&nbsp;update&nbsp;to&nbsp;readers
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(prev&nbsp;==&nbsp;NULL)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.publish(&amp;head,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current-&gt;next);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.publish(&amp;(prev-&gt;next),
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current-&gt;next);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Allow&nbsp;other&nbsp;writes&nbsp;to&nbsp;proceed.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.writeUnlock();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Wait&nbsp;until&nbsp;no&nbsp;reader&nbsp;has&nbsp;old&nbsp;version.
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(found)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rcuLock.synchronize();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;free(current);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;found;
&nbsp;}</PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.11: </B>Implementation of a linked list using RCU for synchronization.</P></TD></TR></TBODY></TABLE></DIV>
<HR>

<H5 class=subsubsectionHead><A id=x1-910002 name=x1-910002></A>Implementing RCU</H5>When implementing RCU, the central goal is to minimize the cost of read critical sections: the system must allow an arbitrary number of concurrent readers. Conversely, writes can have high <EM>latency</EM>. In particular, grace periods can be long, with tens of milliseconds from when an update is published until the system can guarantee that no readers are still using the old version. Even so, write <EM>overhead</EM> &#8212; the CPU time needed per write &#8212; should be modest. 
<P>A common technique for achieving these goals is to integrate the RCU implementation with that of the thread scheduler. This is in contrast with the readers/writers lock described in the previous chapter, which makes no assumptions about the thread scheduler, but which must track exactly how many readers are active at any given time. </P>
<P>In particular, the implementation we present requires two things from the scheduler: (1) read-only critical sections complete without being interrupted and (2) whenever a thread on a processor is interrupted, the scheduler updates some per-processor RCU state. Then, once a write completes, RCULock::Synchronize simply waits for all processors to be interrupted at least once. At that point, the old version of the object is known to be <EM><A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "glo:quiescent"}'>quiescent</A></EM> &#8212; no thread has access to the old version (other than the writer who changed it). <A id=x1-9100112 name=x1-9100112></A></P>
<HR>

<P></P><PRE class=code>&nbsp;class&nbsp;RCULock{
&nbsp;&nbsp;&nbsp;private:
&nbsp;&nbsp;&nbsp;//&nbsp;Global&nbsp;state
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spinlock&nbsp;globalSpin;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;long&nbsp;globalCounter;
&nbsp;&nbsp;&nbsp;//&nbsp;One&nbsp;per&nbsp;processor
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DEFINE_PER_PROCESSOR(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;static&nbsp;long,&nbsp;quiescentCount);
&nbsp;
&nbsp;&nbsp;&nbsp;//&nbsp;Per-lock&nbsp;state
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spinlock&nbsp;writerSpin;
&nbsp;
&nbsp;&nbsp;&nbsp;//&nbsp;Public&nbsp;API&nbsp;omitted
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RCULock::ReadLock()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;disableInterrupts();
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RCULock::ReadUnlock()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enableInterrupts();
&nbsp;}
&nbsp;
&nbsp;//&nbsp;Called&nbsp;by&nbsp;scheduler
&nbsp;void&nbsp;RCULock::QuiescentState(){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PER_PROC_VAR(quiescentCount)&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;globalCounter;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RCULock::writeLock()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writerSpin.acquire();
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RCULock::writeUnlock()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;writerSpin.release();
&nbsp;}
&nbsp;
&nbsp;void&nbsp;RCULock::publish&nbsp;(void&nbsp;**pp1,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;void&nbsp;*p2){
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*pp1&nbsp;=&nbsp;p2;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;memory_barrier();
&nbsp;}
&nbsp;
&nbsp;void
&nbsp;RCULock::synchronize()&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;p,&nbsp;c;
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;globalSpin.acquire();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c&nbsp;=&nbsp;++globalCounter;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;globalSpin.release();
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FOREACH_PROCESSOR(p)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while((PER_PROC_VAR(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;quiescentCount,&nbsp;p)&nbsp;-&nbsp;c)&nbsp;&lt;&nbsp;0)&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;release&nbsp;CPU&nbsp;for&nbsp;10ms
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sleep(10);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
&nbsp;}
</PRE>
<DIV class=caption align=center>
<TABLE cellPadding=10>
<TBODY>
<TR>
<TD align=left>
<P class=caption width=0><B>Figure&nbsp;6.12: </B>A quiescence-based RCU implementation. The code assumes that spinlock acquire/release and interrupt enable/disable trigger a memory barrier. <EM>Credit:</EM> This pseudo-code is based on an implementation by Paul McKenney in &#8220;Is Parallel Programming Hard, And, If So, What Can be Done About It?&#8221;</P></TD></TR></TBODY></TABLE></DIV>
<HR>

<P>Figure&nbsp;<A data-9uzdtcnnj6xqoalwmdp3qa='{"name": "OEBPS/Text/part0000.xhtml", "frag": "x1-9100112"}'>6.12</A> shows an implementation of RCU based on quiescent states. Notice first that readLock and readUnlock are inexpensive: they update no state and merely ensure that the read is not interrupted. RCU::writeLock and writeUnlock are also inexpensive. They acquire and release a spinlock to ensure that at most one write per RCULock can proceed at a time. </P>
<P>RCU::publish is also simple. It executes a memory barrier so that all modifications to the shared object are completed before the pointer is updated. It then updates the pointer, and then executes another memory barrier so that other processors observe the update. </P>
<P>RCU::synchronize and quiescentState work together to ensure that when synchronize returns, all threads are guaranteed to be done with the old version of the object. RCU::synchronize increments a global counter and then waits until all processors&#8217; match the new value of that counter. RCU::quiescentState is called by the scheduler whenever that processor is interrupted. It updates that processor&#8217;s quiescentCount to match the current globalCounter. Thus, once quiescentCount is at least as large as c, on every processor, synchronize knows that no remaining readers can observe the old version. <A id=x1-91002r139 name=x1-91002r139></A></P><A id=x1-920004 name=x1-920004>