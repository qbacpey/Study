<P width=0><SPAN class=sidebar_name><SPAN class=headers><SPAN class=headers>Title:</SPAN></B><SPAN class=RefText> 2.4.1 Interrupt Vector Table</SPAN></FONT></SPAN></SPAN></P>
<P width=0><SPAN class=sidebar_name><B><I>Multiprocessors and interrupt routing</I></B></SPAN> </P>
<P>On a multiprocessor, which of the various processors should take an interrupt? Some early multiprocessors dedicated a single processor (&#8220;processor 0") to handle all external interrupts. If an event required a change to what one of the other processors was doing, processor 0 could send an interprocessor interrupt to trigger that processor to switch to a new process. </P><SPAN class=extract>
<P>&#26089;&#26399;&#30340;&#22810;&#26680;&#22788;&#29702;&#22120;&#20250;&#35753;&#26576;&#20010;&#29305;&#23450;&#30340;&#22788;&#29702;&#22120;&#19987;&#21496;&#20013;&#26029;&#22788;&#29702;&#65292;&#22240;&#27492;&#22312;&#36825;&#31181;&#35745;&#31639;&#26426;&#19978;&#25152;&#26377;&#30340;&#20013;&#26029;&#22788;&#29702;&#31243;&#24207;&#20195;&#30721;&#37117;&#30001;&#23427;&#26469;&#25191;&#34892;</P>
<P></SPAN>For systems needing to do a large amount of input and output, such as a web server, directing all I/O through a single processor can become a bottleneck. In modern systems, interrupt routing is increasingly programmable, under control of the kernel. Each processor usually has its own hardware timer. Likewise, disk I/O events can be sent directly to the processor that requested the I/O operation rather than to a random processor. Modern processors can run substantially faster if their data is already loaded into the processor cache, versus if their code and data are in some other processor&#8217;s cache. </P>
<P><SPAN class=extract>&#29616;&#22312;&#30340;&#35745;&#31639;&#26426;&#31995;&#32479;&#24448;&#24448;&#35753;&#21508;&#20010;&#22788;&#29702;&#22120;&#33258;&#24049;&#22788;&#29702;&#33258;&#24049;&#30340;&#20013;&#26029;&#20107;&#21153;&#65292;&#20856;&#22411;&#30340;&#20363;&#23376;&#23601;&#26159;I/O&#20013;&#26029;&#65292;&#24456;&#26174;&#28982;&#65292;&#22914;&#26524;&#27599;&#20010;&#22788;&#29702;&#22120;&#25152;&#35201;&#35835;&#21462;&#30340;&#25968;&#25454;&#23601;&#20301;&#20110;&#33258;&#24049;&#30340;Cache&#20013;&#65288;&#32780;&#19981;&#26159;&#20854;&#20182;&#22788;&#29702;&#22120;&#30340;Cache&#20013;&#65289;&#65292;&#37027;&#20040;&#25191;&#34892;&#36895;&#24230;&#23601;&#20250;&#24555;&#24456;&#22810;</SPAN></P>
<P>Efficient delivery of network I/O packets is even more challenging. A high performance server might send and receive tens of thousands of packets per second, representing thousands of different connections. From a processing perspective, it is best to deliver incoming packets to the processor responsible for handling that connection; this requires the network interface hardware to re-direct the incoming packet based on the contents of its header (e.g., the IP address and port number of the client). Recent network controllers accomplish this by supporting multiple buffer descriptor rings for the same device, choosing which ring to use, and therefore which processor to interrupt, based on the header of the arriving packet. 
<P><SPAN class=extract>&#22914;&#26524;&#19968;&#21488;&#35745;&#31639;&#26426;&#38656;&#35201;&#22788;&#29702;&#22823;&#37327;&#30340;I/O&#20013;&#26029;&#65292;&#37027;&#20040;&#32771;&#34385;&#21040;&#24615;&#33021;&#65292;&#32593;&#21345;&#38656;&#35201;&#26681;&#25454;&#21253;&#30340;&#20869;&#23481;&#20915;&#23450;&#23558;&#21253;&#21457;&#36865;&#32473;&#30446;&#26631;&#65288;&#32780;&#19981;&#26159;&#38543;&#26426;&#30340;&#65289;&#22788;&#29702;&#22120;&#65292;&#36825;&#20010;&#36807;&#31243;&#34987;&#31216;&#20026;&#20013;&#26029;&#36335;&#30001;&#65288;interrupt routing&#65289;<BR></SPAN>